% !TEX root = ../notes.tex

We continue discussing completion.

\subsection{Refining Inverse Limits}
Recall that we had a notion of completion for modules as follows.
\modcomplete*
\noindent Here is our primary example.
\begin{example}
	If we fix an ideal $I\subseteq R$, then we are granted an $I$-adic filtration of $M$, which gives the $I$-adic completion of $M$. In particular, this is an $\widehat R_I$-module by \autoref{lem:completemodovercompletering}.
\end{example}
We are going to want some freedom in changing our exact filtration, so we have the following sequence of lemmas. To start, subsequences don't do anything to our inverse limit.
\begin{lemma} \label{lem:subsequencefiltration}
	Fix an $R$-module $M$ with a filtration $\mathcal J=\{M_k\}_{k\in\NN}$. Then, for any strictly increasing function $\alpha:\NN\to\NN$, we have
	\[\limit M/M_{\alpha k}\cong\limit M/M_k.\]
\end{lemma}
\begin{proof}
	We proceed by force. For any $k$, we note that $\alpha k\ge k$ (e.g., by induction because $\alpha$ is strictly increasing), so $M_k\supseteq M_{\alpha k}$, so we have an induced map
	\[\psi_k:M/M_{\alpha k}\onto M/M_k.\]
	As such, we define the map $\psi:\prod_kM/M_{\alpha k}\to\prod_kM/M_k$ by
	\[\psi:\{m_k+M_{\alpha k}\}_{k\in\NN}\mapsto\{m_k+M_k\}_{k\in\NN}\]
	created by gluing the maps $\psi_k$. We claim that $\psi$ descends to the desired isomorphism: let $\varphi$ be the restriction of $\psi$ to $\limit M/M_{\alpha k}$. We have the following checks on $\varphi$.
	\begin{itemize}
		\item The image of $\varphi$ is contained in $\limit M/M_k$. Indeed, fix some $\{m_k+M_{\alpha k}\}_{k\in\NN}$, which goes to $\{m_k+M_k\}_{k\in\NN}$. For any $i>j$, we need to show that
		\[m_i\equiv m_j\pmod{M_i}.\]
		Well, by hypothesis, we see that $m_i\equiv m_j\pmod{M_{\alpha i}}$, so $m_i-m_j\in M_{\alpha i}\subseteq M_i$, which is what we wanted.
		\item The image of $\varphi$ contains $\limit M/M_k$. For this, we create an inverse map of sets. Indeed, fix some $\{m_k+M_k\}_{k\in\NN}$, and we note that
		\[\varphi:\{m_{\alpha k}+M_{\alpha k}\}_{k\in\NN}\mapsto\{m_{\alpha k}+M_k\}_{k\in\NN}.\]
		So we claim that $\{m_{\alpha k}+M_{\alpha k}\}_{k\in\NN}$ is the desired input. First, this input is valid: for any $i>j$, we see that $m_{\alpha i}\equiv m_{\alpha j}\pmod{M_{\alpha i}}$ by hypothesis on the $m_i$.

		But second, we note that $\alpha k\ge k$ implies that
		\[m_{\alpha k}\equiv m_k\pmod{M_k},\]
		so $\{m_{\alpha k}+M_k\}_{k\in\NN}=\{m_k+M_k\}_{k\in\NN}$, so we have indeed hit the desired coset.
		\item The kernel of $\varphi$ is trivial. Indeed, suppose that $\{m_k+M_{\alpha k}\}_{k\in\NN}$ goes to $0$ under $\varphi$, which means that
		\[m_k+M_k=0+M_k\]
		for each $k$. But this implies that $m_{\alpha k}\in M_{\alpha k}$ while $\alpha k\ge k$, so the hypothesis on the $m_k$ implies that
		\[m_k\equiv m_{\alpha k}\equiv0\pmod{M_{\alpha k}},\]
		so the $m_k+M_{\alpha k}$ all vanish. This finishes.
	\end{itemize}
	Thus, we have shown that $\varphi$ will inject onto $\limit M/M_k$ and therefore witnesses the needed isomorphism
	\[\limit M/M_{\alpha k}\cong\limit M/M_k.\]
	This finishes.
\end{proof}
Next, we note that containment is fairly well-behaved.
\begin{lemma} \label{lem:containedfiltration}
	Fix an $R$-module $M$ with filtrations $\mathcal J=\{M_k\}_{k\in\NN}$ and $\mathcal J'=\{M_k'\}_{k\in\NN}$ such that $M_k\subseteq M_k'$ for each $k$. Then the map
	\[\{m_k+M_k\}_{k\in\NN}\mapsto\{m_k+M_k'\}_{k\in\NN}\]
	defines a morphism $\limit M/M_k\to\limit M/M_k'$.
\end{lemma}
\begin{proof}
	For any fixed $k$, that $M_k\subseteq M_k'$ induces a morphism $\psi_k:M/M_k\to M/M_k'$ by
	\[\psi_k:m_k+M_k\to m_k+M_k'.\]
	These glue together to a morphism
	\[\psi:\prod_{k\in\NN}M/M_k\to\prod_{k\in\NN}M/M_k'.\]
	Let $\varphi$ be the restriction of this map to $\limit M/M_k$, and we need to show $\im\varphi\subseteq\limit M/M_k'$. Well, fix $\{m_k+M_k\}_{k\in\NN}$ in $\limit M/M_k$. Then, for any $i>j$, we see that
	\[m_i-m_j\in M_j\subseteq M_j',\]
	so it follows
	\[\{m_k+M_k'\}_{k\in\NN}\in\limit M/M_k',\]
	which is what we wanted.
\end{proof}
We can then synthesize the above two lemmas to give the following refinement result.
\begin{lemma} \label{lem:samecompletion}
	Fix an $R$-module $M$ with filtrations $\mathcal J=\{M_k\}_{k\in\NN}$ and $\mathcal J'=\{M_k'\}_{k\in\NN}$. Further, suppose that, for all $i$, there exists $j$ such that $M_i\supseteq M_j'$; similarly, there exists (perhaps another) $j$ such that $M_i'\supseteq M_j$. Then we have an isomorphism
	\[\limit M/M_i\cong\limit M/M_i'\]
\end{lemma}
\begin{proof}
	In general, if we have two inverse limits, the way to define an inverse limit is to define a map into each of the components. To manifest this idea, we pick up strictly increasing $\alpha,\beta,\gamma:\NN\to\NN$ such that
	\[M_j\supseteq M_{\alpha(j)}'\supseteq M_{\beta(j)}\supseteq M'_{\gamma(j)}.\tag{$*$}\label{eq:inclusions}\]
	To show that such $\alpha,\beta,\gamma$ all actually exist, we proceed inductively: we can start with $\alpha(0)=\beta(0)=\gamma(0)$ because $M_0=M_0'=M$. Then, if we have defined all three up to $n\in\NN$, we increment in three steps.
	\begin{itemize}
		\item We find some $n'$ such that $M_n\supseteq M_{n'}'$. Then we can set $\alpha(n+1)=\max\{n',\alpha n+1\}$, which works because $M_{n'}'\supseteq M_{\alpha(n+1)}$ while $\alpha(n+1)>\alpha(n)$.
		\item We find some $n'$ such that $M_{\alpha(n+1)}'\supseteq M_{n'}$. Then we can set $\beta(n+1)=\max\{n',\beta n+1\}$, which works because $M_{\alpha(n+1)}'\supseteq M_{\beta(n+1)}$ while $\beta(n+1)>\beta(n)$.
		\item We find some $n'$ such that $M_{\beta(n+1)}\supseteq M_{n'}'$. Then we can set $\gamma(n+1)=\max\{n',\gamma n+1\}$, which works because $M_{\beta(n+1)}\supseteq M_{\gamma(n+1)}'$ while $\gamma(n+1)>\gamma(n)$.
	\end{itemize}
	Anyways, the point is that our $\alpha,\beta,\gamma$ induce morphisms
	\[\limit M/M'_{\gamma(j)}\to\limit M/M_{\beta(j)}\to\limit M/M'_{\alpha(j)}\to\limit M/M_j\]
	by \autoref{lem:containedfiltration}. In fact, \autoref{lem:subsequencefiltration} lets us remove the $\alpha,\beta,\gamma$ to set up the following commutative diagram.
	% https://q.uiver.app/?q=WzAsOCxbMCwwLCJcXGxpbWl0IE0vTSdfe1xcZ2FtbWEoail9Il0sWzEsMCwiXFxsaW1pdCBNL01fe1xcYmV0YShqKX0iXSxbMiwwLCJcXGxpbWl0IE0vTSdfe1xcYWxwaGEoail9Il0sWzMsMCwiXFxsaW1pdCBNL01fe2p9Il0sWzAsMSwiXFxsaW1pdCBNL01fe2p9JyJdLFsxLDEsIlxcbGltaXQgTS9NX3tqfSJdLFszLDEsIlxcbGltaXQgTS9NX3tqfSJdLFsyLDEsIlxcbGltaXQgTS9NX3tqfSciXSxbMCw0XSxbMSw1XSxbMiw3XSxbMyw2XSxbMCwxXSxbMSwyXSxbMiwzXSxbNCw1LCJmIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzUsNywiZyIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dLFs3LDYsImgiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{\limit M/M'_{\gamma(j)}} & {\limit M/M_{\beta(j)}} & {\limit M/M'_{\alpha(j)}} & {\limit M/M_{j}} \\
		{\limit M/M_{j}'} & {\limit M/M_{j}} & {\limit M/M_{j}'} & {\limit M/M_{j}}
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-3, to=2-3]
		\arrow[from=1-4, to=2-4]
		\arrow[from=1-1, to=1-2]
		\arrow[from=1-2, to=1-3]
		\arrow[from=1-3, to=1-4]
		\arrow["f", dashed, from=2-1, to=2-2]
		\arrow["g", dashed, from=2-2, to=2-3]
		\arrow["h", dashed, from=2-3, to=2-4]
	\end{tikzcd}\]
	Namely, the vertical morphisms are isomorphisms and therefore induce the morphisms on the bottom row. We claim that $gf$ and $hg$ are both the identity. Indeed, tracking through the morphisms in the commutative diagram, we see that $fg$ moves as follows.
	% https://q.uiver.app/?q=WzAsOCxbMCwwLCJcXHttX3tcXGdhbW1hIGt9K01fe1xcZ2FtbWEga30nXFx9X3trXFxpblxcTk59Il0sWzEsMCwiXFx7bV97XFxnYW1tYSBrfStNX3tcXGJldGEga31cXH1fe2tcXGluXFxOTn0iXSxbMiwwLCJcXHttX3tcXGdhbW1hIGt9K01fe1xcYWxwaGEga30nXFx9X3trXFxpblxcTk59Il0sWzMsMCwiXFxidWxsZXQiXSxbMCwxLCJcXHttX2srTV9rJ1xcfV97a1xcaW5cXE5OfSJdLFsxLDEsIlxcYnVsbGV0Il0sWzMsMSwiXFxidWxsZXQiXSxbMiwxLCJcXHttX3tcXGdhbW1hIGt9K01fe2t9J1xcfV97a1xcaW5cXE5OfSJdLFswLDRdLFsxLDVdLFsyLDddLFszLDZdLFswLDFdLFsxLDJdLFsyLDNdLFs0LDUsImYiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XSxbNSw3LCJnIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzcsNiwiaCIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{\{m_{\gamma k}+M_{\gamma k}'\}_{k\in\NN}} & {\{m_{\gamma k}+M_{\beta k}\}_{k\in\NN}} & {\{m_{\gamma k}+M_{\alpha k}'\}_{k\in\NN}} & \bullet \\
		{\{m_k+M_k'\}_{k\in\NN}} & \bullet & {\{m_{\gamma k}+M_{k}'\}_{k\in\NN}} & \bullet
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-3, to=2-3]
		\arrow[from=1-4, to=2-4]
		\arrow[from=1-1, to=1-2]
		\arrow[from=1-2, to=1-3]
		\arrow[from=1-3, to=1-4]
		\arrow["f", dashed, from=2-1, to=2-2]
		\arrow["g", dashed, from=2-2, to=2-3]
		\arrow["h", dashed, from=2-3, to=2-4]
	\end{tikzcd}\]
	This is the identity because $\gamma k\ge k$ (because $\gamma$ is strictly increasing), so $m_k+M_k'=m_{\gamma k}+M_k'$ for any $k$.
	
	Similarly, we track $hg$ as follows.
	% https://q.uiver.app/?q=WzAsOCxbMCwwLCJcXGJ1bGxldCJdLFsxLDAsIlxce21fe1xcYmV0YSBrfStNX3tcXGJldGEga31cXH1fe2tcXGluXFxOTn0iXSxbMiwwLCJcXHttX3tcXGJldGEga30rTV97XFxhbHBoYSBrfSdcXH1fe2tcXGluXFxOTn0iXSxbMywwLCJcXHttX3tcXGJldGEga30rTV97a31cXH1fe2tcXGluXFxOTn0iXSxbMCwxLCJcXGJ1bGxldCJdLFsxLDEsIlxce21faytNX2tcXH1fe2tcXGluXFxOTn0iXSxbMywxLCJcXHttX3tcXGJldGEga30rTV97a31cXH1fe2tcXGluXFxOTn0iXSxbMiwxLCJcXGJ1bGxldCJdLFswLDRdLFsxLDVdLFsyLDddLFszLDZdLFswLDFdLFsxLDJdLFsyLDNdLFs0LDUsImYiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XSxbNSw3LCJnIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzcsNiwiaCIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		\bullet & {\{m_{\beta k}+M_{\beta k}\}_{k\in\NN}} & {\{m_{\beta k}+M_{\alpha k}'\}_{k\in\NN}} & {\{m_{\beta k}+M_{k}\}_{k\in\NN}} \\
		\bullet & {\{m_k+M_k\}_{k\in\NN}} & \bullet & {\{m_{\beta k}+M_{k}\}_{k\in\NN}}
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-3, to=2-3]
		\arrow[from=1-4, to=2-4]
		\arrow[from=1-1, to=1-2]
		\arrow[from=1-2, to=1-3]
		\arrow[from=1-3, to=1-4]
		\arrow["f", dashed, from=2-1, to=2-2]
		\arrow["g", dashed, from=2-2, to=2-3]
		\arrow["h", dashed, from=2-3, to=2-4]
	\end{tikzcd}\]
	Again, this is the identity because $\beta k\ge k$ everywhere implies that $m_k+M_k=m_{\beta k}+M_k$ for any $k$.

	Thus, we see that $g$ is a morphism with both a left and a right inverse, so it is an isomorphism. (For example, a left inverse shows that $g$ is injective, and a right inverse shows that $g$ is surjective.) This is what we wanted to prove, so we are done.
\end{proof}
\begin{remark}[Nir]
	Another way to prove \autoref{lem:samecompletion} is to note that both filtrations will induce the same topology on $M$ and therefore will be isomorphic as completions.
\end{remark}

\subsection{Completion for Modules}
We now return to talking about completions. We want to show that $\widehat R_I$ is flat, so we will want to talk about short exact sequences.
\begin{lemma}
	Fix $R$ a Noetherian ring and an ideal $I$. Further, suppose that we have a short exact sequence
	\[0\to A\to B\to C\to 0\]
	of finitely generated $R$-modules. Then we have a short exact sequence
	\[0\to\widehat A\to\widehat B\to\widehat C\to0\]
	of completions.
\end{lemma}
\begin{proof}
	We start with the short exact sequence
	\[0\to A\to B\to C\to 0\]
	and tensor by $-\otimes R/I^s$ to get a right-exact sequence
	\[A/I^sA\to B/I^sB\to C/I^sC\to0.\]
	We can show by hand that this gives us a surjection $\widehat B\onto\widehat C$, but we need this to be exact on the left. Well, the next best thing that we can write down is
	\[0\to\frac A{A\cap I^sB}\to\frac B{I^sB}\to\frac C{I^sC},\]
	so because taking inverse limits is left exact, we have a left-exact sequence
	\[0\to\limit\frac A{A\cap I^sB}\to\limit\frac B{I^sB}\to\limit\frac C{I^sC}.\]
	It remains to show that our left term is $\widehat A$. Well, by the Artin--Rees lemma (!), we see that the filtration
	\[A\cap I^sB\]
	is an $I$-stable filtration. In other words, there is an $n$ such that $I^k(A\cap I^nB)=A\cap I^{n+k}B\subseteq I^kA$ for sufficiently large $k$. Applying \autoref{lem:samecompletion} finishes.
\end{proof}
The point of this is that we see completion is an exact functor. In fact, as with localization, there is a flat module hiding in the background.
\completetensor*
\begin{proof}
	So we show (a). If $M\cong R$, then we are done. Because tensoring and completion commutes with taking direct sums, we see that (a) remains true for $M\cong R^n$ for $n\in\NN$. Otherwise, because we live in a Noetherian world, $M$ is finitely presented, so we have a right-exact sequence
	\[G\to F\to M\to 0\]
	where $F$ and $G$ are both free of finite rank. Tensoring with $\widehat R_I$, we see that
	\[G\otimes_R\widehat R_I\to G\otimes_R\widehat R_I\to M\otimes_R\widehat R\to0.\]
	We also have the short exact sequence
	\[\widehat G_I\to\widehat F_I\to\widehat M_I\to0,\]
	so we slap them on top of each other to build the following diagram.
	% https://q.uiver.app/?q=WzAsOCxbMCwwLCJHXFxvdGltZXNfUlxcd2lkZWhhdCBSX0kiXSxbMSwwLCJGXFxvdGltZXNfUlxcd2lkZWhhdCBSX0kiXSxbMiwwLCJNXFxvdGltZXNfUlxcd2lkZWhhdCBSX0kiXSxbMCwxLCJcXHdpZGVoYXQgR19JIl0sWzEsMSwiXFx3aWRlaGF0IEZfSSJdLFsyLDEsIlxcd2lkZWhhdCBNX0kiXSxbMywwLCIwIl0sWzMsMSwiMCJdLFswLDFdLFsxLDJdLFsyLDZdLFszLDRdLFs0LDVdLFs1LDddLFswLDNdLFsxLDRdLFsyLDVdXQ==
	\[\begin{tikzcd}
		{G\otimes_R\widehat R_I} & {F\otimes_R\widehat R_I} & {M\otimes_R\widehat R_I} & 0 \\
		{\widehat G_I} & {\widehat F_I} & {\widehat M_I} & 0
		\arrow[from=1-1, to=1-2]
		\arrow[from=1-2, to=1-3]
		\arrow[from=1-3, to=1-4]
		\arrow[from=2-1, to=2-2]
		\arrow[from=2-2, to=2-3]
		\arrow[from=2-3, to=2-4]
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-3, to=2-3]
	\end{tikzcd}\]
	In particular, the two left maps are isomorphisms, so the right map is also an isomorphism by the Snake lemma.

	We now show (b). We would like to use the previous lemma, but it only works for finitely generated modules instead of general short exact sequences. But have no fear---it suffices to show that the natural inclusion
	\[J\otimes_R\widehat R_I\to\widehat R_I\]
	is an inclusion for any finitely generated $J$ by our flatness criterion, % \todo{}
	which we do have, so we are done.
\end{proof}
\begin{remark}[Nir]
	It is in fact necessary that $M$ be finitely generated. For example, take $R=\ZZ$ and $I=(p)$ and $M=\QQ$. In this case, $\widehat R_I\otimes_RM=\QQ_p$, but $\widehat M_I=0$ because $M/I^sM=\QQ/\left(p^s\right)\QQ=\QQ/\QQ=0$ for all $s$.
\end{remark}

\subsection{Examples of Hensel's Lemma}
Let's continue talking about number theory. Hensel's lemma is a way to lift solutions to polynomial equations from quotients up to complete rings. More precisely, we have the following.
\begin{theorem}[Hensel's lemma] \label{thm:hensel}
	Suppose that $R$ is a ring complete with respect to an $I$-adic filtration, and pick up a polynomial $f(x)\in R[x]$. Now, suppose we have $a\in R$ such that
	\[f(a)\equiv0\pmod{f'(a)^2I}.\]
	Then there exists $b\in R$ such that $b\equiv a\pmod{f'(a)m}$ and $f(b)=0$.
\end{theorem}
We do a few examples before proving the lemma.
\begin{exe}
	We solve for $x\in k[[t]]$ in the equation $x^2=1+t$, where $k[[t]]$ is complete with respect to $(t)$.
\end{exe}
\begin{proof}
	Note that $x_0=1$ is a solution in $R/(t)$. So we hope that we can find a solution $u\in k[[t]]$ such that $u\equiv1\pmod t$ such that $u^2=1+t$. Well, from the general binomial theorem, we can write
	\[\sqrt{1+t}=\sum_{k=0}^\infty\binom{1/2}kt^k.\]
	We can check that this works.
\end{proof}
\begin{exe}
	Fix $a\in\ZZ_p$ for an odd prime $p$. We discuss when we can solve $x^2\equiv a$.
\end{exe}
\begin{proof}
	If $a=0$, then we are done. Otherwise, write $a=bp^n$ where $b\in\ZZ_p\setminus p\ZZ_p$. If $n$ is odd, there is no solution; so we let $n=2k$ and write
	\[\left(x/p^k\right)^2=b,\]
	so we are solving $y^2=b$, where $b\in\ZZ_p\setminus p\ZZ_p$. Now, if a solution is to exist, then we require $b\pmod p$ to be a perfect square, so find $x_0\in\FF_p$ such that 
	\[x_0^2\equiv b\pmod p.\]
	To check that we can lift by Hensel's lemma, we need to check the derivative, but when $p$ is odd, then our derivative is $2x_0$, which is nonzero because $x_0$ is nonzero.

	Let's actually show how we can solve this. Well, expand out $x$ in a $p$-adic series as
	\[\left(\sum_{k=0}^\infty x_kp^k\right)^2=b=:\sum_{k=0}^\infty b_kp^k.\]
	We already have $x_0$. For $x_1$, we check the linear term to find
	\[2x_0x_1\equiv b_1\pmod p,\]
	from which we extract $b_1$. More generally, this term reads as
	\[x_0x_n+\sum_{k=1}^nx_kx_{n-k}=b_n,\]
	from which we can solve for $x_n$ recursively.
\end{proof}
\begin{exe}
	We show that $x^2=b$ has a solution in $\ZZ_2$ if $b$ is an odd perfect square$\pmod8$. In other words, we require $b\equiv1\pmod8$.
\end{exe}
\begin{proof}
	Simply use Hensel's lemma, but now $f'(a)^2\cdot2$ is divisible by a factor of $8$.
\end{proof}

\subsection{Proof of Hensel's Lemma}
With sufficient motivation, we now turn to a proof of \autoref{thm:hensel}. We have the following universal property.
\begin{proposition}
	Fix $S$ an $R$-algebra such that $S$ is complete with respect to an ideal $I\subseteq S$. If $I=(f_1,\ldots,f_n)$ is finitely generated, then there is a unique homomorphism
	\[\varphi:R[[x_1,\ldots,x_n]]\to S\]
	such that $x_\bullet\mapsto f_\bullet$, and $\varphi$ is continuous under the induced $I$-adic topology. In fact, the following hold.
	\begin{itemize}
		\item If $R\to S/I$ is surjective, then $\varphi$ is surjective.
		\item If the induced map $R[x_1,\ldots,x_n]\to\op{gr}_IS$, then $\varphi$ is injective.
	\end{itemize}
\end{proposition}
\begin{remark}
	This is intended to be an analog for the universal property of polynomial algebras.
\end{remark}
\begin{proof}
	To construct $\varphi$, it suffices to note that $R[[x_1,\ldots,x_n]]$ is the completion of $R[x_1,\ldots,x_n]$ with respect to the ideal $\mf m=(x_1,\ldots,x_n)$ and then construct a system of maps
	\[\varphi_k:\frac{R[x_1,\ldots,x_n]}{\mf m^k}\to\frac S{I^k}.\]
	Alternatively, we can note that the restricted map on $R[x_1,\ldots,x_n]\to S$ is forced and use continuity to fill in for the rest of $R[[x_1,\ldots,x_n]]$.

	For the surjectivity check, we note that we can lift to
	\[\varphi_k:\frac{R[x_1,\ldots,x_n]}{\mf m^k}\to\frac S{I^k}\]
	is surjective, so going to the completion provides the result.

	Lastly, we note that the condition tells us that
	\[\bigcap_iI^i=0\implies\bigcap\mf m^i=0.\]
	To finish our injectivity check, we note more generally that if $\varphi:A\to B$ is a map of filtered algebras, then we can build an associated map $\op{gr}\varphi:\op{gr}A\to\op{gr}B$. Then if $\op{gr}\varphi$ is injective (as seen above), then $\varphi$ is also injective. This gives the result after some care.
\end{proof}
\begin{corollary}
	Fix $\varphi:R[[x]]\to R[[x]]$ some morphism. Further, find $f\in(x)$ such that $f\equiv x\pmod{x^2}$. Then if $\varphi(x)=f$ and $\varphi(r)=r$ for $r\in R$, then $\varphi$ is an isomorphism.
\end{corollary}
\begin{proof}
	Use the previous lemma to construct $\varphi$ and then run the previous surjectivity and injectivity check.
\end{proof}
\begin{remark}
	In fact, there is an explicit inverse map for this $\varphi$.
\end{remark}
We are now ready to prove \autoref{thm:hensel}.
\begin{proof}[Proof of \autoref{thm:hensel}]
	We use Newton's lemma to build our solution $b$. For ease of mind, we set $e:=f'(a)$ so that we know
	\[f(a)\equiv0\pmod{e^2m}.\]
	Now, we can write $f(a+ex)$, which upon expansion via the binomial theorem looks like
	\[f(a+ex)=f(a)+f'(a)ex+h(x)(ex)^2\]
	for some $h\in R[x]$. Using $f'(a)=e$, we get
	\[f(a+ex)=f(a)+e^2\left(x+x^2h(x)\right).\]
	Now, consider the homomorphism $\varphi:R[[x]]\to R[[x]]$ by $\varphi(x):=x+x^2h(x)$, but the previous corollary tells us that $\varphi$ is an isomorphism! So we see
	\[f\left(a+e\varphi^{-1}(x)\right)=f(a)+e^2x\]
	by plugging in. To finish, we build $\psi:R[[x]]\to R$ by $\psi(x)=-c$, where $f(a)=e^2c$ and can compute that
	\[f\left(a+e\psi\varphi^{-1}(x)\right)=f(a)-e^2c=0,\]
	which finishes.
\end{proof}
\begin{remark}
	We can show that the solution above is unique, provided that $f'(a)$ is not a zero-divisor. We will omit this proof.
\end{remark}
% \begin{center}
% 	\begin{asy}
% 		import graph;
% 		unitsize(4cm);
% 		real f(real x)
% 		{
% 			return x*x*x - x + 0.1;
% 		}
% 		draw((-0.6,0)--(2,0)); draw((0,-0.6)--(0,2));
% 		draw(graph(f,-0.6,1.5), blue);

% 		real a0 = 1.3;
% 		real a1 = a0 - (a0*a0*a0 - a0) / (3*a0*a0 - 1);

% 		pair v = (a0, f(a0)) - (a1, 0);
% 		draw((a1, 0) -- (a1, 0) + 1.8*v, red);

% 		draw((a0,0) -- (a0,f(a0)), dashed);
% 		draw((a1,0) -- (a1,f(a1)), dashed);

% 		dot("$x_0$", (a0,0), S); dot("$x_1$", (a1, 0), S);

% 		dot("$(x_0,f(x_0))$", (a0, f(a0)), WNW);
% 		dot("$(x_{1},f(x_{1}))$", (a1, f(a1)), WNW);

% 		label("\color{red}$y-f(x_0)=f'(x_0)(x-x_0)$", (a1,0) + 1.5*v, W);
% 	\end{asy}
% \end{center}