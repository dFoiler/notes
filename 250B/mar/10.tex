% !TEX root = ../notes.tex

We continue discussing completion.

\subsection{Completion for Modules}
Recall that we had a notion of completion for modules as follows.
\begin{definition}[Completion, modules]
	Fix $R$ a ring and $M$ a module with a filtration $\mathcal J$ given by
	\[M=M_0\supseteq M_1\supseteq M_2\supseteq\cdots.\]
	Then we define the \textit{completion} as the inverse limit $\limit M/M_i$.
\end{definition}
Here is our primary example.
\begin{example}
	If we fix an ideal $I\subseteq R$, then we are granted an $I$-adic filtration of $M$, which gives the $I$-adic completion of $M$. In particular, this is an $\widehat R_I$-module.
\end{example}
Here is a nice lemma.
\begin{lemma} \label{lem:samecompletion}
	Suppose we have two filtrations of an $R$-module $M$ given by $\mathcal J$
	\[M\supseteq M_1\supseteq M_2\supseteq\cdots\]
	and $\mathcal J'$ given by
	\[M\supseteq M_1'\supseteq M_2'\supseteq\cdots.\]
	Further, suppose that, for all $i$, there exists $j$ such that $M_i\supseteq M_j'$ and perhaps another $j$ such that $M_i'\supseteq M_j'$. Then we have an isomorphism
	\[\limit M/M_i\cong\limit M/M_i'\]
\end{lemma}
\begin{remark}
	Of course, any subsequence of a filtration $\mathcal J$ will give rises to the same inverse limit. Intuitively, this is fairly clear because any given term in the inverse limit is just some sequence where earlier terms are fixed by later ones, so we can just build the isomorphism explicitly.
\end{remark}
\begin{proof}
	In general, if we have two inverse limits, the way to define an inverse limit is to define a map into each of the components. To manifest this idea, we pick up strictly increasing $\alpha,\beta,\gamma:\NN\to\NN$ such that
	\[M_j\supseteq N_{\alpha(j)}\supseteq M_{\beta(j)}\supseteq N_{\gamma(j)}.\tag{$*$}\label{eq:inclusions}\]
	These embeddings give us surjections
	\[M/N_{\gamma(j)}\onto M/M_{\beta(j)}\onto M/M_{\alpha(j)}\onto M/M_j.\]
	This gives rise to morphisms
	\[\limit M/N_{\gamma(j)}\to\limit M/M_{\beta(j)}\to\limit M/M_{\alpha(j)}\to\limit M/M_j.\]
	Now, these are subsequences, so the terms are isomorphic to the terms without the injective functions, so we get morphisms
	\[\limit M/N_j\to\limit M/M_j\to\limit M/M_j\to\limit M/M_j.\]
	We can check by hand that the composite of any consecutive map is the identity by tracking through \autoref{eq:inclusions} on the inclusions $M_j\subseteq M_{\beta(j)}$ and $N_{\alpha(j)}\subseteq N_{\gamma(j)}$. This provides us with our isomorphisms.
\end{proof}
Here is another lemma which we will want for abstract nonsense reasons.
\begin{lemma}
	Fix $R$ a Noetherian ring and an ideal $I$. Further, suppose that we have a short exact sequence
	\[0\to A\to B\to C\to 0\]
	of finitely generated $R$-modules. Then we have a short exact sequence
	\[0\to\widehat A\to\widehat B\to\widehat C\to0\]
	of completions.
\end{lemma}
\begin{proof}
	We start with the short exact sequence
	\[0\to A\to B\to C\to 0\]
	and tensor by $-\otimes R/I^s$ to get a right-exact sequence
	\[A/I^sA\to B/I^sB\to C/I^SC\to0.\]
	We can show by hand that this gives us a surjection $\widehat B\onto\widehat C$, but we need this to be exact on the left. Well, the next best thing that we can write down is
	\[0\to\frac A{A\cap I^sB}\to\frac B{I^sB}\to\frac C{I^sC},\]
	so because taking inverse limits is left exact, we have a left-exact sequence
	\[0\to\limit\frac A{A\cap I^sB}\to\limit\frac B{I^sB}\to\limit\frac C{I^sB}.\]
	It remains to show that our left term is $\widehat A$. Well, by the Artin--Rees lemma (!), we see that the filtration
	\[A\cap I^sB\]
	is an $I$-stable filtration. In other words, there is an $n$ such that $I^k(A\cap I^nB)=A\cap I^{n+k}B\subseteq I^kA$ for sufficiently large $k$. Applying \autoref{lem:samecompletion} finishes.
\end{proof}
The point of this is that we see completion is an exact functor. In fact, as with localization, there is a flat module hiding in the background.
\begin{theorem}
	Fix $R$ a Noetherian ring with an ideal $I\subseteq R$ and $M$ a finitely generated $R$-module.
	\begin{listalph}
		\item We have that $\widehat M_I\cong\widehat R_I\otimes_RM$, and this isomorphism is natural in $M$.
		\item We have that $\widehat R_I$ is a flat $R$-module.
	\end{listalph}
\end{theorem}
\begin{proof}
	So we show (a). If $M\cong R$, then we are done. Because tensoring and completion commutes with taking direct sums, we see that (a) remains true for $M\cong R^n$ for $n\in\NN$. Otherwise, because we live in a Noetherian world, $M$ is finitely presented, so we have a right-exact sequence
	\[G\to F\to M\to 0\]
	where $F$ and $G$ are both free of finite rank. Tensoring with $\widehat R_I$, we see that
	\[G\otimes_R\widehat R_I\to G\otimes_R\widehat R_I\to M\otimes_R\widehat R\to0.\]
	We also have the short exact sequence
	\[\widehat G_I\to\widehat F_I\to\widehat M_I\to0,\]
	so we slap them on top of each other to build the following diagram.
	% https://q.uiver.app/?q=WzAsOCxbMCwwLCJHXFxvdGltZXNfUlxcd2lkZWhhdCBSX0kiXSxbMSwwLCJGXFxvdGltZXNfUlxcd2lkZWhhdCBSX0kiXSxbMiwwLCJNXFxvdGltZXNfUlxcd2lkZWhhdCBSX0kiXSxbMCwxLCJcXHdpZGVoYXQgR19JIl0sWzEsMSwiXFx3aWRlaGF0IEZfSSJdLFsyLDEsIlxcd2lkZWhhdCBNX0kiXSxbMywwLCIwIl0sWzMsMSwiMCJdLFswLDFdLFsxLDJdLFsyLDZdLFszLDRdLFs0LDVdLFs1LDddLFswLDNdLFsxLDRdLFsyLDVdXQ==
	\[\begin{tikzcd}
		{G\otimes_R\widehat R_I} & {F\otimes_R\widehat R_I} & {M\otimes_R\widehat R_I} & 0 \\
		{\widehat G_I} & {\widehat F_I} & {\widehat M_I} & 0
		\arrow[from=1-1, to=1-2]
		\arrow[from=1-2, to=1-3]
		\arrow[from=1-3, to=1-4]
		\arrow[from=2-1, to=2-2]
		\arrow[from=2-2, to=2-3]
		\arrow[from=2-3, to=2-4]
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-3, to=2-3]
	\end{tikzcd}\]
	In particular, the two left maps are isomorphisms, so the right map is also an isomorphism by the Snake lemma.

	We now show (b). We would like to use the previous lemma, but it only works for finitely generated modules instead of general short exact sequences. But have no fear---it suffices to show that the natural inclusion
	\[J\otimes_R\widehat R_I\to\widehat R_I\]
	is an inclusion for any finitely generated $J$ by our flatness criterion, % \todo{}
	which we do have, so we are done.
\end{proof}

\subsection{Examples of Hensel's Lemma}
Let's continue talking about number theory. Hensel's lemma is a way to lift solutions to polynomial equations from quotients up to complete rings. More precisely, we have the following.
\begin{theorem}[Hensel's lemma] \label{thm:hensel}
	Suppose that $R$ is a ring complete with respect to an $I$-adic filtration, and pick up a polynomial $f(x)\in R[x]$. Now, suppose we have $a\in R$ such that
	\[f(a)\equiv0\pmod{f'(a)^2m}.\]
	Then there exists $b\in R$ such that $b\equiv a\pmod{f'(a)m}$ and $f(b)=0$.
\end{theorem}
We do a few examples before proving the lemma.
\begin{exe}
	We solve $x^2=1+t$ in $R[[t]]$, where $k[[t]]$ is complete with respect to $(t)$.
\end{exe}
\begin{proof}
	Note that $x_0=1$ is a solution in $R/(t)$. So we hope that we can find a solution $u\in k[[t]]$ such that $u\equiv1\pmod t$ such that $u^2=1+t$. Well, from the general binomial theorem, we can write
	\[\sqrt{1+t}=\sum_{k=0}^\infty\binom{1/2}kt^k.\]
	We can check that this works.
\end{proof}
\begin{exe}
	Fix $a\in\ZZ_p$ for an odd prime $p$. We discuss when we can solve $x^2\equiv a$.
\end{exe}
\begin{proof}
	If $a=0$, then we are done. Otherwise, write $a=bp^n$ where $b\in\ZZ_p\setminus p\ZZ_p$. If $n$ is odd, there is no solution; so we let $n=2k$ and write
	\[\left(x/p^k\right)^2=b,\]
	so we are solving $y^2=b$, where $b\in\ZZ_p\setminus p\ZZ_p$. Now, if a solution is to exist, then we require $b\pmod p$ to be a perfect square, so find $x_0\in\FF_p$ such that 
	\[x_0^2\equiv b\pmod p.\]
	To check that we can lift by Hensel's lemma, we need to check the derivative, but when $p$ is odd, then our derivative is $2x_0$, which is nonzero because $x_0$ is nonzero.

	Let's actually show how we can solve this. Well, expand out $x$ in a $p$-adic series as
	\[\left(\sum_{k=0}^\infty x_kp^k\right)^2=b=:\sum_{k=0}^\infty b_kp^k.\]
	We already have $x_0$. For $x_1$, we check the linear term to find
	\[2x_0x_1\equiv b_1\pmod p,\]
	from which we extract $b_1$. More generally, this term reads as
	\[x_0x_n+\sum_{k=1}^nx_kx_{n-k}=b_n,\]
	from which we can solve for $x_n$ recursively.
\end{proof}
\begin{exe}
	We show that $x^2=b$ has a solution in $\ZZ_2$ if $b$ is an odd perfect square$\pmod8$. In other words, we require $b\equiv1\pmod8$.
\end{exe}
\begin{proof}
	Simply use Hensel's lemma, but now $f'(a)^2\cdot2$ is divisible by a factor of $8$.
\end{proof}

\subsection{Proof of Hensel's Lemma}
With sufficient motivation, we now turn to a proof of \autoref{thm:hensel}. We have the following universal property.
\begin{proposition}
	Fix $S$ an $R$-algebra such that $S$ is complete with respect to an ideal $I\subseteq S$. If $I=(f_1,\ldots,f_n)$ is finitely generated, then there is a unique homomorphism
	\[\varphi:R[[x_1,\ldots,x_n]]\to S\]
	such that $x_\bullet\mapsto f_\bullet$, and $\varphi$ is continuous under the induced $I$-adic topology. In fact, the following hold.
	\begin{itemize}
		\item If $R\to S/I$ is surjective, then $\varphi$ is surjective.
		\item If the induced map $R[x_1,\ldots,x_n]\to\op{gr}_IS$, then $\varphi$ is injective.
	\end{itemize}
\end{proposition}
\begin{remark}
	This is intended to be an analog for the universal property of polynomial algebras.
\end{remark}
\begin{proof}
	To construct $\varphi$, it suffices to note that $R[[x_1,\ldots,x_n]]$ is the completion of $R[x_1,\ldots,x_n]$ with respect to the ideal $\mf m=(x_1,\ldots,x_n)$ and then construct a system of maps
	\[\varphi_k:\frac{R[x_1,\ldots,x_n]}{\mf m^k}\to\frac S{I^k}.\]
	Alternatively, we can note that the restricted map on $R[x_1,\ldots,x_n]\to S$ is forced and use continuity to fill in for the rest of $R[[x_1,\ldots,x_n]]$.

	For the surjectivity check, we note that we can lift to
	\[\varphi_k:\frac{R[x_1,\ldots,x_n]}{\mf m^k}\to\frac S{I^k}\]
	is surjective, so going to the completion provides the result.

	Lastly, we note that the condition tells us that
	\[\bigcap_iI^i=0\implies\bigcap\mf m^i=0.\]
	To finish our injectivity check, we note more generally that if $\varphi:A\to B$ is a map of filtered algebras, then we can build an associated map $\op{gr}\varphi:\op{gr}A\to\op{gr}B$. Then if $\op{gr}\varphi$ is injective (as seen above), then $\varphi$ is also injective. This gives the result after some care.
\end{proof}
\begin{corollary}
	Fix $\varphi:R[[x]]\to R[[x]]$ some morphism. Further, find $f\in(x)$ such that $f\equiv x\pmod{x^2}$. Then if $\varphi(x)=f$ and $\varphi(r)=r$ for $r\in R$, then $\varphi$ is an isomorphism.
\end{corollary}
\begin{proof}
	Use the previous lemma to construct $\varphi$ and then run the previous surjectivity and injectivity check.
\end{proof}
\begin{remark}
	In fact, there is an explicit inverse map for this $\varphi$.
\end{remark}
We are now ready to prove \autoref{thm:hensel}.
\begin{proof}[Proof of \autoref{thm:hensel}]
	We use Newton's lemma to build our solution $b$. For ease of mind, we set $e:=f'(a)$ so that we know
	\[f(a)\equiv0\pmod{e^2m}.\]
	Now, we can write $f(a+ex)$, which upon expansion via the binomial theorem looks like
	\[f(a+ex)=f(a)+f'(a)ex+h(x)(ex)^2\]
	for some $h\in R[x]$. Using $f'(a)=e$, we get
	\[f(a+ex)=f(a)+e^2\left(x+x^2h(x)\right).\]
	Now, consider the homomorphism $\varphi:R[[x]]\to R[[x]]$ by $\varphi(x):=x+x^2h(x)$, but the previous corollary tells us that $\varphi$ is an isomorphism! So we see
	\[f\left(a+e\varphi^{-1}(x)\right)=f(a)+e^2x\]
	by plugging in. To finish, we build $\psi:R[[x]]\to R$ by $\psi(x)=-c$, where $f(a)=e^2c$ and can compute that
	\[f\left(a+e\psi\varphi^{-1}(x)\right)=f(a)-e^2c=0,\]
	which finishes.
\end{proof}
\begin{remark}
	We can show that the solution above is unique, provided that $f'(a)$ is not a zero-divisor. We will omit this proof.
\end{remark}
% \begin{center}
% 	\begin{asy}
% 		import graph;
% 		unitsize(4cm);
% 		real f(real x)
% 		{
% 			return x*x*x - x + 0.1;
% 		}
% 		draw((-0.6,0)--(2,0)); draw((0,-0.6)--(0,2));
% 		draw(graph(f,-0.6,1.5), blue);

% 		real a0 = 1.3;
% 		real a1 = a0 - (a0*a0*a0 - a0) / (3*a0*a0 - 1);

% 		pair v = (a0, f(a0)) - (a1, 0);
% 		draw((a1, 0) -- (a1, 0) + 1.8*v, red);

% 		draw((a0,0) -- (a0,f(a0)), dashed);
% 		draw((a1,0) -- (a1,f(a1)), dashed);

% 		dot("$x_0$", (a0,0), S); dot("$x_1$", (a1, 0), S);

% 		dot("$(x_0,f(x_0))$", (a0, f(a0)), WNW);
% 		dot("$(x_{1},f(x_{1}))$", (a1, f(a1)), WNW);

% 		label("\color{red}$y-f(x_0)=f'(x_0)(x-x_0)$", (a1,0) + 1.5*v, W);
% 	\end{asy}
% \end{center}