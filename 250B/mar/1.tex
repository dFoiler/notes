% !TEX root = ../notes.tex

Welcome back everyone. The average and median for the exam was 32/50.

\subsection{Krull's Intersection Theorem}
Last time we showed the following.
\krullintersectii*
\noindent The Noetherian condition is necessary here; consider the following example.
\begin{exe}
	Let $R$ consist of the ring of germs of infinitely differentiable functions $f:\RR\to\RR$ at $0$. Namely, two functions $f,g:\RR\to\RR$ are equivalent in $R$ if and only if they coincide on an open neighborhood around $0$. Then $R$ is local with unique maximal ideal
	\[\mf m:=\{f\in R:f(0)=0\}.\]
	However,
	\[\bigcap_{s\ge0}\mf m^s\]
	is nonzero.
\end{exe}
\begin{proof}
	We start with the checks on $R$.
	\begin{itemize}
		\item We describe how to check that $R$ is actually a ring, but we will not do so. To begin, the set of infinitely differentiable functions $C^\infty(\RR)$ is a ring with addition and multiplicative defined pointwise; e.g., our identity is $f\equiv1$. Then we define the ideal
		\[I=\{f:f(x)=0\text{ for all }x\in U\text{ for some open }U\text{ containing }0\}.\]
		It is not hard to check that $I$ is an ideal: if $f,g\in I$ and $r,s\in C^\infty(\RR)$ with $f|_U=0$ and $g|_V=0$ where $0\in U\cap V$, then $(rf+sg)|_{U\cap V}=0$.

		Now, we simply define $R:=C^\infty(\RR)/I$. In particular, $[f]_I=[g]_I$ for $f,g\in C^\infty(\RR)$ if and only if $(f-g)$ vanishes on some neighborhood $U$ of $0$, which is equivalent to $f$ and $g$ agreeing on some neighborhood $U$ of $0$.

		\item We check that $R$ is local with the given maximal ideal $\mf m$. For this, we show that all elements outside $\mf m$ are units, which will be enough because it will show that any proper ideal (which only contains non-units) is contained in $\mf m$.

		Indeed, pick up some $u\notin\mf m$ so that $u(0)\ne1$. Because $u$ is continuous, $u(\RR\setminus\{0\})$ is open and contains $0$, so there exists an $\varepsilon>0$ such that $u$ is nonzero on the compact set $[-\varepsilon,\varepsilon]$. Then $1/u$ is an infinitely differentiable function $v$ on $(-\varepsilon,\varepsilon)$, which we can then extend to a function in $C^\infty(\RR)$.\footnote{I think some kind of uniformity condition is needed here to make sure that $1/u$ can be extended as claimed, but I won't bother making this rigorous.} So indeed, $uv$ agrees with the function $1$ on $(-\varepsilon,\varepsilon)$, so $uv\equiv1\pmod I$.
	\end{itemize}
	It remains to check that
	\[\bigcap_{s\ge0}\mf m^s\ne0.\]
	Indeed, set, for given $m$,
	\[g_m(x):=\begin{cases}
		e^{-1/x^2}/x^m & x\ne0, \\
		0 & x=0.
	\end{cases}\]
	An induction shows that, on $\RR\setminus\{0\}$, we have $g_m^{(n)}(x)=p_n(1/x)e^{-1/x^2}$ some $p_n\in\QQ[x]$, for any $n\ge0$. Indeed, it holds for $n=0$ by taking $p_0(x)=x^m$, and the inductive step merely needs to write
	\[g_m^{(n+1)}(x)=\frac d{dx}g_m^{(n)}(x)=\frac d{dx}p_n(1/x)e^{-1/x^2}=\underbrace{\left(p_n'\left(\frac1x\right)\cdot-\frac1{x^2}+\frac{-2}{x^3}\right)}_{p_{n+1}(1/x)}e^{-1/x^2}.\]
	Thus, we can show by induction that $g^{(n)}_m(0)=0$ for each $0$. We get $n=0$ for free, and otherwise, we compute
	\[g_m^{(n+1)}(0)=\lim_{x\to0}\frac{g_m^{(n)}(x)-g_m^{(n)}(0)}x=\lim_{h\to0}\left(\frac{p_n(1/x)}x\cdot e^{-1/x^2}\right)=\lim_{x\to\pm\infty}\frac{xp_n(x)}{e^{-x^2}},\]
	which vanishes no matter which $\pm\infty$ we approach. So in total, we see that $g\in C^\infty(\RR)$, so it will produce a legal germ at $0$.
	
	It follows that $e^{-1/x^2}/x^m=g_m(x)\in C^\infty(\RR)$ for each $m$. To finish, we see that
	\[e^{-1/x^2}=x^m\cdot e^{-1/x^2}/x^m\in\mf m^mC^\infty(\RR)\subseteq\mf m^m\]
	for any $m$, which is what we wanted.
\end{proof}
\begin{remark}[Nir]
	The finite generation is also necessary: the module $M=\QQ$ over the integral domain $R=\ZZ$ has $I=(2)\subseteq\ZZ$ a proper ideal while $IM=(2)\QQ=\QQ$ so that $\bigcap_sI^sM=M$. We are essentially detecting a counterexample to Nakayama's lemma here.
\end{remark}
% Finitely generated M is also necessary: Take R = Z and M = Q and I = (2)

\subsection{Flat Modules}
Today we are talking about flatness and $\op{Tor}$. Let's start with flatness; we recall the definition.
\flatdefi*
\noindent As we discussed in \autoref{rem:easierflat}, because $M\otimes_R-$ is already left-exact, we merely have to check that $N\into N'$ induces an injection $M\otimes_RN\into M\otimes_RN'$.

We now run through some examples of flat modules.
\begin{example}
	We showed back in \autoref{ex:freeisflat} that $R^n$ is a flat $R$-module. Essentially this is because $R^n\otimes A\simeq(R\otimes A)^n\simeq M^n$ (functorially), so injections $A\into B$ remain injections $A^n\into B^n$.
\end{example}
\begin{example}
	For any multiplicative set $U\subseteq R$, the module $R\left[U^{-1}\right]$ is flat, as we showed in \autoref{cor:localflat}. For example, $\QQ$ is flat as a $\ZZ$-module.
\end{example}
\begin{remark}
	As a small aside, we note that \autoref{prop:localexact} only says that $R\left[U^{-1}\right]\otimes-:\mathrm{Mod}_R\to\mathrm{Mod}_{R\left[U^{-1}\right]}$ takes short exact sequences in $\mathrm{Mod}_R$ to short exact sequences in $\mathrm{Mod}_{R\left[U^{-1}\right]}$, but this restricts to $R$-modules just fine (even when $R\to R\left[U^{-1}\right]$ is not injective). To be explicit, given $A\into B$ in $\mathrm{Mod}_R$, the fact that the map
	\[A\otimes_RR\left[U^{-1}\right]\to B\otimes_RR\left[U^{-1}\right]\]
	is injective does not matter if we are looking in the category $\mathrm{Mod}_{R\left[U^{-1}\right]}$ or $\mathrm{Mod}_R$.
\end{remark}
And let's see a non-example.
\begin{exe}
	For any positive integer $n>1$, the module $\ZZ/n\ZZ$ is not flat in the category of $\ZZ$-modules.
\end{exe}
\begin{proof}
	We witness this with a specific short exact sequence. For our purposes, we will take
	\[0\to\ZZ\stackrel{\times n}\to\ZZ\to\ZZ/n\ZZ\to0.\]
	We now claim that the induced sequence
	\[0\to\ZZ\otimes_\ZZ\ZZ/n\ZZ\stackrel{\times n}\to\ZZ\otimes_\ZZ\ZZ/n\ZZ\to\ZZ/n\ZZ\to0\]
	is not exact. In particular, we need to show that the induced map $\varphi:\ZZ\otimes_\ZZ\ZZ/n\ZZ\stackrel{\times n}\to\ZZ\otimes_\ZZ\ZZ/n\ZZ$ is not injective. Well, we note $\ZZ\otimes_\ZZ\ZZ/n\ZZ\cong\ZZ/n\ZZ$ by $1\otimes[k]_n\mapsto[k]_n$, so we note $1\otimes[1]_n$ is a nonzero element (it goes to $[1]_n$ under the isomorphism) and that
	\[\varphi(1\otimes[1]_n)=1\otimes n[1]_n=1\otimes[0]_n\]
	is $0$ in $\ZZ\otimes_\ZZ\ZZ/n\ZZ$.
\end{proof}

\subsection{Projective Modules}
For our next example of flat modules, we will want to talk about projective modules. Before doing, so we should discuss what it means for a short exact sequence to split.
\begin{definition}[Splits] \label{def:splits}
	Fix a short exact sequence of $R$-modules
	\[0\to A\to B\stackrel\pi\to C\to0.\]
	Then we say that this short exact sequence \textit{splits} if and only if there is a ``lift'' $\varphi:C\to B$ such that $\pi\circ\varphi=\id_C$.
\end{definition}
Here are a few equivalent conditions.
\begin{lemma} \label{lem:splitgrabbag}
	Fix a short exact sequence of $R$-modules.
	\[0\to A\stackrel\iota\to B\stackrel\pi\to C\to0.\]
	Then the following are equivalent.
	\begin{listalph}
		\item The short exact sequence splits, in the sense of \autoref{def:splits}.
		\item There is an isomorphism $\psi:A\oplus C\to B$ such that the following diagram commutes, where the bottom row has the canonical inclusion and projection.
		% https://q.uiver.app/?q=WzAsMTAsWzAsMCwiMCJdLFsxLDAsIkEiXSxbMiwwLCJBXFxvcGx1cyBDIl0sWzMsMCwiQyJdLFs0LDAsIjAiXSxbMCwxLCIwIl0sWzEsMSwiQSJdLFsyLDEsIkIiXSxbMywxLCJDIl0sWzQsMSwiMCJdLFswLDFdLFsxLDJdLFsyLDNdLFszLDRdLFs1LDZdLFs2LDcsIlxcaW90YSJdLFs3LDgsIlxccGkiXSxbOCw5XSxbMSw2LCIiLDEseyJsZXZlbCI6Miwic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsyLDcsIlxcdmFycGhpIl0sWzMsOCwiIiwxLHsibGV2ZWwiOjIsInN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XV0=
		\[\begin{tikzcd}
			0 & A & {A\oplus C} & C & 0 \\
			0 & A & B & C & 0
			\arrow[from=1-1, to=1-2]
			\arrow[from=1-2, to=1-3]
			\arrow[from=1-3, to=1-4]
			\arrow[from=1-4, to=1-5]
			\arrow[from=2-1, to=2-2]
			\arrow["\iota", from=2-2, to=2-3]
			\arrow["\pi", from=2-3, to=2-4]
			\arrow[from=2-4, to=2-5]
			\arrow[Rightarrow, no head, from=1-2, to=2-2]
			\arrow["\psi", from=1-3, to=2-3]
			\arrow[Rightarrow, no head, from=1-4, to=2-4]
		\end{tikzcd}\]
		\item The function $(\pi\circ-):\op{Hom}_R(C,B)\to\op{Hom}_R(C,C)$ is surjective.
		\item There are morphisms $\varphi:B\to A$ and $\psi:C\to B$ so that $\psi\pi+\iota\varphi=\id_B$.
	\end{listalph}
\end{lemma}
\begin{proof}
	We start by showing (a) is equivalent to (b).
	\begin{itemize}
		\item We show that (a) implies (b). Well, we claim that the provided lift $\varphi:C\to B$ such that $\pi\circ\varphi=\id_C$ will create the needed isomorphism by $\psi=\iota\oplus\varphi$. Namely, we have to show that $\iota\oplus\varphi:A\oplus C\to B$ is an isomorphism. Certainly it is an $R$-module homomorphism, so we need to show that it is a bijection, for which we have the following checks.
		\begin{itemize}
			\item We show that $\iota\oplus\varphi$ is injective. Well, if $(\iota\oplus\varphi)(a,c)=0$, then we want to show $(a,c)=(0,0)$. Well, $\iota(a)+\varphi(c)=0$, so
			\[0+c=\pi(\iota(a))+\pi(\varphi(c))=\pi(\iota(a)+\varphi(c))=0,\]
			so $c=0$ follows. But then $\iota(a)=0$, so $a=0$ by injectivity of $\iota$.
			\item We show that $\iota\oplus\varphi$ is surjective. Well, pick up some $b\in B$. Then we set $c:=\pi(b)$ so that
			\[\pi(b-\varphi(c))=\pi(b)-\id_C(c)=0.\]
			In particular, $b-\varphi(c)\in\ker\pi=\im\iota$ by exactness, so there exists $a\in A$ such that $b-\varphi(c)=\iota(a)$, from which $(\iota\oplus\varphi)(a,c)=b$ follows.
		\end{itemize}
		It remains to show that the diagram
		% https://q.uiver.app/?q=WzAsMTAsWzAsMCwiMCJdLFsxLDAsIkEiXSxbMiwwLCJBXFxvcGx1cyBDIl0sWzMsMCwiQyJdLFs0LDAsIjAiXSxbMCwxLCIwIl0sWzEsMSwiQSJdLFsyLDEsIkIiXSxbMywxLCJDIl0sWzQsMSwiMCJdLFswLDFdLFsxLDJdLFsyLDNdLFszLDRdLFs1LDZdLFs2LDcsIlxcaW90YSJdLFs3LDgsIlxccGkiXSxbOCw5XSxbMSw2LCIiLDEseyJsZXZlbCI6Miwic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsyLDcsIlxcaW90YVxcb3BsdXNcXHZhcnBoaSIsMV0sWzMsOCwiIiwxLHsibGV2ZWwiOjIsInN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XV0=
		\[\begin{tikzcd}
			0 & A & {A\oplus C} & C & 0 \\
			0 & A & B & C & 0
			\arrow[from=1-1, to=1-2]
			\arrow[from=1-2, to=1-3]
			\arrow[from=1-3, to=1-4]
			\arrow[from=1-4, to=1-5]
			\arrow[from=2-1, to=2-2]
			\arrow["\iota", from=2-2, to=2-3]
			\arrow["\pi", from=2-3, to=2-4]
			\arrow[from=2-4, to=2-5]
			\arrow[Rightarrow, no head, from=1-2, to=2-2]
			\arrow["\iota\oplus\varphi"{description}, from=1-3, to=2-3]
			\arrow[Rightarrow, no head, from=1-4, to=2-4]
		\end{tikzcd}\]
		commutes. To check that the left square commutes, we go along the top to get $a\mapsto(a,0)\mapsto\iota(a)$ and go along the bottom to get $a\mapsto a\mapsto\iota(a)$, which match.

		To check that the right square commutes, we go along the top to get $(a,c)\mapsto c\mapsto c$ and go along the bottom to get $(a,c)\mapsto\iota(a)+\varphi(c)\mapsto 0+c$, which match.

		\item We show that (b) implies (a). Well, we claim that the composite
		\[\varphi(c):=\psi((0,c))\]
		will work. Indeed, because the right square of the given diagram commutes, we see that
		\[\pi(\varphi(c))=\pi(\psi((0,c)))=c,\]
		which is what we wanted.
	\end{itemize}
	We now show that (a) is equivalent to (c).
	\begin{itemize}
		\item We show that (a) implies (c). For this, we pick up any morphism $f:C\to C$ that we want to hit and observe $(\varphi\circ f):C\to B$ will have
		\[(\pi\circ-)(\varphi\circ f)=(\pi\circ\varphi)\circ f=\id_C\circ f=f,\]
		so we are done.
		
		\item We show that (c) implies (a). This is not too bad: because $(\pi\circ-)$ is surjective, it must hit $\id_C:C\to C$, so there is a morphism $\varphi:C\to B$ such that $\pi\circ\varphi=(\pi\circ-)(\varphi)=\id_C$, which is what we wanted.
	\end{itemize}
	The above implications finish the proof.
\end{proof}
And now we get to talk about projective modules.
\begin{definition}[Projective] \label{def:projective}
	An $R$-module $P$ is \textit{projective} if and only if, for any surjection $\pi:B\onto C$ and map $\varphi:P\to C$, there exists an induced map $\overline\varphi:P\to B$ making the following diagram commute.
	% https://q.uiver.app/?q=WzAsMyxbMSwwLCJQIl0sWzEsMSwiTScnIl0sWzAsMSwiTSJdLFsyLDEsIlxccGkiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbMCwxLCJcXHZhcnBoaSJdLFswLDIsIlxccHNpIiwyLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV1d
	\[\begin{tikzcd}
		& P \\
		B & {C}
		\arrow["\pi"', two heads, from=2-1, to=2-2]
		\arrow["\varphi", from=1-2, to=2-2]
		\arrow["\psi"', dashed, from=1-2, to=2-1]
	\end{tikzcd}\]
\end{definition}
We might feel scammed that we just spent so much time discussing short exact sequences splitting, and the definition of projective does not use this. However, there are lots of equivalent definitions of projective; here are the ones we care about.
\begin{lemma} \label{lem:projgrabbag}
	Fix an $R$-module $P$. Then the following are equivalent.
	\begin{listalph}
		\item $P$ is projective, in the sense of \autoref{def:projective}.
		\item Any short exact sequence of $R$-modules
		\[0\to A\to B\to P\to 0\]
		splits.
		\item There exists an $R$-module $K$ such that $K\oplus P$ is a free $R$-module.
		\item The functor $\op{Hom}_R(P,-)$ is exact.
	\end{listalph}
\end{lemma}
\begin{proof}
	We take our implications one at a time.
	\begin{itemize}
		\item We show that (a) implies (b). The key is to write the short exact sequence in the following diagram.
		% https://q.uiver.app/?q=WzAsNixbMywwLCJQIl0sWzMsMSwiUCJdLFsyLDEsIkIiXSxbNCwxLCIwIl0sWzAsMSwiMCJdLFsxLDEsIkEiXSxbMCwxLCIiLDAseyJsZXZlbCI6Miwic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFswLDIsIlxcdmFycGhpIiwyLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzIsMSwiXFxwaSIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFs0LDVdLFs1LDJdLFsxLDNdXQ==
		\[\begin{tikzcd}
			&&& P \\
			0 & A & B & P & 0
			\arrow[Rightarrow, no head, from=1-4, to=2-4]
			\arrow["\varphi"', dashed, from=1-4, to=2-3]
			\arrow["\pi"', two heads, from=2-3, to=2-4]
			\arrow[from=2-1, to=2-2]
			\arrow[from=2-2, to=2-3]
			\arrow[from=2-4, to=2-5]
		\end{tikzcd}\]
		In particular, because $P$ is projective, there exists a map $\varphi:P\to M$ such that $\pi\circ\varphi=\id_P$. This is exactly what we need for the short exact sequence to split.

		\item We show that (b) implies (c). The point is to create a free $R$-module to surject onto $R$ and then use \autoref{lem:splitgrabbag}. We outsource this difficulty into the following lemma.
	\end{itemize}
	\begin{lemma} \label{lem:getenoughprojectives}
		Fix $M$ an $R$-module. Then there is a free $R$-module which surjects onto $M$.
	\end{lemma}
	\begin{proof}
		For each $m\in M$, we have a map $\varphi_m:R\to M$ by sending $\varphi_m:x\mapsto xm$, and this is an $R$-module homomorphism because, for $r_1,r_2,x_1,x_2\in R$ we have
		\[\varphi_m(r_1x_1+r_2x_2)=(r_1x_1+r_2x_2)m=r_1(x_1m)+r_2(x_2m)=r_1\varphi_m(x_1)+r_2\varphi_m(x_2).\]
		Now, we can stitch these $\varphi_m$ together to create a surjection
		\[\varphi:\underbrace{\bigoplus_{m\in M}R}_F\to M,\]
		and we note that $\varphi$ is now surjective because, for any $m_0,$ we have
		\[\varphi\left((1_{m=m_0})_{m\in M}\right)=\sum_{m\in M}\varphi_m(1_{m=m_0})=\varphi_{m_0}(1)=m_0.\]
		Thus, we do indeed have a free module $F$ which surjects onto $M$.
	\end{proof}
	\begin{itemize}
		\item[] We now finish showing that (b) implies (c). We use \autoref{lem:getenoughprojectives} to conjure the map $\varphi:F\onto M$ where $F$ is a free $R$-mdule and then create the short exact sequence
		\[0\to\ker\varphi\to F\stackrel\varphi\to M\to0.\]
		Now, by definition of $M$, this short exact sequence splits, so by \autoref{lem:splitgrabbag}, we have an isomorphism $F\cong(\ker\varphi)\oplus M$, which is what we wanted.
		\item We show that (c) implies (d). The main point is that (d) is not too hard to verify for free modules, so we will start by reducing to the free case. Fix our $R$-modules $K$ and $F$ so that $F$ is free and $F\cong K\oplus P$; name this isomorphism $\psi:F\to K\oplus P$. Now, given a short exact sequence
		\[0\to A\to B\to C\to 0,\]
		we need to show that the sequence
		\[0\to\op{Hom}_R(P,A)\to\op{Hom}_R(P,B)\to\op{Hom}_R(P,C)\to0\]
		is exact. Well, we know that $\op{Hom}_R(P,-)$ is always left-exact, so it remains to show that the map $\op{Hom}_R(P,B)\to\op{Hom}_R(P,C)$ is surjective. To be explicit, we name the map $B\to C$ by $\pi:B\to C$ so that we are showing
		\[(\pi\circ-):\op{Hom}_R(P,B)\to\op{Hom}_R(P,C)\]
		is surjective.

		For this, pick up a morphism $f:P\to C$ that we want to hit. We now reduce to the free case. By gluing this together with the zero morphism $0:K\to C$, we get an induced map $f:P\oplus K\to C$, which induces a map $f\varphi:F\to C$. Now that we are mapping from a free module, we can lift to $P\to B$ with ease: suppose $F=R^\lambda$ is free indexed by $\alpha\in\lambda$, so we see that we can find elements $\{b_\alpha\}_{\alpha\in\lambda}\subseteq B$ such that
		\[\pi(b_\alpha)=(f\varphi)(\alpha)\]
		because $\pi$ is surjective. Now, we can define a map $\overline f:F\to B$ by $\alpha\mapsto b_\alpha$ because $F$ is free, which satisfies
		\[\pi\circ\overline f=f\varphi\]
		by checking $(\pi\circ\overline f)(\alpha)=\pi(b_\alpha)=(f\varphi)(\alpha)$ on each $\alpha\in\lambda$.

		To finish, $\overline f:F\to B$ induces a map $\overline f\varphi^{-1}:P\oplus K\to B$, which restricts to a map $\overline f\varphi^{-1}\iota:P\to K$ by $p\mapsto(p,0)\mapsto\overline f(\varphi^{-1}(p,0))$. We now check that $\overline f\varphi^{-1}\iota$ actually satisfies the desired property: we see
		\[\pi\circ(\overline f\circ\varphi^{-1}\circ\iota)=f\circ\varphi\circ\varphi^{-1}\circ\iota=f\circ\id_{P\oplus K}\circ\iota_P=f\circ\id_P=f,\]
		so we are done.

		\item We show that (d) implies (a). This is definition-chasing. Suppose that we have a surjection $\pi:B\onto C$ and a map $\varphi:P\to C$ that we want to lift. Well, there is a short exact sequence
		\[0\to\ker\pi\to B\stackrel\pi\to C\to 0,\]
		which upon applying the exact functor $\op{Hom}_R(P,-)$ gives tells us that
		\[(\pi\circ-):\op{Hom}_R(P,C)\to\op{Hom}_R(P,B)\]
		is surjective, which is (c). In particular, there is a map $\overline\varphi:P\to C$ such that $\pi\circ\overline\varphi=\varphi$, which is what we wanted.
		\qedhere
	\end{itemize}
\end{proof}
\begin{remark}[Nir]
	Even though being projective has many definitions, some more concrete than others, I have chosen \autoref{def:projective} to begin with because it will be the most useful in homological algebra, which is where we are going next.
\end{remark}
Because I just can't resist, here is a more geometric view of projective modules, which was not covered in class.
\begin{proposition}
	Fix $M$ a finitely presented $R$-module. Then $M$ is projective if and only if $M_\mf p$ is a free $R_\mf p$ for all primes $\mf p\subseteq R$. In other words, $M$ is projective if and only if $M$ is locally free.
\end{proposition}
\begin{proof}
	We take our directions separately.
	\begin{itemize}
		\item Suppose $M$ is a finitely generated projective $R$-module. Thus, we have a projection $R^n\onto M$, so \autoref{lem:projgrabbag} grants us an isomorphism $K\oplus M\cong R^n$ for some $R$-module $K$. Localizing at some prime $\mf p$, we get
		\[K_\mf p\oplus M_\mf p\cong R_\mf p^n.\]
		So now we see that the localized module $M_\mf p$ is still a finitely generated projective $R_\mf p$-module by \autoref{lem:projgrabbag}, but now $R_\mf p$ is local with maximal ideal $\mf p_\mf p$.
		
		The main idea, now, is to extract out our dimension via \autoref{cor:quotientdimension}: note that we have an isomorphism
		\[(K_\mf p/\mf p_\mf pK_\mf p)\oplus(M_\mf p/\mf p_\mf pM_\mf p)\cong(R_\mf p/\mf p_\mf p)\otimes_{R_\mf p}(K_\mf p\oplus M_\mf p)\cong(R_\mf p/\mf p_\mf p)\otimes_{R_\mf P}R_\mf p^n\cong(R_\mf p/\mf p_\mf pR_\mf p)^n\]
		by repeatedly using \autoref{prop:tensorquotient}. Now, everything involved now has the $\mf p_\mf p$-action vanished, so the above exhibits an isomorphism of $R_\mf p/\mf p_\mf p$-vector spaces. In particular,
		\[\dim_{R_\mf p/\mf p_\mf p}(K_\mf p/\mf p_\mf pK_\mf p)+\dim_{M_\mf p/\mf p_\mf p}(M_\mf p/\mf p_\mf pM_\mf p)=n,\]
		so we provide these with bases $\{\overline{k_1},\ldots,\overline{k_a}\}$ and $\{\overline{m_1},\ldots,\overline{m_b}\}$ with $a+b=n$. By \autoref{cor:quotientdimension}, these bases extend to surjections $R_\mf p^a\onto K_\mf p$ and $R_\mf p^b\onto M_\mf p$ so that we have a big surjection
		\[R_\mf p^n=R_\mf p^a\oplus R_\mf p^b\onto K_\mf p\oplus M_\mf p\cong R_\mf p^n.\]
		But now \autoref{prop:epiisiso} now tells us that this is an isomorphism! In particular, the map $R_\mf p^b\onto M_\mf p$ may have no kernel, so it is an isomorphism, and we conclude that $M_\mf p$ is free.

		\item Suppose $M$ is a finitely presented $R$-module such that $M_\mf p$ is a free $R_\mf p$-module for each prime $\mf p\subseteq R$. The key is to use \autoref{rem:splitsifflocallysplits}. Indeed, suppose that we have any short exact sequence
		\[0\to A\to B\to M\to 0,\]
		and by \autoref{lem:projgrabbag}, it suffices to show that this short exact sequence splits. Well, by \autoref{rem:splitsifflocallysplits}, this short exact sequence splits if and only if
		\[0\to A_\mf p\to B_\mf p\to M_\mf p\to 0\]
		splits for all prime ideals $\mf p$. But now $M_\mf p$ is free and in particular projective (e.g., use (c) of \autoref{lem:projgrabbag}), so the short exact sequence splits by (b) of \autoref{lem:projgrabbag}. So we are done.
		\qedhere
	\end{itemize}
\end{proof}
Anyways, here is, roughly, why we introduced projective modules now.
\begin{prop}
	Projective modules are flat.
\end{prop}
\begin{proof}
	The main point is to use (c) of \autoref{lem:projgrabbag} to reduce to the free case, which we already know. Indeed, fix $P$ a projective $R$-module. By (c) of \autoref{lem:projgrabbag}, we are promised an $R$-module $K$ such that $K\oplus P$ is free.

	Now, by \autoref{rem:easierflat}, it suffices to pick up an inclusion $\iota:A\into B$ and show that the induced maps $\iota_P:A\otimes_RP\to B\otimes_RP$ is also injective. As promised, we will reduce to the free case. Indeed, we see that, for an $R$-module $M$, we have
	\[\psi_M:M\otimes_R(K\oplus P)\simeq(M\otimes_RK)\oplus(M\otimes_RP)\]
	by $\psi_M:m\otimes(k,p)\mapsto(m\otimes k,m\otimes p)$. In particular, we pick up the induced map $\iota_K:A\otimes_RK\to B\otimes_RK$ and $\iota_F:A\otimes_R(K\oplus P)\to B\otimes_R(K\oplus P)$ and note that the following diagram commutes.
	% https://q.uiver.app/?q=WzAsNCxbMCwwLCJBXFxvdGltZXNfUihLXFxvcGx1cyBQKSJdLFswLDEsIkJcXG90aW1lc19SKEtcXG9wbHVzIFApIl0sWzEsMCwiKEFcXG90aW1lc19SSylcXG9wbHVzKEFcXG90aW1lc19SUCkiXSxbMSwxLCIoQlxcb3RpbWVzX1JLKVxcb3BsdXMoQlxcb3RpbWVzX1JQKSJdLFswLDEsIlxcaW90YV9GIl0sWzIsMywiXFxpb3RhX0tcXG9wbHVzXFxpb3RhX1AiXSxbMCwyXSxbMSwzXV0=
	\[\begin{tikzcd}
		{A\otimes_R(K\oplus P)} & {(A\otimes_RK)\oplus(A\otimes_RP)} \\
		{B\otimes_R(K\oplus P)} & {(B\otimes_RK)\oplus(B\otimes_RP)}
		\arrow["{\iota_F}", from=1-1, to=2-1]
		\arrow["{\iota_K\oplus\iota_P}", from=1-2, to=2-2]
		\arrow["{\psi_A}", from=1-1, to=1-2]
		\arrow["{\psi_B}"', from=2-1, to=2-2]
	\end{tikzcd}\tag{$*$}\label{eq:tensordistribfunctorial}\]
	Tracking our generating elements, along the top we have $a\otimes(k,p)\mapsto(a\otimes k,a\otimes p)\mapsto(\iota a\otimes k,\iota a\otimes p)$, and along the bottom we have $a\otimes(k,p)\mapsto\iota a\otimes(k,p)\mapsto(\iota a\otimes k,\iota a\otimes p)$, which matches.

	To finish, suppose that we have an element $x\in A\otimes_R P$ in the kernel of $\iota_P$. Then $(0,x)\in\ker\iota_K\oplus\iota_P$, so because the diagram in \autoref{eq:tensordistribfunctorial} commutes, we see that
	\[\iota_F\left(\psi_A^{-1}(0,x)\right)=\psi_B^{-1}\big((\iota_K\oplus\iota_P)(0,x)\big)=0.\]
	But now $F$ is surely projective by \autoref{ex:freeisflat}, so $\iota_F$ is injective, so $\psi_A^{-1}(0,x)=0$, so $(0,x)=0$, so $x=0$. Thus, $\iota_P$ does indeed have trivial kernel.
\end{proof}

\subsection{Flatness for Geometers}
In algebraic geometry, we are interested in families of affine varieties, which consists of a base $B$ and a morphism $\varphi:X\to B$; in particular, we get an affine variety ``parameterized'' by the elements of our $B$ by taking the fiber $\varphi^{-1}(b)$ for each $b\in B$.

For example, here is the standard image of a M\"obius strip $X$ as a family of affine lines over $S^1$.
\begin{center}
	\begin{asy}
		import graph3;
		// thank you https://asymptote.sourceforge.io/asymptote_tutorial.pdf
		unitsize(2cm);
		currentprojection=orthographic(0,-2,1);
		
		real offset = pi;
		triple F(pair uv) {
			real t = uv.x;
			real r = uv.y;
			return (
				cos(t+offset) + r*cos(t)*sin(t/2),
				sin(t+offset) + r*sin(t)*sin(t/2),
				r*cos(t/2)
			);
		}
		real r = 0.2;
		surface moeb = surface(F, (0,-r), (2pi,r), Spline);
		draw(moeb, surfacepen=material(gray(0.7)+opacity(0.7), emissivepen=0.2 white));
		
		real x(real t) {return cos(2pi*t);}
		real y(real t) {return sin(2pi*t);}
		real z1(real t) {return 0;}
		real z2(real t) {return -2;}
		draw(graph(x,y,z1,0,1,operator ..));
		draw(graph(x,y,z2,0,1,operator ..));
	
		label("$X$", (-1.5,0,0));
		label("$S^1$", (-1.5,0,-2));
		draw((-1.5,0,-0.3) -- (-1.5,0,-2+0.3), EndArrow3);
		label("$\pi$", (-1.63,0,-1));
		
		real theta = -1;
		dot((cos(theta), sin(theta), 0), red);
		dot((cos(theta), sin(theta), -2), red);
		draw((cos(theta), sin(theta), -2+0.3) -- (cos(theta), sin(theta), -0.3), arrow=Arrow3(DefaultHead2(),Fill,emissive(red)), p=red+dashed);
		
		real t0 = theta-offset;
		real r0 = -0.4;
		draw(F((t0,-r0)) -- F((t0,r0)), arrow=Arrow3(DefaultHead2(),Fill,emissive(red)), p=red);
		draw(F((t0,r0)) -- F((t0,-r0)), arrow=Arrow3(DefaultHead2(),Fill,emissive(red)), p=red);
		
		label("$x$", (1.3*cos(theta), 1.3*sin(theta), -2), p=red);
		label("$\pi^{-1}(x)$", (1.3*cos(theta-0.1)+0.5, 1.3*sin(theta-0.1), 0), p=red);
	\end{asy}
\end{center}
In particular, the ``data'' of this family really just consists of the morphism $\pi:X\to S^1$.

As usual, the algebraic story will reverse, so a family in the algebraic world should consist of the data
\[(-\circ\varphi):A(B)\to A(X).\]
In particular, such a map $A(B)\to A(X)$ is exactly the data of $A(X)$ being an $A(B)$-algebra. To make our notions more general, we set $S:=A(X)$ an $R:=A(B)$-algebra by $\varphi:R\to S$.

Keeping track of our geometry, we would like to talk about how to move fibers into our algebraic world. We start by fixing a point $p\in B$, whose coordinate ring is $R/\mf m$, where $\mf m$ is some maximal ideal. Moving up to $S$, we note that if we want a function $f:X\to k$ to vanish on $\varphi^{-1}(p)$, then ``morally'' it should look like it factors through $\varphi$ and take the form $f\varphi$ for some $f\in\mf m$. In other words, we should modulo out by the ideal generated by
\[(-\circ\varphi)(\mf m),\]
which is $\mf mS$, so the coordinate ring of $\varphi^{-1}(p)$ will be
\[S/\mf mS.\]
To generalize this past maximal ideals, we write\footnote{For example, we are using \autoref{prop:tensorquotient} to get an isomorphism of $R$-modules, but the multiplication also matches: we have $\psi:[s]_{\mf mS}\mapsto[1]_\mf m\otimes s$, so $\psi([s]\cdot[t])=\psi([st])=[1]\otimes st=([1]\otimes s)([1]\otimes t)=\psi([s])\psi([t])$.} $S/\mf mS\simeq(R/\mf m)\otimes_RS$, so for more general primes $\mf p\subseteq R$, our coordinate ring of the fiber over $\mf p$ will be
\[(R/\mf p)\otimes_RS.\]
In a family, we would like the fibers to be well-behaved. One way to keep track of well-behaved families of ``algebras'' (which, as above, consists of the data of a single ring homomorphism $R\to S$) is via the flatness condition.
\begin{definition}[Flat]
	An $R$-algebra $S$ is \textit{flat} if and only if $S$ is flat as an $R$-module.
\end{definition}
On the geometric side, flatness (roughly speaking) means that the fiber $(R/\mf p)\otimes_RS$ varies continuously as the point $\mf p$ moves.

Let's see some examples. We will take our base to be $B:=\AA^1(k)$ the affine line over a characteristic-$0$ algebraically closed field $k$, which gives that $R:=k[t]$.
\begin{exe}
	We consider the flatness of $S:=R[x]/\left(x^2-t\right)$ geometrically and algebraically.
\end{exe}
\begin{proof}
	Our family looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(1cm);
			import graph;
			real y(real t)
			{
				return t;
			}
			real x(real t)
			{
				return t*t;
			}
			draw(graph(x, y,-2,2));
			draw((-0.5,0)--(4,0), dotted); label("$t$", (4,0), E);
			draw((0,-2)--(0,2), dotted); label("$x$", (0,2), N);
		\end{asy}
	\end{center}
	Now, for a given $a\in k$, the coordinate ring of our fiber over $a$ will be
	\[\frac S{(t-a)S}=\frac{k[x,t]/\left(x^2-t\right)}{(t-a)k[x,t]/\left(x^2-t\right)}\cong\frac{k[x,t]}{\left(x^2-t,t-a\right)}\cong\frac{k[x]/(x-a)}{\left(x^2-t\right)/(x-a)}\cong\frac{k[x]}{\left(x^2-a\right)},\]
	where we have applied evaluation at $t=a$ in the last isomorphism.

	We are now ready to compute the fiber. We have two cases.
	\begin{itemize}
		\item Take $a=0$. Then we get $k[x]/\left(x^2\right)$, which is a two-dimensional $k$-algebra generated by $\{1,x\}$. For example, we can use \autoref{prop:integralitydef} for this.
		\item Take $a\ne0$. Then we get $x^2-a$ has a root $\beta$ with $\beta\ne0$, so $\beta\ne-\beta$ are distinct roots of $x^2-a$. So the polynomials $(x-\beta)$ and $(x+\beta)$ are coprime (any common divisor would have to divide $(x+\beta)-(x-\beta)=2\beta\in k^\times$), so the Chinese remainder theorem implies
		\[\frac{k[x]}{\left(x^2-a\right)}\cong\frac{k[x]}{(x-\beta)}\oplus\frac{k[x]}{(x+\beta)}.\]
		Now, each term on the right-hand side is isomorphic to $k$ by the evaluation morphism $k[x]/(x-\gamma)\to k$ by $x\mapsto\gamma$. So our fiber is isomorphic to $k^2$. Geometrically, the coordinate ring of a point is simply $k$, so our fiber looks like two points, as we expect.
	\end{itemize}
	Even though the fiber has a bit of hiccup at $a=0$, its dimension is still uniform (namely, the coordinate ring is generated by two elements), so our fibers appear ``continuous.''

	So we have geometric reason to expect $S$ to be flat. Algebraically, we note from \autoref{prop:integralitydef} that
	\[S=\frac{R[t]}{\left(x^2-t\right)}\]
	is a free $R$-module and therefore flat by \autoref{ex:freeisflat}.
\end{proof}
\begin{exe}
	We consider the flatness of $S:=R[x]/\left(xt-1\right)$ geometrically and algebraically.
\end{exe}
\begin{proof}
	Our family looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(0.5cm);
			import graph;
			real y(real t)
			{
				return t;
			}
			real x(real t)
			{
				return 1/t;
			}
			draw(graph(x, y,-4,-1/4));
			draw(graph(x, y, 4,1/4));
			draw((-4,0)--(4,0), dotted); label("$t$", (4,0), E);
			draw((0,-4)--(0,4), dotted); label("$x$", (0,4), N);
		\end{asy}
	\end{center}
	We now split our computation of the coordinate ring of the fiber over some fixed $a\in k$ into two cases.
	\begin{itemize}
		\item If $a=0$, then we are computing $S/(t)S$, but we notice that $t\in S$ is a unit because $xt=1$ in $S$, so $S/(t)S$ is simply $0$. This corresponds to the fact that we have an empty variety as the fiber over $0$.
		\item If $a\ne0$, then we directly compute
		\[\frac S{(t-a)S}=\frac{k[x,t]/(xt-1)}{(t-a)k[x,t]/(xt-1)}\cong\frac{k[x,t]}{(xt-1,t-a)}\cong\frac{k[x,t]/(t-a)}{(xt-1)/(t-a)}\cong\frac{k[x]}{(ax-1)},\]
		where we have applied evaluation at $t=a$ in the last isomorphism. Now, the point is that $(ax-1)=(x-1/a)$ because $a\in k^\times$, so $S/(t-a)S\cong k$ by applying the isomorphism $k[x]/(x-1/a)\to k$ by $x\mapsto 1/a$.

		In particular, the coordinate ring being $k$ corresponds to the fact that we have a single point in our fiber.
	\end{itemize}
	From the above casework, we see that our fibers vary continuously except for a ``singularity'' at $a=0$, which is still legal, so we have some reason to believe that $S$ is flat. And indeed, $S=R[x]/(xt-1)\cong R\left[t^{-1}\right]$ as we showed on the homework, so $S$ is a localization of $R$, so $S$ is flat as an $R$-module.
\end{proof}
\begin{exe}
	We consider the non-flatness of $S:=R[x]/(tx-t)$ geometrically and algebraically.
\end{exe}
\begin{proof}
	Our family looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(0.5cm);
			import graph;
			draw((-4,1)--(4,1));
			draw((0,-4)--(0,4));
			draw((-4,0)--(4,0), dotted); label("$t$", (4,0), E);
			label("$x$", (0,4), N);
		\end{asy}
	\end{center}
	We now compute the coordinate ring of the fiber over a fixed point $a\in k$. Generally speaking, we find that
	\[\frac S{(t-a)S}=\frac{k[x,t]/(tx-t)}{(t-a)k[x,t]/(tx-t)}\cong\frac{k[x,t]}{(tx-t,t-a)}\cong\frac{k[x]}{(ax-a)}.\]
	To finish, we do casework on $a$.
	\begin{itemize}
		\item Take $a=0$ so that we have
		\[\frac S{(t)S}\cong\frac{k[x]}{(0)}=k[x].\]
		In particular, our coordinate ring being $k[x]$ corresponds to this fiber being a full line.
		\item Take $a\ne0$. Then we have
		\[\frac S{(t-a)S}\cong\frac{k[x]}{(ax-a)}.\]
		But now, $(ax-a)=(a)(x-1)=(x-1)$ because $a\in k^\times$. So, applying evaluation at $x=1$, we see that $S/(t-a)S\cong k$, which corresponds to our coordinate ring consisting of a single point.
	\end{itemize}
	Now, the above situation feels and looks significantly less continuous: we added a full line of dimension at $a=0$.

	And indeed, we can verify that $S$ is not flat as an $R$-module. We have the following result.
	\begin{lemma}
		Fix $R$ a ring $a\in R$ a non-zero-divisor. Further, if $M$ is a flat $R$-module, then $am=0$ implies $m=0$ for $m\in M$.
	\end{lemma}
	\begin{proof}
		The key is to use the flatness condition on the short exact sequence
		\[0\to R\stackrel{\times a}\to R\to R/(a)\to 0.\]
		We quickly check that $R\stackrel{\times a}\to R$ is indeed injective because it has trivial kernel: if $ar=0$, then $r=0$ by construction of $a$.

		So now, upon tensoring with $M$, we get an embedding
		\[\iota:R\otimes_RM\stackrel{\times a}\into R\otimes_RM\]
		induced by $R\stackrel{\times a}\into R$. In particular, using the isomorphism $R\otimes_RM\cong M$ by $r\otimes m\mapsto rm$, we see that $am=0$ implies that $a\otimes m=0$ implies that
		\[\iota(1\otimes m)=a\otimes m=0.\]
		Thus, $1\otimes m\in\ker\iota$, so $1\otimes m=0$ is forced, so by pushing through $R\otimes_RM\cong M$ again, we see that $m=1m=0$. This is what we wanted.
	\end{proof}
	Now, using the above lemma, we note that $t(x-1)=tx-t=0$ in $S$ while $t\in k[t]=R$ is not a zero-divisor and $x-1\ne0$, so $S$ is not flat. Technically, some argument is required to verify that $x-1\ne0$, but we can see this because $S/(t)S\cong k[x]$ computed above takes $x\mapsto x$, so $x$ is transcendental over $k$, so $x\ne1$.
\end{proof}

\subsection{Complexes and Homology}
We will want to talk about $\op{Tor}$ in our discussion of flatness, so we will introduce the necessary homological algebra.

In homological algebra, there are dual discussions of homology and cohomology, but we will choose to focus on homology because that is where $\op{Tor}$ arises from, though we will make occasionally comments about how the cohomological story works.
\begin{quot}
	The difference between homology and cohomology is that homology indexes like $H_i$, and cohomology indexes like $H^i$.
\end{quot}
The purpose of homological algebra is to create derived functors, which we will talk about tomorrow. Derived functors, roughly speaking, are a useful way to start with a short exact sequence and get out a long exact sequence. However, we will want to be able to talk about long sequences which are a little less than exact, so we have the following definition.
\begin{definition}[Chain complex]
	Fix a ring $R$ with the trivial grading. An \textit{$R$-complex} $(C,\del)$ is a $\ZZ$-graded module $C:=\oplus_{i\in\ZZ}C_i$ (i.e., $RC_i\subseteq C_i$) that is equipped with a (graded) morphism $\del\in\op{End}_R(C)$ such that $\del^2=0$.
	\begin{itemize}
		\item If $\deg\del=-1$ (i.e., $\del|_{C_i}:C_i\to C_{i-1}$), we will call this an $R$-chain complex.
		\item If $\deg\del=+1$ (i.e., $\del|_{C_i}:C_i\to C_{i+1}$), we will call this an $R$-cochain complex.
	\end{itemize}
	As much as possible, we will omit the ambient ring $R$ and say ``(co)chain complex.''
\end{definition}
One often views a chain complex $C$ as some large chain which looks like
\[\cdots\stackrel\del\to C_2\stackrel\del\to C_1\stackrel\del\to C_0\stackrel\del\to C_{-1}\stackrel\del\to\cdots.\]
For bookkeeping reasons, we might define $\del_i:=\del|_{C_i}:C_i\to C_{i-1}$ to be more specific about our domain. Dually, a cochain complex can be viewed as a large chain
\[\cdots\stackrel\del\to C_{-1}\stackrel\del\to C^0\stackrel\del\to C^1\stackrel\del\to C^2\stackrel\del\to\cdots.\]
Again, we can index our arrows as $\del^i:=\del|_{C^i}:C^i\to C^{i-1}$.
\begin{remark}[Nir] \label{rem:cochaintochain}
	Given a cochain complex $(D^\bullet,\del^\bullet)$, we can set $C_i:=D^{-i}$ to make a chain complex. Formally, $\del^i:D^i\to D^{i+1}$ becomes $\del_{-i}:C_{-i}\to C_{-i-1}$, giving our chain complex. Pictorially, we are applying the following process.
	% https://q.uiver.app/?q=WzAsMTAsWzEsMCwiRF57LTF9Il0sWzIsMCwiRF4wIl0sWzMsMCwiRF4xIl0sWzEsMSwiQ18xIl0sWzIsMSwiQ18wIl0sWzMsMSwiQ197LTF9Il0sWzAsMCwiXFxjZG90cyJdLFs0LDAsIlxcY2RvdHMiXSxbMCwxLCJcXGNkb3RzIl0sWzQsMSwiXFxjZG90cyJdLFswLDMsIiIsMCx7ImxldmVsIjoyLCJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzEsNCwiIiwwLHsibGV2ZWwiOjIsInN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMiw1LCIiLDAseyJsZXZlbCI6Miwic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs2LDAsIlxcZGVsXnstMn0iXSxbMCwxLCJcXGRlbF57LTF9Il0sWzEsMiwiXFxkZWxeMCJdLFsyLDcsIlxcZGVsXjEiXSxbOCwzLCJcXGRlbF4yIiwyXSxbMyw0LCJcXGRlbF4xIiwyXSxbNCw1LCJcXGRlbF4wIiwyXSxbNSw5LCJcXGRlbF57LTF9IiwyXV0=&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		\cdots & {D^{-1}} & {D^0} & {D^1} & \cdots \\
		\cdots & {C_1} & {C_0} & {C_{-1}} & \cdots
		\arrow[Rightarrow, no head, from=1-2, to=2-2]
		\arrow[Rightarrow, no head, from=1-3, to=2-3]
		\arrow[Rightarrow, no head, from=1-4, to=2-4]
		\arrow["{\del^{-2}}", from=1-1, to=1-2]
		\arrow["{\del^{-1}}", from=1-2, to=1-3]
		\arrow["{\del^0}", from=1-3, to=1-4]
		\arrow["{\del^1}", from=1-4, to=1-5]
		\arrow["{\del^2}"', from=2-1, to=2-2]
		\arrow["{\del^1}"', from=2-2, to=2-3]
		\arrow["{\del^0}"', from=2-3, to=2-4]
		\arrow["{\del^{-1}}"', from=2-4, to=2-5]
	\end{tikzcd}\]
\end{remark}
\begin{warn}
	In light of \autoref{rem:cochaintochain}, we will stop talking about cochain complexes, except to say that they have analogous definitions and results by adding in the prefix co- everywhere and flipping the arrows as described in \autoref{rem:cochaintochain}.
\end{warn}
With our chain complexes in place, we can define homology.
\begin{definition}[Homology]
	Given a chain complex $(C,\del)$, we define the \textit{homology module} as
	\[H_i(C):=\ker\del_i/\im\del_{i+1}.\]
\end{definition}
\begin{remark} \label{rem:homologywelldefined}
	We quickly check that these modules are well-defined. For a chain complex $(C,\del)$, we see that $\del^2=0$ implies that $\del_i\del_{i+1}:C_{i+1}\to C_{i-1}$ is the zero morphism, so
	\[\im\del_{i+1}\subseteq\ker\del_i,\]
	making our quotient well-defined.
\end{remark}
\begin{remark}[Nir]
	To remember this notation, note that we always want $\ker\del_i\subseteq C_i$, so $H_i(C)$ is represented by elements of $C_i$.
\end{remark}

\subsection{Chain Morphisms}
We have just defined an algebraic object (the chain complex), so because this is algebra, we will want to define their morphisms.
\begin{definition}[Chain morphism]
	Given chain complexes $\left(A,\del^A\right)$ and $\left(B,\del^B\right)$, we define a \textit{chain morphism} $\varphi$ as a degree-$0$ morphism $\varphi:A\to B$ such that $\del^B\circ\varphi=\varphi\circ\del^A$.
\end{definition}
As usual, we can look at chain morphisms $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ on the level of component modules as well: for each index $i\in\ZZ$, we can restrict $\varphi$ to a morphism $\varphi_i:A_i\to B_i$ such that the following diagram commutes.
% https://q.uiver.app/?q=WzAsNCxbMCwwLCJDX2kiXSxbMSwwLCJDX3tpLTF9Il0sWzEsMSwiQydfe2ktMX0iXSxbMCwxLCJDJ19pIl0sWzAsMSwiXFxkZWwiXSxbMywyLCJcXGRlbCciLDJdLFswLDMsIlxcdmFycGhpIiwyXSxbMSwyLCJcXHZhcnBoaSJdXQ==
\[\begin{tikzcd}
	{A_i} & {A_{i-1}} \\
	{B_i} & {B_{i-1}}
	\arrow["{\del^A_i}", from=1-1, to=1-2]
	\arrow["{\del^B_i}"', from=2-1, to=2-2]
	\arrow["{\varphi_i}"', from=1-1, to=2-1]
	\arrow["{\varphi_{i-1}}", from=1-2, to=2-2]
\end{tikzcd}\]
Before continuing, we check that composition of chain morphisms gives another chain morphism.
\begin{lemma} \label{lem:composechainmorphism}
	Fix chain morphisms $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ and $\psi:\left(B,\del^B\right)\to\left(C,\del^C\right)$. Then $\psi\circ\varphi:\left(A,\del^A\right)\to\left(C,\del^C\right)$ is a chain morphism.
\end{lemma}
\begin{proof}
	Because $\varphi$ and $\psi$ are both degree-$0$ graded morphisms, we see $\psi\circ\varphi$ is a degree-$0$ graded morphism; explicitly, for any index $i$, we have $\varphi(A_i)\subseteq B_i$ and $\psi(B_i)\subseteq C_i$ gives $(\psi\circ\varphi)(A_i)\subseteq C_i$.
	
	Additionally, we note that
	\[(\psi\circ\varphi)\circ\del^A=\psi\circ\varphi\circ\del^A=\psi\circ\del^B\circ\varphi=\del^C\circ\psi\circ\varphi=\del^C\circ(\psi\circ\varphi),\]
	so we see that $\psi\circ\varphi:\left(A,\del^A\right)\to\left(C,\del^C\right)$ is indeed a chain morphism.
\end{proof}
Also, $R$-linear combination of chain morphisms gives another chain morphism.
\begin{lem} \label{lem:rlinearchainmorphism}
	Fix elements $r,s\in R$ and chain morphisms $\varphi,\psi:\left(A,\del^A\right)\to\left(B,\del^B\right)$. Then $r\varphi+s\psi$ is also a chain morphism.
\end{lem}
\begin{proof}
	For any index $i$, we do indeed have $\varphi(A_i),\psi(A_i)\subseteq B_i$, so
	\[(r\varphi+s\psi)(A_i)=r\cdot\varphi(A_i)+s\cdot\psi(A_i)\subseteq rB_i+sB_i\subseteq B_i.\]
	Additionally, for any $a\in A$, we can check that
	\[\big((r\varphi+s\psi)\circ\del^A\big)(a)=r\left(\varphi\del^A\right)(A)+s\left(\psi\del^A\right)(a)=r\left(\del^B\varphi\right)(a)+s\left(\del^B\psi\right)(a)=\big(\del^B\circ(r\varphi+s\psi)\big)(a),\]
	finishing.
\end{proof}
Now, the commutativity condition $\del^B\varphi=\varphi\del^A$ is essentially in place to ensure that chain morphisms give rise to natural morphisms of homology modules.
\begin{lemma} \label{lem:gethomologymorphism}
	Fix a chain morphism $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ and an index $i\in\ZZ$. Then there is a map
	\[H_i(\varphi):H_i(A)\to H_i(B)\]
	induced as $H_i(\varphi):[a]_{\im\del^A_{i+1}}\mapsto[\varphi_ia]_{\im\del^B_{i+1}}$. In fact, $\varphi_i$ induces maps $\ker\del_i^A\to\ker\del_i^B$ and $\im\del_{i+1}^A\to\im\del_{i+1}^B$ by restriction.
\end{lemma}
\begin{proof}
	By construction of the chain morphism, the following diagram commutes.
	% https://q.uiver.app/?q=WzAsNixbMSwwLCJBX2kiXSxbMiwwLCJBX3tpLTF9Il0sWzAsMCwiQV97aSsxfSJdLFswLDEsIkJfe2krMX0iXSxbMSwxLCJCX2kiXSxbMiwxLCJCX3tpLTF9Il0sWzIsMywiXFx2YXJwaGlfe2krMX0iLDJdLFswLDQsIlxcdmFycGhpX2kiXSxbMSw1LCJcXHZhcnBoaV97aS0xfSJdLFsyLDAsIlxcZGVsXkFfe2krMX0iXSxbMCwxLCJcXGRlbF5BX2kiXSxbMyw0LCJcXGRlbF5CX3tpKzF9IiwyXSxbNCw1LCJcXGRlbF5CX2kiLDJdXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{A_{i+1}} & {A_i} & {A_{i-1}} \\
		{B_{i+1}} & {B_i} & {B_{i-1}}
		\arrow["{\varphi_{i+1}}"', from=1-1, to=2-1]
		\arrow["{\varphi_i}", from=1-2, to=2-2]
		\arrow["{\varphi_{i-1}}", from=1-3, to=2-3]
		\arrow["{\del^A_{i+1}}", from=1-1, to=1-2]
		\arrow["{\del^A_i}", from=1-2, to=1-3]
		\arrow["{\del^B_{i+1}}"', from=2-1, to=2-2]
		\arrow["{\del^B_i}"', from=2-2, to=2-3]
	\end{tikzcd}\]
	Now, for each element $a\in\ker\del_i^A$, we see that $\del_i^B(\varphi_ a)=\varphi_i\left(\del_i^Aa\right)=\varphi(0)=0$, so $\varphi_i$ restricts to a map
	\[\varphi_i:\ker\del_i^A\to\ker\del_i^B.\]
	Continuing, if we pick up some $\del_{i+1}^Aa\in\im\del_{i+1}^A\subseteq\ker\del_i^A$ (see \autoref{rem:homologywelldefined}), then $\varphi_i\left(\del_{i+1}^Aa\right)=\del_{i+1}^B(\varphi_ia)$, so $\varphi_i$ again restricts to a map
	\[\varphi_i:\im\del_{i+1}^A\to\im\del_{i+1}^B.\]
	Thus, we have shown the last sentence of the claim. Continuing, $\varphi_i$ induces a map $\ker\del_i^A\to\ker\del_i^B\onto\ker\del_i^B/\im\del_{i+1}^B$, from which we can induce our desired map
	\[H_i(\varphi):H_i(A)\to H_i(B)\]
	by sending $[a]\mapsto[\varphi_ia]$, as needed.
\end{proof}
In fact, so far we have discussed how homology produces an $R$-module from a chain, and we have also discussed how to get a morphism of homology from a morphism of chains. Thus, we have all the data for a functor from chains to $R$-modules by homology, and we only have to run the following checks.
\begin{lemma} \label{lem:homologyfunctor}
	Fix an index $i\in\ZZ$. The mapping $H_i$ taking chains $(C,\del)$ to $H_i(C)$ and morphisms $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ to $H_i(\varphi)$ is in fact a functor. Namely, we have the following.
	\begin{itemize}
		\item Identity: $H_i(\id_C)=\id_{H_i(C)}$ for any chain complex $(C,\del)$.
		\item Composition: $H_i(\psi\circ\varphi)=H_i(\psi)\circ H_i(\varphi)$ for any morphisms $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ and $\psi:\left(B,\del^B\right)\to\left(C,\del^C\right)$.
	\end{itemize}
\end{lemma}
\begin{proof}
	We take our checks one at a time.
	\begin{itemize}
		\item Fix a chain complex $(C,\del)$. Here, $\id_C:(C,\del)\to(C,\del)$ is given by $\id_C:C\to C$, which is a chain morphism $\del\id_C=\del=\id_C\del$. Then, by definition in \autoref{lem:gethomologymorphism}, we see that
		\[H_i(\id_C)\left([c]_{\im\del_{i+1}}\right):=[\id_Cc]_{\im\del_{i+1}}=[c]_{\im\del_{i+1}},\]
		so $H_i(\id_C)=\id_{H_i(C)}$.
		\item Fix chain morphisms $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ and $\psi:\left(B,\del^B\right)\to\left(C,\del^C\right)$. Then we see that $\psi\circ\varphi:\left(A,\del^A\right)\to\left(C,\del^C\right)$ is a chain morphism by \autoref{lem:composechainmorphism}. Now, using the definition in \autoref{lem:gethomologymorphism}, we see
		\[H_i(\psi\circ\varphi)\big([a]_{\im\del^A_{i+1}}\big)=[\psi_i\varphi_ia]_{\im\del^A_{i+1}}=H_i(\psi)\big([\varphi_ia]_{\im\del^A_{i+1}}\big)=H_i(\psi)H_i(\varphi)\big([a]_{\im\del^A_{i+1}}\big),\]
		so we do indeed have $H_i(\psi\circ\varphi)=H_i(\psi)\circ H_i(\varphi)$.
		\qedhere
	\end{itemize}
\end{proof}
In fact, $H_i$ is an amazing functor: it also preserves the structure of our $\op{Hom}$ sets.
\begin{lemma} \label{lem:rlinearhomology}
	Fix an index $i\in\ZZ$. Then, elements of our ambient ring $r,s\in R$ and chain morphisms $\varphi,\psi:\left(A,\del^A\right)\to\left(B,\del^B\right)$, we have
	\[H_i(r\varphi+s\psi)=rH_i(\varphi)+sH_i(\psi).\]
\end{lemma}
\begin{proof}
	Note that $r\varphi+s\psi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ is indeed a chain morphism by \autoref{lem:rlinearchainmorphism}. Now, we pick up some $[a]_{\im\del^A_{i+1}}\in H_i(A)$ and check via \autoref{lem:gethomologymorphism} that
	\begin{align*}
		H_i(r\varphi+s\psi)\big([a]_{\im\del^A_{i+1}}\big) &= [r\varphi_ia+s\psi_ia]_{\im\del^A_{i+1}} \\
		&= r[\varphi_ia]_{\im\del^A_{i+1}}+s[\psi_ia]_{\im\del^A_{i+1}} \\
		&= rH_i(\varphi)\big([a]_{\im\del^A_{i+1}}\big)+rH_i(\psi)\big([a]_{\im\del^A_{i+1}}\big) \\
		&= \big(rH_i(\varphi)+sH_i(\psi)\big)\big([a]_{\im\del^A_{i+1}}\big),
	\end{align*}
	so $H_i(r\varphi+s\psi)=rH_i(\varphi)+sH_i(\psi)$ follows.
\end{proof}

\subsection{Chain Homotopy}
We defined our chain morphisms to give rise to maps of homology modules. Now, sometimes different chain morphisms will give rise to the same map of homology modules, so we will want a way to keep track of this back in the world of chain morphisms. This gives the following definition.
\begin{definition}[Chain homotopy]
	Two chain morphisms $\varphi,\psi:\left(A,\del^A\right)\to(B,\del^B)$ are \textit{homotopically equivalent} if and only if there exists an $R$-module homomorphism $h:A\to B$ of degree $1$ (i.e., $h|_{A_i}:A_i\to B_{i+1}$) such that $\varphi-\psi=h\del_A+\del_Bh$. In this case, we will write $\varphi\sim\psi$ and call $h$ a \textit{chain homotopy}.
\end{definition}
On the level of component modules, the image is as follows. As a warning, this diagram does not commute.
% https://q.uiver.app/?q=WzAsMTAsWzIsMCwiQ18xIl0sWzMsMCwiQ18wIl0sWzQsMCwiMCJdLFsyLDEsIkNfMSciXSxbMywxLCJDXzAnIl0sWzQsMSwiMCJdLFsxLDAsIkNfMiJdLFsxLDEsIkNfMiciXSxbMCwwLCJcXGNkb3RzIl0sWzAsMSwiXFxjZG90cyJdLFs4LDZdLFs2LDBdLFswLDFdLFsxLDJdLFs5LDddLFs3LDNdLFszLDRdLFs0LDVdLFsxLDRdLFswLDNdLFs2LDddLFsxLDMsImgiLDFdLFswLDcsImgiLDFdXQ==
\[\begin{tikzcd}
	\cdots & {A_2} & {A_1} & {A_0} & {\cdots} \\
	\cdots & {B_2} & {B_1} & {B_0} & {\cdots}
	\arrow[from=1-1, to=1-2]
	\arrow[from=1-2, to=1-3]
	\arrow[from=1-3, to=1-4]
	\arrow[from=1-4, to=1-5]
	\arrow[from=2-1, to=2-2]
	\arrow[from=2-2, to=2-3]
	\arrow[from=2-3, to=2-4]
	\arrow[from=2-4, to=2-5]
	\arrow[from=1-4, to=2-4]
	\arrow[from=1-3, to=2-3]
	\arrow[from=1-2, to=2-2]
	\arrow["{h_0}"{description}, from=1-4, to=2-3]
	\arrow["{h_1}"{description}, from=1-3, to=2-2]
\end{tikzcd}\]
In particular, we can break up $h:A\to B$ into individual morphisms $h_i:A_i\to B_{i+1}$ such that $\varphi_i-\psi_i=h_{i-1}\del^A_i+\del^B_{i+1}h_i$.

Before continuing, we run some checks on homotopy equivalence.
\begin{lemma}
	Homotopy equivalence of morphisms $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ is an equivalence relation.
\end{lemma}
\begin{proof}
	We have the following checks. All of our chain morphisms will be $\left(A,\del^A\right)\to\left(B,\del^B\right)$, so we will omit this information in our discussion.
	\begin{itemize}
		\item Reflexive: fix a chain morphism $\varphi$, and we show $\varphi\sim\varphi$. Well, take $h=0$, which is indeed a degree-$1$ map ($h(A_i)=\{0\}\subseteq B_{i+1}$), and
		\[\varphi-\varphi=0=0\cdot\del_A+\del_B\cdot0.\]
		\item Symmetric: fix homotopically equivalent chain morphisms $\varphi\sim\psi$ so that we are given a degree-$1$ map $h:A\to B$ such that $\varphi-\psi=h\del_A+\del_BA$. We want to show $\psi\sim\varphi$, for which we take $-h:A\to B$. Note $-h$ is a degree-$1$ map because $(-h)(A_i)=-h(A_i)\subseteq -B_{i+1}=B_{i+1}$ for any index $i$. Further, we see
		\[\psi-\varphi=-(\varphi-\psi)=-(h\del_A+\del_Bh)=(-h)\del_A+\del_B(-h)\]
		after rearranging, so we are done.
		\item Transitive: fix chain morphisms $\alpha,\beta,\gamma$ so that $\alpha\sim\beta$ and $\beta\sim\gamma$. So we are promised a chain homotopies $a$ and $b$ so that
		\[\alpha-\beta=a\del_A+\del_Ba\qquad\text{and}\qquad\beta-\gamma=b\del_A+\del_Bb,\]
		from which we find
		\[\alpha-\gamma=(a+b)\del_A+\del_B(a+b)\]
		by adding. To finish, we check that $a+b$ is a degree-$1$ morphism, for which we note $(a+b)(A_i)=a(A_i)+b(A_i)\subseteq B_i+B_i=B_i$ for any index $i$.
		\qedhere
	\end{itemize}
\end{proof}
\begin{lem} \label{lem:rlinearchainhomotopy}
	Fix elements $r,s\in R$ and chain morphisms $\varphi,\varphi',\psi,\psi':\left(A,\del^A\right)\to\left(B,\del^B\right)$. If $\varphi\sim\varphi'$ and $\psi\sim\psi'$, then
	\[r\varphi+s\psi\sim r\varphi'+s\psi'.\]
\end{lem}
\begin{proof}
	We are promised chain homotopies $a$ and $b$ witnessing $\varphi\sim\varphi'$ and $\psi\sim\psi'$, respectively. Now, we compute that
	\begin{align*}
		(r\varphi+s\psi)-(r\varphi'+s\psi') &= r(\varphi-\varphi')+s(\psi-\psi') \\
		&= r\left(a\del^A+\del^Ba\right)+s\left(b\del^A+\del^Bb\right) \\
		&= (ra+sb)\del^A+\del^B(ra+sb).
	\end{align*}
	So we will have that $ra+sb$ witnesses $r\varphi+s\psi\sim r\varphi'+s\psi'$ as soon as we know that $ra+sb$ is degree-$1$, for which we note $(ra+sb)(A_i)=ra(A_i)+sb(A_i)\subseteq rB_{i+1}+sB_{i+1}\subseteq B_{i+1}$ for any index $i$.
\end{proof}
With those annoying checks out of the way, we show the main point of introducing chain homotopy.
\begin{proposition} \label{prop:homotopyequalizeshomology}
	Fix homotopically equivalent chain morphisms $\varphi,\psi:\left(A,\del^A\right)\to\left(B,\del^B\right)$. Then, for any index $i$, we have $H_i(\varphi)=H_i(\psi)$.
\end{proposition}
\begin{proof}
	Fix $\gamma:=\varphi-\psi$, for which we note $\varphi\sim\psi$ implies $\gamma=(\varphi-\psi)\sim(\psi-\psi)=0$ by \autoref{lem:rlinearchainhomotopy}. We claim that $H_i(\gamma)=0$, which will be enough because it will show by \autoref{lem:rlinearhomology} that
	\[H_i(\varphi)-H_i(\psi)=H_i(\varphi-\psi)=H_i(\gamma)=0,\]
	thus finishing.

	So it remains to show $\gamma\sim0$ implies $H(\gamma)=0$. To start, we are promised a chain homotopy $h$ such that
	\[\gamma=\gamma-0=h\del^A-\del^Bh.\]
	Now, pick up any element $[a]_{\im\del^A_{i+1}}\in H_i(A)$ so that we want to show $\gamma\big([a]_{\im\del^A_{i+1}}\big)=0\in H_i(B)$. Well, we compute
	\[H_i(\gamma)\big([a]_{\im\del^A_{i+1}}\big)=[\gamma a]_{\im\del^B_{i+1}},\]
	from which we note $a\in\ker\del^A_i$ implies
	\[\gamma(a)=\left(h_{i-1}\del^A_i+\del^B_{i+1}h_i\right)(a)=h_{i-1}(0)+\del^B_{i+1}(h_ia)\in\im\del^B_{i+1},\]
	so we do indeed have $H_i(\gamma)\big([a]_{\im\del^A_{i+1}}\big)=[0]_{\im\del^B_{i+1}}$, finishing.
\end{proof}

\subsection{The Long Exact Sequence}
To close out class, we discuss the long exact sequence. The statement is as follows.
\begin{theorem} \label{thm:les}
	Fix
	\[0\to A\stackrel\varphi\to B\stackrel\psi\to C\to0\]
	a short exact sequence of chain complexes. Then there is a long exact sequence of homology
	\[\cdots\to H_i(A)\stackrel{H_i(\varphi)}\to H_i(B)\stackrel{H_i(\psi)}\to H_i(C)\stackrel{\delta_i}\to H_{i-1}(A)\to\cdots,\]
	for some connecting morphisms $\delta_i$.
\end{theorem}
This is a particularly slick application of the Snake lemma, which is as follows.
\begin{lemma}[Snake] \label{lem:snake}
	Fix a ``snake'' (commutative) diagram as follows.
	% https://q.uiver.app/?q=WzAsOCxbMSwwLCJBIl0sWzIsMCwiQiJdLFszLDAsIkMiXSxbMSwxLCJBJyJdLFsyLDEsIkInIl0sWzMsMSwiQyciXSxbNCwwLCIwIl0sWzAsMSwiMCJdLFsxLDIsImciXSxbMiw2XSxbNywzXSxbMyw0LCJmJyJdLFs0LDUsImcnIl0sWzAsMSwiZiJdLFswLDMsImEiXSxbMSw0LCJiIl0sWzIsNSwiYyJdXQ==
	\[\begin{tikzcd}
		& A & B & C & 0 \\
		0 & {A'} & {B'} & {C'}
		\arrow["g", from=1-3, to=1-4]
		\arrow[from=1-4, to=1-5]
		\arrow[from=2-1, to=2-2]
		\arrow["{f'}", from=2-2, to=2-3]
		\arrow["{g'}", from=2-3, to=2-4]
		\arrow["f", from=1-2, to=1-3]
		\arrow["a", from=1-2, to=2-2]
		\arrow["b", from=1-3, to=2-3]
		\arrow["c", from=1-4, to=2-4]
	\end{tikzcd}\]
	The following are true.
	\begin{listalph}
		\item There is an exact sequence
		\[\ker a\stackrel f\to\ker b\stackrel g\to\ker c\stackrel\delta\to\coker a\stackrel{f'}\to\coker b\stackrel{g'}\to\coker c,\]
		where $\ker x\stackrel h\to\ker y$ is restriction, $\delta$ is the connecting morphism, and $\coker x\stackrel{h'}\to\coker y$ is induced by $h'$ by modding out.
		\item If $f$ is injective, then $\ker a\stackrel f\to\ker b$ is injective.
		\item If $g'$ is surjective, then $\coker b\stackrel{g'}\to\coker c$ is surjective.
	\end{listalph}
\end{lemma}
\begin{proof}
	The point is to prove (a), and we will show (b) and (c) in the process. We will show that each of the maps are well-defined for (a), but we will not do the exactness checks because they should not be read. Indeed, readers are encouraged to not read this proof at all (except, perhaps, for the definition of $\delta$) and attempt a proof on their own.
	\begin{itemize}
		\item We construct $\delta$. In short, we define
		\[\delta:=(f')^{-1}\circ b\circ g^{-1}.\]
		In more words, fix some $z\in\ker c$. Then we use the surjectivity of $g$ to pull $z$ back and find $y\in B$ such that $g(y)=z$. From there, we push $y$ forwards to $b(y)$, from which we note
		\[g'(b(y))=(g'\circ b)(y)=(c\circ g)(y)=c(g(y))=c(z)=0\]
		because $z\in\ker c$. Thus, $b(y)\in\ker g'$, but $\ker g'=\im f'$ by exactness, so we can pull back $b(y)\in\im f'$ to some $x'\in A'$ such that $f'(x')=b(y)$. In particular, $x'$ is unique given $b(y)$ because $f'$ is injective by exactness.

		The above does not describe a well-defined map $\ker c\to A'$ because pulling $z\in C$ back yo $y\in B$ with $g(y)=z$ is unique. However, we can fix this: if we pick up $y_1,y_2\in B$ such that $g(y_1)=g(y_2)=z$, then $g(y_1-y_2)=z-z=0$, so
		\[y_1-y_2\in\ker g=\im f\]
		by exactness. So find some $x\in A$ such that $f(x)=y_1-y_2$. Then, when we pull $b(y_1)$ and $b(y_2)$ back along $f'$ to $x_1'$ and $x_2'$ respectively, we see that
		\[f'(x_1'-x_2')=f'(x_1')-f'(x_2')=b(y_1)-b(y_2)=b(y_1-y_2)=(bf)(x)=(f'a)(x)=f'(a(x)),\]
		so $x_1'-x_2'=a(x)\in\im a$ by injectivity of $f'$. Thus, $x_1'$ and $x_2'$ do live in the same coset in $\coker a$, so we have a well-defined map $\delta:\ker c\to\coker a$.

		\item To construct the maps $\ker x\stackrel h\to\ker y$ by restriction, we fix the following square to focus on.
		% https://q.uiver.app/?q=WzAsNCxbMCwwLCJYIl0sWzEsMCwiWSJdLFswLDEsIlgnIl0sWzEsMSwiWSciXSxbMCwxLCJoIl0sWzIsMywiaCciLDJdLFswLDIsIngiLDJdLFsxLDMsInkiXV0=&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
		\[\begin{tikzcd}
			X & Y \\
			{X'} & {Y'}
			\arrow["h", from=1-1, to=1-2]
			\arrow["{h'}"', from=2-1, to=2-2]
			\arrow["x"', from=1-1, to=2-1]
			\arrow["y", from=1-2, to=2-2]
		\end{tikzcd}\tag{$*$}\label{eq:basicsquare}\]
		(Notably, we are applying this to the square with $\{A,B,A',B'\}$ and the square with $\{B,C,B',C'\}$.) We need to show that $h$ restricted to $\ker x$ outputs into $\ker y$. Well, any $a\in\ker x$ will have
		\[y(h(a))=(y\circ h)(a)=(h'\circ x)(a)=h'(x(a))=0\]
		by the commutativity of \autoref{eq:basicsquare}. Thus, we have an induced map $h:\ker x\to\ker y$ by restriction.

		To close, we note that we can show (b) without tears: the map $\ker a\stackrel f\to\ker b$ is $f$ on restriction, so this map is injective for free when $f$ is injective. Indeed, $f(x)=f(y)$ for $x,y\in\ker a$ implies $x=y$ because $f$ is injective.

		\item To construct the maps $\ker x\stackrel{h'}\to\ker y$ by restriction, we fix the same square \autoref{eq:basicsquare}; again, we are applying this to the square with $\{A,B,A',B'\}$ and the square with $\{B,C,B',C'\}$.
		
		We need to induce a map $\coker x\to\coker y$. The main point is to show that $h'$ sends $\im x$ to $\im y$. Indeed, for any $x(a)\in\im x$, we see that
		\[h'(x(a))=(h'\circ x)(a)=(y\circ h)(a)=y(h(a))\in\im y\]
		by the commutativity of \autoref{eq:basicsquare}. Thus, we have an induced map $h':\im x\to\im y$ by restriction. In particular, we can take the composite
		\[X'\stackrel{h'}\to Y'\onto Y'/\im y=\coker y\]
		and mod out by $\im x$ in the front because $h'(\im x)\subseteq\im y$. So this is exactly our map $\coker x\to\coker y$; explicitly, we are sending $[x']\mapsto[h'(x')]$.

		To close, we note that we can show (c) without tears: the map $\coker b\stackrel{g'}\to\coker c$ is $g'$ on modding out, so this map is surjective for free when $g'$ is surjective. Indeed, for any $[c']\in\coker c$, there is $b'\in B'$ with $g'(b')=c'$, so $[c']=[g'(b')]$ lives in the image of the induced map of $g'$.
	\end{itemize}
	So far we have constructed the maps in the exact sequence for (a) and showed (b) and (c). As stated above, we will omit the exactness checks for (a).
\end{proof}
We now proceed with the proof of \autoref{thm:les}.
\begin{proof}[Proof of \autoref{thm:les}]
	The main idea is to use \autoref{lem:snake} to induce an exact sequence as follows.
	% https://q.uiver.app/?q=WzAsNixbMCwwLCJIX2koQSkiXSxbMSwwLCJIX2koQikiXSxbMiwwLCJIX2koQykiXSxbMCwxLCJIX3tpLTF9KEEpIl0sWzEsMSwiSF97aS0xfShCKSJdLFsyLDEsIkhfe2ktMX0oQykiXSxbMCwxLCJIX2koXFx2YXJwaGkpIl0sWzEsMiwiSF9pKFxccHNpKSJdLFsyLDMsIlxcZGVsdGFfaSIsMV0sWzMsNCwiSF97aS0xfShcXHZhcnBoaSkiLDJdLFs0LDUsIkhfe2ktMX0oXFxwc2kpIiwyXV0=&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{H_i(A)} & {H_i(B)} & {H_i(C)} \\
		{H_{i-1}(A)} & {H_{i-1}(B)} & {H_{i-1}(C)}
		\arrow["{H_i(\varphi)}", from=1-1, to=1-2]
		\arrow["{H_i(\psi)}", from=1-2, to=1-3]
		\arrow["{\delta_i}"{description}, from=1-3, to=2-1]
		\arrow["{H_{i-1}(\varphi)}"', from=2-1, to=2-2]
		\arrow["{H_{i-1}(\psi)}"', from=2-2, to=2-3]
	\end{tikzcd}\tag{1}\label{eq:lesunit}\]
	As such, we want to create a snake diagram where the terms $H_i(X)=\ker\del^X_i/\im\del^X_{i+1}$ appear as kernels and the terms $H_{i-1}(X)=\ker\del^X_{i-1}/\im\del^X_i$ appear as cokernels. With this in mind, we draw the following diagram.
	% https://q.uiver.app/?q=WzAsOCxbMSwxLCJcXGtlclxcZGVsXkFfe2ktMX0iXSxbMiwxLCJcXGtlclxcZGVsXkJfe2ktMX0iXSxbMywxLCJcXGtlclxcZGVsXkNfe2ktMX0iXSxbMSwwLCJBX2kvXFxpbVxcZGVsX3tpKzF9XkEiXSxbMiwwLCJCX2kvXFxpbVxcZGVsX3tpKzF9XkIiXSxbMywwLCJDX2kvXFxpbVxcZGVsX3tpKzF9XkMiXSxbNCwwLCIwIl0sWzAsMSwiMCJdLFszLDAsIlxcZGVsXkFfaSIsMl0sWzQsMSwiXFxkZWxfaV5CIl0sWzUsMiwiXFxkZWxfaV5DIl0sWzMsNCwiXFx2YXJwaGlfaSJdLFs0LDUsIlxccHNpX2kiXSxbNSw2XSxbNywwXSxbMCwxLCJcXHZhcnBoaV97aS0xfSIsMl0sWzEsMiwiXFxwc2lfe2ktMX0iLDJdXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		& {A_i/\im\del_{i+1}^A} & {B_i/\im\del_{i+1}^B} & {C_i/\im\del_{i+1}^C} & 0 \\
		0 & {\ker\del^A_{i-1}} & {\ker\del^B_{i-1}} & {\ker\del^C_{i-1}}
		\arrow["{\del^A_i}"', from=1-2, to=2-2]
		\arrow["{\del_i^B}", from=1-3, to=2-3]
		\arrow["{\del_i^C}", from=1-4, to=2-4]
		\arrow["{\varphi_i}", from=1-2, to=1-3]
		\arrow["{\psi_i}", from=1-3, to=1-4]
		\arrow[from=1-4, to=1-5]
		\arrow[from=2-1, to=2-2]
		\arrow["{\varphi_{i-1}}"', from=2-2, to=2-3]
		\arrow["{\psi_{i-1}}"', from=2-3, to=2-4]
	\end{tikzcd}\tag{2}\label{eq:snake1}\]
	We have the following remarks on \autoref{eq:snake1}.
	\begin{itemize}
		\item As discussed in \autoref{lem:gethomologymorphism}, we see that $\varphi_i$ (respectively, $\psi_i$) maps $\im\del_{i+1}^A$ (respectively, $\del_{i+1}^B$) to $\im\del_{i+1}^B$ (respectively, $\im\del_{i+1}^C$), so we have induced maps $\varphi_i:A_i/\im\del_{i+1}^A\to B_i/\im\del_{i+1}^B$ and $\psi_i:B_i/\im\del_{i+1}^B\to C_i/\im\del_{i+1}^C$. These are our maps along the top.

		Similarly, \autoref{lem:gethomologymorphism} tells us that we have restriction maps $\varphi_{i-1}:\ker\del^A_{i-1}\to\ker\del^B_{i-1}$ and $\psi_{i-1}:\ker\del^B_{i-1}\to\ker\del^C_{i-1}$. These are our maps along the bottom.

		\item The vertical maps $\del^X_i:X_i/\im\del^X_{i-1}\to\ker\del^X_i$ are well-defined because $\left(\del^X\right)^2=0$ implies
		\[\del^X_{i-1}\del^X_i=0\qquad\text{and}\qquad\del^X_i\del^X_{i+1}=0,\]
		so $\del^X_i:X_i\to X_{i-1}$ maps into the kernel of $\del^X_{i-1}$ (by the first equality above) and contains $\im\del^X_{i+1}$ in its kernel (by the second equality above), so we get to induce a map $\del^X_i:X_i/\im\del^X_{i-1}\to\ker\del^X_i$.

		\item We check that the diagram commutes. It will suffice to show that the square
		% https://q.uiver.app/?q=WzAsNCxbMCwxLCJcXGtlclxcZGVsXkFfe2ktMX0iXSxbMSwxLCJcXGtlclxcZGVsXkJfe2ktMX0iXSxbMCwwLCJBX2kvXFxpbVxcZGVsX3tpKzF9XkEiXSxbMSwwLCJCX2kvXFxpbVxcZGVsX3tpKzF9XkIiXSxbMiwwLCJcXGRlbF5BX2kiLDJdLFszLDEsIlxcZGVsX2leQiJdLFsyLDMsIlxcdmFycGhpX2kiXSxbMCwxLCJcXHZhcnBoaV97aS0xfSIsMl1d&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
		\[\begin{tikzcd}
			{A_i/\im\del_{i+1}^A} & {B_i/\im\del_{i+1}^B} \\
			{\ker\del^A_{i-1}} & {\ker\del^B_{i-1}}
			\arrow["{\del^A_i}"', from=1-1, to=2-1]
			\arrow["{\del_i^B}", from=1-2, to=2-2]
			\arrow["{\varphi_i}", from=1-1, to=1-2]
			\arrow["{\varphi_{i-1}}"', from=2-1, to=2-2]
		\end{tikzcd}\]
		commutes for any chain morphism $\varphi:\left(A,\del^A\right)\to\left(B,\del^B\right)$ and then apply this to both squares in the diagram. Well, along the top, we have $[a]$ goes to $[\varphi_ia]$ goes to $\del_i^B\varphi_i(a)$; along the bottom, we have $[a]$ goes to $\del_i^Aa$ goes to $\varphi_{i-1}\del_i^Aa$. These outputs are equal because $\varphi$ is a chain morphism.
	\end{itemize}
	We will show that \autoref{eq:snake1} has exact rows as an application of \autoref{lem:snake}. Assuming this for a moment, we note that applying \autoref{lem:snake} directly to \autoref{eq:snake1}: note $\ker\del_i^X$ consists of the cosets of $[x]=X_i/\im\del_{i+1}^X$ such that $x\in\ker\del_i^X$, which is simply $\ker\del_i^X/\im\del_{i+1}^X=H_i(X)$. Similarly, $\coker\del_i^X$ is $\ker\del_{i-1}^X$ modded out by the image of $X_i/\im\del_{i+1}^X$, which is just the image of $X_i$, so we have $\coker\del_i^X=\ker\del_{i-1}^X/\im\del_i^X$. Thus, \autoref{lem:snake} gives us an exact sequence as follows.
	% https://q.uiver.app/?q=WzAsNixbMCwwLCJIX2koQSkiXSxbMSwwLCJIX2koQikiXSxbMiwwLCJIX2koQykiXSxbMCwxLCJIX3tpLTF9KEEpIl0sWzEsMSwiSF97aS0xfShCKSJdLFsyLDEsIkhfe2ktMX0oQykiXSxbMCwxLCJcXHZhcnBoaV9pIl0sWzEsMiwiXFxwc2lfaSJdLFsyLDMsIlxcZGVsdGFfaSIsMV0sWzMsNCwiXFx2YXJwaGlfe2ktMX0iLDJdLFs0LDUsIlxccHNpX3tpLTF9IiwyXV0=&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{H_i(A)} & {H_i(B)} & {H_i(C)} \\
		{H_{i-1}(A)} & {H_{i-1}(B)} & {H_{i-1}(C)}
		\arrow["{\varphi_i}", from=1-1, to=1-2]
		\arrow["{\psi_i}", from=1-2, to=1-3]
		\arrow["{\delta_i}"{description}, from=1-3, to=2-1]
		\arrow["{\varphi_{i-1}}"', from=2-1, to=2-2]
		\arrow["{\psi_{i-1}}"', from=2-2, to=2-3]
	\end{tikzcd}\]
	Very quickly, we note that $\varphi_i$ along the top sends $[a]\in A_i/\im\del_{i+1}^A$ to $[\varphi_ia]=H_i(\varphi)([a])$, so this map is $H_i(\varphi)$; in the same way, $\psi_i$ along the top is $H_i(\psi)$. Further, $\varphi_{i-1}$ along the bottom sends $[a]\in\ker\del_{i-1}^A/\im\del_i^A$ to $[\varphi_{i-1}a]=H_{i-1}(\varphi)[a]$; in the same way, $\psi_{i-1}$ along the bottom is $H_{i-1}(\psi)$. Thus, we have exhibited \autoref{eq:lesunit}; superimposing the shifts of \autoref{eq:lesunit} gives the desired long exact sequence.

	It remains to show that \autoref{eq:snake1} has exact rows. After shifting indices in the top and bottom rows together and noting $X_i/\im\del_{i+1}^X=\coker\del_{i+1}^X$, it suffices to show that the sequence
	\[0\to\ker\del_i^A\stackrel{\varphi_i}\to\ker\del_i^B\stackrel{\psi_i}\to\ker\del_i^C\stackrel\delta\to\coker\del_i^A\stackrel{\varphi_i}\to\coker\del_i^B\stackrel{\psi_i}\to\coker\del_i^C\to0\]
	is exact, for some connecting morphism $\delta$. (The exactness of left half gives exactness of the bottom row of \autoref{eq:snake1}, and the exactness of the right half gives exactness of the top row of \autoref{eq:snake1}.) Notably, the maps between kernels are by restriction, and the maps between cokernels are induced. Well, looking at \autoref{lem:snake}, we draw the following diagram.
	% https://q.uiver.app/?q=WzAsMTAsWzEsMCwiQV9pIl0sWzIsMCwiQl9pIl0sWzMsMCwiQ19pIl0sWzEsMSwiQV97aSsxfSJdLFsyLDEsIkJfe2krMX0iXSxbMywxLCJDX3tpKzF9Il0sWzAsMCwiMCJdLFswLDEsIjAiXSxbNCwwLCIwIl0sWzQsMSwiMCJdLFs2LDBdLFswLDEsIlxcdmFycGhpX2kiXSxbMSwyLCJcXHBzaV9pIl0sWzIsOF0sWzcsM10sWzMsNCwiXFx2YXJwaGlfe2krMX0iLDJdLFs0LDUsIlxccHNpX3tpKzF9IiwyXSxbNSw5XSxbMCwzLCJcXGRlbF9pXkEiLDJdLFsxLDQsIlxcZGVsX2leQiJdLFsyLDUsIlxcZGVsX2leQyJdXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		0 & {A_i} & {B_i} & {C_i} & 0 \\
		0 & {A_{i+1}} & {B_{i+1}} & {C_{i+1}} & 0
		\arrow[from=1-1, to=1-2]
		\arrow["{\varphi_i}", from=1-2, to=1-3]
		\arrow["{\psi_i}", from=1-3, to=1-4]
		\arrow[from=1-4, to=1-5]
		\arrow[from=2-1, to=2-2]
		\arrow["{\varphi_{i+1}}"', from=2-2, to=2-3]
		\arrow["{\psi_{i+1}}"', from=2-3, to=2-4]
		\arrow[from=2-4, to=2-5]
		\arrow["{\del_i^A}"', from=1-2, to=2-2]
		\arrow["{\del_i^B}", from=1-3, to=2-3]
		\arrow["{\del_i^C}", from=1-4, to=2-4]
	\end{tikzcd}\]
	The diagram commutes and is exact because we are supposed to start with a short exact sequences of complexes. Thus, \autoref{lem:snake} gives us a short exact sequence
	\[0\to\ker\del_i^A\stackrel{\varphi_i}\to\ker\del_i^B\stackrel{\psi_i}\to\ker\del_i^C\stackrel\delta\to\coker\del_i^A\stackrel{\varphi_i}\to\coker\del_i^B\stackrel{\psi_i}\to\coker\del_i^C\to0,\]
	which is exactly what we need; note that the maps between kernels are by restriction and the maps between cokernels are induced, so we did provide exactness of the correct sequence of morphisms. (In particular, we get the $0$s on the ends of the above exact sequence by (b) and (c) of \autoref{lem:snake}.)
\end{proof}