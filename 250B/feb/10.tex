% !TEX root = ../notes.tex

Here we go.

\subsection{Unique Factorization Domains}

We start with the following result; it is due to Gauss.
\begin{theorem} \label{thm:rxisufd}
	Fix $R$ a unique factorization domain. Then $R[x]$ is a unique factorization domain.
\end{theorem}
\begin{proof}
	The main character in our story is as follows.
	\begin{definition}[Content]
		Fix $R$ a ring and $f(x)=a_0x^0+\cdots+a_nx^n\in R[x]$. Then we define the \textit{content} of $f$ to be the ideal
		\[\op{cont}(f):=(a_0,\ldots,a_n)\subseteq R.\]
	\end{definition}
	\begin{remark}[Nir]
		This definition always looked unnatural until I realized that it does in fact preserve some structure of $R[x]$. For example, for $r\in R$ and $f(x)=a_0x^0+\cdots+a_nx^n\in R[x]$, we see $(rf)(x)=ra_0x^0+\cdots+ra_nx^n$ so that
		\[\op{cont}(rf)=(ra_0,\ldots,ra_n)=r(a_0,\ldots,a_n)=r\op{cont}(f).\]
		Additionally, we can show $\op{cont}(f(x+r))=\op{cont}(f(x))$. By symmetry, it suffices for $\op{cont}(f(x+r))\subseteq\op{cont}(f(x))$, for which we note
		\[f(x+r)=\sum_{k=0}^na_k(x+r)^k=\sum_{k=0}^n\left(\sum_{\ell=0}^ka_k\binom k\ell x^\ell r^k\right)=\sum_{\ell=0}^n\left(\sum_{k=\ell}^n\binom k\ell r^ka_k\right)x^\ell\]
		has all coefficients in $\op{cont}(f)$.
	\end{remark}
	Here is the main claim.
	\begin{lemma}[Gauss] \label{lem:gauss}
		Fix $R$ a ring and $f,g\in R[x]$. Then $\op{cont}(fg)\subseteq\op{cont}(f)\op{cont}(g)\subseteq\rad\op{cont}(fg)$.
	\end{lemma}
	\begin{proof}
		We show the inclusions independently.
		\begin{itemize}
			\item That $\op{cont}(fg)\subseteq\op{cont}(f)\op{cont}(g)$ is easier. We write out
			\[f(x)=\sum_{k=0}^\infty a_kx^k\qquad\text{and}\qquad g(x)=\sum_{\ell=0}^\infty b_\ell x^\ell,\]
			where all but finitely many of the $a_k$ and $b_\ell$ vanish. Then
			\[(fg)(x)=\sum_{n=0}^\infty\left(\sum_{k+\ell=n}a_kb_\ell\right)x^n.\]
			Now, by definition, each $a_k$ and $b_\ell$ will have $a_k\in\op{cont}(f)$ and $b_\ell\in\op{cont}(g)$ so that $a_kb_\ell\in\op{cont}(f)\op{cont}(g)$. In particular all coefficients of $fg$ live in $\op{cont}(f)$ and $\op{cont}(g)$, so $\op{cont}(fg)\subseteq\op{cont}(f)\op{cont}(g)$.

			\item The other inclusion $\op{cont}(f)\op{cont}(g)\subseteq\rad\op{cont}(fg)$ is harder. Note that, by \autoref{prop:radprimes},
			\[\rad\op{cont}(fg)=\bigcap_{\op{cont}(fg)\subseteq\mf p}\mf p.\]
			Thus, to show that $\op{cont}(f)\op{cont}(g)\subseteq\rad\op{cont}(fg)$, we will show that $\op{cont}(f)\op{cont}(g)\subseteq\mf p$ for each prime $\mf p$ containing $\op{cont}(fg)$.

			The key trick is to work in $R/\mf p$. Let $\overline p$ denote the image of some $p\in R[x]$ along $R[x]\to(R/\mf p)[x]$. (Importantly, yhe map $R[x]\to(R/\mf p)[x]$ merely mods coefficients.) Because $\op{cont}(fg)\subseteq\mf p$, all the coefficients of $fg$ live in $\mf p$, so
			\[\overline f\cdot\overline g=\overline{fg}=0\]
			in $(R/\mf p)[x]$. But now we see that $R/\mf p$ is an integral domain, so $(R/\mf p)[x]$ is also an integral domain!
			
			So without loss of generality, we take $\overline f=0$ in $(R/\mf p)[x]$, so all of the coefficients of $f$ live in $\mf p$, so $\op{cont}(f)\subseteq\mf p$, so $\op{cont}(f)\op{cont}(g)\subseteq\mf p$. This finishes.
			\qedhere
		\end{itemize}
	\end{proof}
	\begin{remark}[Nir] \label{rem:optimizegauss}
		The above proof actually gave us something which looks a little stronger: for each $\mf p$ containing $\op{cont}(fg)$, we have $\op{cont}(f)\subseteq\mf p$ or $\op{cont}(g)\subseteq\mf p$.
	\end{remark}
	\begin{remark}[Nir] \label{rem:primeslift}
		Here is one way to view Gauss's lemma: if $\mf p$ is prime ideal in $R$, then $\mf pR[x]$ remains prime in $R[x]$. Namely, if $fg\in\mf pR[x]$, then $\op{cont}(fg)\subseteq\mf p$, so \autoref{rem:optimizegauss} forces $\op{cont}(f)\subseteq\mf p$ or $\op{cont}(g)\subseteq\mf p$. In other words, $f\in\mf pR[x]$ or $g\in\mf pR[x]$.
	\end{remark}
	Now, the key to getting unique factorization in $R[x]$ is to get it via unique factorization in $K[x]$, where $K:=\op{Frac}(R)$ is the field of fractions. In particular, recall $K[x]$ is a unique factorization domain because it is a Euclidean domain (see \autoref{ex:fieldpolyufd}).

	Our next step is to create a weak classifiaction of irreducibles in $R[x]$.
	\begin{remark}[Nir] \label{rem:unitslift}
		Additionally, when $R$ is an integral domain the units of $R[x]$ are precisely the units in $R[x]$. Certainly any unit in $R$ will remain a unit in $R[x]$ because the inverse lives in $R\subseteq R[x]$. However, if $u\in R[x]$ is a unit with inverse $v$, then the equation $uv=1$ forces $\deg u=\deg v=0$, so $u,v\in R$, so $u\in R^\times$.
	\end{remark}
	\begin{lemma} \label{lem:irredfracfield}
		Fix $R$ a unique factorization domain. Then if $f$ is a nonconstant irreducible in $R[x]$, then $f$ is irreducible in $K[x]$.
	\end{lemma}
	\begin{proof}
		Fix some nonconstant $f(x)$. We proceed by contraposition; taking $f$ not irreducible in $K[x]$ and showing that it is not irreducible in $R[x]$. Well, in this case we can write $f=g_0h_0$ for some $g_0,h_0\in K[x]$, where $0<\deg g_0,\deg h_0<\deg f$. (Note this factorization exists because $f$ remains not a unit in $K[x]$ because the units in $K[x]$ are constants by \autoref{rem:unitslift}.)
		
		Now we move back to $R[x]$. Callously, let $a\in R$ (respectively, $b\in R$) be the product of all the denominators of all the coefficients of $g_0$ (respecitvely, $h_0$) so that $g:=ag_0$ and $h:=bh_0$ live in $R[x]$. Then we set $r:=ab$, which gives
		\[rf=gh\]
		where $g,h\in R[x]$. Now that we're in $R[x]$, we can talk about the content. To set up our discussion, we use the fact that $R$ is a unique factorization domain to write
		\[r=u\prod_{k=1}^n\pi_k\]
		for some $u\in R^\times$ and some (not necessarily distinct) irreducibles $\pi_k$.

		Note that if $n=0$, then $r=u$ is a unit, so we get the factorization $f=(g/u)h$ in $R[x]$, which witnesses $f$ not being irreducible. (In particular, $g/u$ and $h$ are not units by \autoref{rem:unitslift}.) So we claim that we can find some triple $(r,g,h)$ consisting of elements $r\in R$ and $g,h\in R[x]$ where $rf=gh$ and $n=0$. Because we already have such an example, we choose $r$ to have minimal $n$.

		To finish, suppose for the sake of contradiction\footnote{It is possible to remove the contradiction by doing induction on $n$, showing that ``for any $n$, there exists a triple $(r,g,h)$ where $r$ is a unit.''} $n>1$ so that $r$ is divisible by the irreducible element $\pi_n$. Because $R$ is a unique factorization domain, \autoref{rem:ufdimpliesirredisprime} tells us $(\pi_n)$ is prime. So by \autoref{rem:optimizegauss}, we see $gh\in(\pi_1)R[x]$ implies $\op{cont}(gh)\in(\pi_1)$ implies
		\[\op{cont}(g)\subseteq(\pi_n)\qquad\text{or}\qquad\op{cont}(h)\subseteq(\pi_n).\]
		So without loss of generality, we take $\op{cont}(g)\subseteq(\pi_1)$, so all coefficients of $f$ are divisible by $\pi_n$, so $g/\pi_n\in R[x]$, so we can write
		\[(r/\pi_n)f=(g/\pi_n)h,\]
		so we have a triple $(r/\pi_n,g/\pi_n,h)$ where $r/\pi_n$ has strictly fewer irreducibless than $r$. This contradicts the minimality of $r$, finishing.
	\end{proof}
	% To finish checking that $R[x]$ is a unique factorization domain, we recall that it suffices to show all irreducibles are prime.
	We can extend our classification to show that all irreducibles are prime in $R[x]$.
	\begin{remark}[Nir] \label{rem:irredslift}
		Taking $R$ to be an integral domain, we note $\pi\in R$ an irreducible in $R$ will remain irreducible in $R[x]$. Indeed, degrees add in integral domains, so if $f,g\in R[x]$ have $fg=\pi$, then $\deg f=\deg g=0$, so $f,g\in R$. In particular, $\pi=fg$ now forces one of $f$ or $g$ to be a unit in $R$ and hence a unit in $R[x]$.
	\end{remark}
	\begin{lemma} \label{lem:classifyirreds}
		Fix $R$ a unique factorization domain. If $f$ is irreducible in $R[x]$, then either
		\begin{itemize}
			\item $f$ is a constant irreducible in $R$, or
			\item $f$ is a (nonconstant) irreducible in $K[x]$, and $\op{cont}(f)\not\subseteq(\pi)$ for any irreducible $\pi\in R$.
		\end{itemize}
		In either case, $f$ is prime in $R[x]$.
	\end{lemma}
	\begin{proof}
		Observe that, if $f$ is a constant, then $f$ will be irreducible in $R$ automatically: writing $f=ab$ for any $a,b\in R$ forces one of $a$ or $b$ to be a unit in $R[x]$ and hence in $R$ (see \autoref{rem:unitslift}). So because $R$ is a unique factorization domain, \autoref{rem:ufdimpliesirredisprime} gives $(f)$ is prime in $R$, so \autoref{rem:primeslift} gives $(f)$ is prime in $R[x]$ as well.

		Otherwise, $f$ is a nonconstant irreducible in $R[x]$. Thus, it is irreducible and hence prime in $K[x]$ by \autoref{lem:irredfracfield}. In particular, if $f\mid gh$ in $R[x]$ for $g,h\in R[x]$, then $f\mid gh$ in $K[x]$ as well (namely, the quotient lives in $R[x]\subseteq K[x]$), but because $f$ is prime in $K[x]$, we see $f\mid g$ or $f\mid h$ in $K[x]$.

		Without loss of generality take $f\mid g$; setting $fq_0=g$, we can let $r$ be the product of the denominators of $q_0$ (note $r\ne0$) so that $q:=rq_0\in R[x]$ and gives
		\[fq=rg.\]
		We will now argue akin to \autoref{lem:irredfracfield} to show that $f\mid g$. In particular, we have found some pair $(r,q)\in(R\setminus\{0\})\times R[x]$ such that $fq=rg$, we can find an $r$ with minimal number of irreducible factors in its factorization into irreducibles.

		Note that if $r$ is divisible by no irreducibles, then this will imply that $r$'s factorization into irreducibles merely consists of a unit, so $r\in R^\times$. In particular,
		\[f(q/r)=g,\]
		where $q/r\in R[x]$, implying $f\mid g$ in $R[x]$. This finishes the primality check for $f$.

		Otherwise, suppose for the sake of contadiction $\pi\mid r$ for some irreducible in $\pi\in R$. Then $(\pi)$ is a prime ideal by \autoref{rem:ufdimpliesirredisprime}, so \autoref{rem:optimizegauss} tells us that $\op{cont}(fq)\subseteq(\pi)$ implies
		\[\op{cont}(f)\subseteq(\pi)\qquad\text{or}\qquad\op{cont}(q)\subseteq(\pi).\]
		We take the cases separately.
		\begin{itemize}
			\item In the case where $\op{cont}(q)\subseteq(\pi)$, we see $q/\pi\in R[x]$, so we could write
			\[f(q/\pi)=(r/\pi)g\]
			to create an $(r,q)$ pair with strictly fewer irreducibles in $r$, thus violating the minimality of $r$.
			\item In the case where $\op{cont}(f)\subseteq(\pi)$, we see $f/\pi\in R[x]$, so $f=\pi\cdot f/\pi$ provides a factorization of $r$ into non-units: the only units of $R[x]$ are $R^\times$ by \autoref{rem:unitslift}, but $\pi\in R\setminus R^\times$ and $f\notin R$. So this contradicts the irreducibility of $f$.
		\end{itemize}
		We remark that the argument at the end of the second case actually shows that $\op{cont}(f)\not\subseteq(\pi)$ for any irreducible $\pi\in R$.
	\end{proof}
	\begin{remark}[Nir] \label{rem:classifyirreds}
		In fact, \autoref{lem:classifyirreds} is sharp: if $f\in R[x]$ is an irreducible in $R$, then $f$ remains irreducible in $R[x]$ by \autoref{rem:irredslift}.
		
		Otherwise if $f\in R[x]$ is an irreducible in $K[x]$ with $\op{cont}(f)\not\subseteq(\pi)$ for each irreducible $\pi\in R$, then if we factor $f=gh$ where $g,h\in R[x]$, irreducibility in $K[x]$ forces $\deg g=0$ or $\deg h=0$, so without loss of generality $g=0$. But no irreducible $\pi$ may divide $g$ because then it would divide $f$, giving $\op{cont}(f)\subseteq(\pi)$.
	\end{remark}
	The above lemma finishes the proof by \autoref{rem:betterufd}: $R[x]$ is Noetherian by \autoref{thm:hilbasis} and so satisfies the ascending chain condition on principal ideals, and all irreducibles are prime in $R[x]$ by the above lemma.
\end{proof}
\begin{corollary}
	The ring $k[x_1,\ldots,x_n]$ is a unique factorization domain.
\end{corollary}
\begin{proof}
	We induct on $n$: when $n=0$, we note that fields vacuously have unique factorization. The inductive step is to show that $k[x_1,\ldots,x_{n-1}][x_n]$ has unique factorization from $k[x_1,\ldots,x_{n-1}]$, which is precisely \autoref{thm:rxisufd}.
\end{proof}
\begin{example}
	We show that $\left(y^2-x^3\right)\subseteq k[x,y]$ is prime. Because $k[x,y]$ is a unique factorization domain, it suffices to show that $y^2-x^3$ is irreducible in $k[x,y]=k[x][y]$, for which it suffices to show that $y^2-x^3$ is irreducible in $k(x)[y]$ by \autoref{rem:classifyirreds}.
	
	But $y^2-x^3$ is a quadratic in $k(x)[y]$ and therefore irreducible because it has no roots: there is no $y=f(x)/g(x)$ such that $f(x)^2/g(x)^2=x^3$ because this gives
	\[f(x)^2=x^3g(x)^2,\]
	which fails by degree arguments. Namely, $f,g\ne0$, and $\deg\left(f(x)^2\right)$ is even while $\deg\left(x^3g(x)^2\right)$ is odd.
\end{example}
\begin{example}
	We show that $\left(y^2-x^3\right)\subseteq k[x,y]$ is prime a different way. Indeed, by sending $x\mapsto t^2$ and $y\mapsto t^3$, there is an embedding
	\[\frac{k[x,y]}{\left(y^2-x^3\right)}\into k\left[t^2,t^3\right]\]
	by a homework problem. So the quotient is a domain, so $\left(y^2-x^3\right)$ is prime.
\end{example}

\subsection{The Cayley--Hamilton Theorem}
Here is the main result we are going to prove.
\begin{theorem}
	Fix $R$ a ring and $A\in R^{n\times n}$ a matrix. Then define $p_A(x):=\det(xI-A)\in R[x]$. Then $p_A(A)=0\in R^{n\times n}$.
\end{theorem}
This statement is usually stated in linear algebra over a field, but it should hold for arbitrary rings.
\begin{proof}
	We need to pick up the following definition.
	\begin{definition}[Adjugate matrix]
		Fix $A\in R^{n\times n}$. Then we define the \textit{adjugate matrix} by
		\[C_{ij}:=(-1)^{ij}\det A_{i,j},\]
		where $A_{i,j}$ is the matrix $A$ without the $i$th row and without the $j$th column.
	\end{definition}
	\begin{example}
		Set
		\[A=\begin{bmatrix}
			a_{11} & a_{12} \\
			a_{21} & a_{22}
		\end{bmatrix}.\]
		Then
		\[C=\begin{bmatrix}
			a_{22} & -a_{21} \\
			-a_{12} & a_{11}
		\end{bmatrix}.\]
		We can verify by hand that $C^\intercal A=(\det A)I$.
	\end{example}
	The central idea behind the adjugate matrix is that it ``almost inverts'' $A$.
	\begin{lemma}
		Fix $A\in R^{n\times n}$ with adjugate matrix $C$. Then $C^\intercal A=(\det A)I$.
	\end{lemma}
	\begin{proof}
		Omitted.
	\end{proof}
	To show the result, the key is to consider the elements of $R$ as living in $\op{End}_R(R)$, alongside with $A$. we define
	\[A(x):=xI-A,\]
	which is a matrix whose entires are in $\op{End}_R(R)$. We can check that this matrix vanishes on each basis vector of $R^n$ when we take $x=A$. Then we see that
	\[C^\intercal(x)A(x)=\det(xI-A)I\]
	will still vanish upon taking $x=A$. Expanding out $\det(xI-A)$ as a polynomial (with coefficients in $\op{End}_R(R)$) finishes.
\end{proof}
Our application to commutative algebra is as follows.
\begin{theorem} \label{thm:betterch}
	Fix $M$ a finitely generated $R$-module with $n$ generators. Further, fix $\varphi\in\op{End}_R(M)$. Then there exists some monic polynomial
	\[p_\varphi=x^n+p_1x^{n-1}+\cdots+p_n\]
	of degree $n$ such that $p_\varphi(\varphi)$ is zero. In fact, if there is an ideal $I\subseteq R$ such that $IM=M$, then $p_k\in I^k$.
\end{theorem}
\begin{proof}
	Let $\{m_1,\ldots,m_n\}$ generate $M$ so that we can use the equations
	\[\varphi(m_i)=\sum_{k=1}^na_{ij}m_j\]
	to give a matrix form for $\varphi$. Then we set $p_\varphi$ to be the characteristic polynomial for $\varphi$, which finishes the first part by the Cayley--Hamilton theorem. For the second part, we note that $IM=M$ can force that $a_{ij}\in I$ for each $i,j$, which upon writing out the coefficients for the characteristic polynomial will finish.
\end{proof}
Let's now see some applications.
\begin{proposition} \label{prop:epiisiso}
	Let $M$ be a finitely generated $R$-module and $\psi\in\op{End}_R(M)$. Then if $\psi$ is surjective, then $\psi$ is an isomorphism.
\end{proposition}
\begin{proof}
	The key trick is to give $M$ an $R[t]$-module structure to $M$ by defining $R[t]\mapsto\op{End}_RM$ by sending $t\mapsto\psi$.
	In particular, using the above, we get some $p_{\id}$ such that $p_{\id}({\id})=0$.
	Further, because $\psi$ is surjective, we see that $(t)\cdot M=M$, so when we write out
	\[p_{\id}(x)=x^n+p_1x^{n-1}+\cdots+p_n,\]
	we see that $p_i\in\left(t^i\right)$ for each $i$. In particular, plugging in $x=\id$, we see that
	\[0=\id{}+t\cdot q(t)\]
	for some $q\in R[t]$. In particular, $t$ is invertible with inverse $q(t)$.
\end{proof}
\begin{remark}
	This need not be true even in vector spaces which are not finitely generated. For example, consider
	\[V:=\bigoplus_{i=1}^\infty kv_i\]
	for some vectors $\{v_i\}_{i=1}^\infty$. Then we have the surjective map defined by $v_1\mapsto0$ and $v_i\mapsto v_{i-1}$ for $i>1$, and this is not an isomorphism.
\end{remark}
\begin{remark}
	This definitely need not be true for injections giving isomorphisms. For example, $\ZZ\to2\ZZ\into\ZZ$ is injective but not an isomorphism.
\end{remark}
\begin{corollary}
	Fix $m$ and $n$ positive integers. Then if $R^n\cong R^m$ is an isomorphism of $R$-modules. Then $m=n$.
\end{corollary}
\begin{proof}
	Without loss of generality take $n\ge m$. Then we can construct a surjective map
	\[R^m\cong R^n\onto R^m,\]
	which must be an isomorphism by \autoref{prop:epiisiso}. However, the map $R^n\onto R^m$ by projection has a kernel whenever $n>m$, so the composite would have a kernel, which is our contradiction. So we must have $n=m$.
\end{proof}

\subsection{Nakayama's Lemma}
Recall the definition.
\begin{definition}[Jacobson radical]
	Fix a ring $R$. Then we define the \textit{Jacobson radical} by
	\[\rad R:=\bigcap_{\mf m}\mf m.\]
\end{definition}
Observe that $r\in\rad R$ if and only if $1-r\in R^\times$. In particular, $r\in\rad R$ if and only if $1-r$ is not in any maximal ideal if and only if $(1-r)=R$.

We have the following result.
\begin{theorem}[Nakayama's lemma]
	Fix $I\subseteq\op{rad}R$ and $M$ a finitely generated $R$-module. Then if $IM=M$, we have $M=0$.
\end{theorem}
\begin{proof}
	The main idea is in the following lemma.
	\begin{lemma}
		Fix everything as above. Then $IM=M$ implies that there is some $r\in I$ such that $(1-r)M=0$.
	\end{lemma}
	\begin{proof}
		The idea is, as usual, to use \autoref{thm:betterch}. We are promised some polynomial
		\[p_{\id}(x):=x^n+p_1x^{n-1}+\cdots+p_n,\]
		where $p_k\in I^k$. But plugging in $x=\id$ gives the result after rearranging for $\id^n=\id$.
	\end{proof}
	From this lemma the result directly follows because the promised $1-r$ is a unit.
\end{proof}
\begin{corollary}
	Fix $I\subseteq\op{rad}R$ and $M$ a finitely generated $R$-module with elements $m_1,\ldots,m_n\in M$. Then if the images $\overline{m_1},\ldots,\overline{m_n}$ generate $M/IM$, then the original elements generate $M$.
\end{corollary}
\begin{proof}
	Consider
	\[M':=Rm_1+\cdots+Rm_n.\]
	Then because the given elements generate $M/IM$, we note that $M/M'=I(M/M')$, so $M/M'=0$, so $M=M'$. \todo{find counter: M = Q and I = (2)}
\end{proof}

Here is an application, to localization.
\begin{proposition} \label{prop:localtensorintdomain}
	Fix $R$ a local ring with $M$ and $N$ finitely generated $R$-modules. Then $M\otimes_RN=0$ if and only if $M=0$ or $N=0$.
\end{proposition}
\begin{proof}
	If $M=0$ or $N=0$, then of course $M\otimes_RN=0$.
	
	In the reverse direction, suppose $M\ne0$. Fix $\mf m$ the maximal ideal. Then, because $M$ is finitely generated by some elements, we get a surjective map $M\onto R/\mf m$. Tensoring, we see that
	\[M\otimes_RN\to(R/\mf m)\otimes_RN\to0\]
	is also surjective, but then $R/\mf m\otimes_RN=N/\mf mN$. However, $M\otimes_RN=0$, so $N/\mf mN=0$ for all maximal ideals, so $N=0$.
\end{proof}
\begin{corollary}
	Fix $M$ and $N$ finitely generated $R$-modules. Then $M\otimes_RN=0$ if and only if $\op{Ann}M+\op{Ann}N=R$.
\end{corollary}
\begin{proof}
	If $\op{Ann}M+\op{Ann}N=R$, then $M\otimes_RN=0$ by decomposing $1=a+b$ where $a\in\op{Ann}M$ and $b\in\op{Ann}N$.

	In the other direction, suppose that $I:=\op{Ann}M+\op{Ann}N\subsetneq R$. Putting $I$ in some maximal ideal $\mf m$, we note that we can localize to $R_\mf m$ and then reduce to \autoref{prop:localtensorintdomain}.
\end{proof}
\begin{corollary}
	Fix $M$ and $N$ finitely generated $R$-modules. Then $\op{Supp}(M\otimes_RN)=\op{Supp}M\cap\op{Supp}N$.
\end{corollary}
\begin{proof}
	Fix a prime $\mf p$. Then we see that
	\[(M\otimes_RN)_\mf p=M_\mf p\otimes_{R_\mf p}N_\mf p\]
	will vanish if and only if $M_\mf p=0$ or $N_\mf p=0$ (in particular, $R_\mf p$ is local with unique maximal ideal $\mf pR_\mf p$, so \autoref{prop:localtensorintdomain} applies), which is precisely the statement after negation.
\end{proof}
We note that the condition that $M$ and $N$ are finitely generated is crucial.
\begin{nex}
	We note that $\QQ\otimes_\ZZ\ZZ/n\ZZ=0$ because $\QQ$ is divisible and $\ZZ/n\ZZ$ is torsion. But $\QQ\ne0$ and $\ZZ/n\ZZ\ne0$.
\end{nex}

\subsection{Integrality Preview}
We will spend the rest of class on the following theorem.
\begin{prop}
	Fix $R$ a ring and an $R$-algebra $S:=R[s]/I$ for some ideal $I$. We have the following.
	\begin{listalph}
		\item $S$ is finitely generated as an $R$-module if and only if $I$ contains a monic polynomial (i.e., there is some monic $p(x)\in R[x]$ such that $p(s)=0$).
		\item $S$ is a free, finitely generated $R$-module if $I=(p)$ for some monic polynomial $p$.
	\end{listalph}
\end{prop}
\begin{proof}
	Here we go.
	\begin{listalph}
		\item If $S$ is finitely generated as an $R$-module, we apply \autoref{thm:betterch} with $\varphi=\mu_s:m\mapsto sm$ to finish.

		In the other direction, suppose
		\[p(x):=x^n+p_1x^{n-1}+\cdots+p_n\]
		is a polynomial in $I$. Then $\{1,s,s^2,\ldots,s^{n-1}\}$ will generate $S$ over $R$: indeed, it suffices to check that each $s^k$ can be written as an $R$-linear combination of the $\{1,s,\ldots,s^{n-1}\}$, but we get this by induction after noting $p$ promises
		\[s^{n+\ell}=-\sum_{i=0}^{n-1}p_{n-i}s^{i+\ell}.\]

		\item If $S$ is a free, finitely generated $R$-module, we got some monic polynomial in $I$, so we find the nonzero polynomial of least degree. Because the generation is free, using a power basis means we can force this polynomial to be monic, which gives the result.

		The other direction is similar to the other direction above.
		\qedhere
	\end{listalph}
\end{proof}
We close with some definitions.
\begin{definition}[Finite]
	Fix $S$ an $R$-algebra. Then $S$ is \textit{finite} over $R$ if and only if $S$ is finitely geneated over $R$.
\end{definition}
\begin{definition}[Integral]
	Fix $S$ an $R$-algebra. Then $s\in S$ is \textit{integral over $R$} if and only if $s$ is a root of some monic polynomial over $R$. If all elements $s\in S$ are integral over $R$, then we say $S$ is \textit{integral over $R$}.
\end{definition}