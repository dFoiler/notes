% !TEX root = ../notes.tex

We localize more.

\subsection{Flat Modules}
Last time we left off with the right-exactness of the tensor product: a right-exact sequence of $R$-modules
\[A\to B\to C\to 0\]
becomes a right-exact sequence
\[M\otimes_RA\to M\otimes_RB\to M\otimes_RC\to 0\]
for any other $R$-module $M$. More formally, we have the following statement.
\begin{proposition}
	Fix $R$ a ring and $M$ an $R$-module. Then the functor $M\otimes_R-:\mathrm{Mod}_R\to\mathrm{Mod}_R$ is right-exact.
\end{proposition}
\begin{proof}
	This is a restatement of the discussion above.
\end{proof}
However, it is not true that a short exact sequence
\[0\to A\to B\to C\to 0\]
will always become a short exact sequence
\[0\to M\otimes_RA\to M\otimes_RB\to M\otimes_RC\to 0.\]
In fact, this is rather rare! Explicitly, the problem is that $M\otimes_RA\to M\otimes_RB$ might not be injectivem ruining exactness at the front, and this is the only obstruction by right-exactness.
\begin{example}
	We work in $\mathrm{Mod}_\ZZ$, and let $n$ be a positive integer. Then tensoring the short exact sequence
	\[0\to\ZZ\stackrel{\times n}\to\ZZ\to\ZZ/n\ZZ\to0\]
	with $\ZZ/n\ZZ$ will give the commutative diagram
	% https://q.uiver.app/?q=WzAsMTAsWzAsMCwiMCJdLFsxLDAsIlxcWlpcXG90aW1lc19cXFpaXFxaWi9uXFxaWiJdLFsyLDAsIlxcWlpcXG90aW1lc19cXFpaXFxaWi9uXFxaWiJdLFszLDAsIlxcWlovblxcWlpcXG90aW1lc19cXFpaXFxaWi9uXFxaWiJdLFs0LDAsIjAiXSxbMSwxLCJcXFpaL25cXFpaIl0sWzIsMSwiXFxaWi9uXFxaWiJdLFswLDEsIjAiXSxbMywxLCJcXFpaL25cXFpaXFxvdGltZXNfXFxaWlxcWlovblxcWloiXSxbNCwxLCIwIl0sWzAsMV0sWzEsMiwiXFx0aW1lcyBuIl0sWzIsM10sWzMsNF0sWzUsNiwiZiJdLFsxLDVdLFs3LDVdLFsyLDZdLFs2LDhdLFszLDhdLFs4LDldXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		0 & {\ZZ\otimes_\ZZ\ZZ/n\ZZ} & {\ZZ\otimes_\ZZ\ZZ/n\ZZ} & {\ZZ/n\ZZ\otimes_\ZZ\ZZ/n\ZZ} & 0 \\
		0 & {\ZZ/n\ZZ} & {\ZZ/n\ZZ} & {\ZZ/n\ZZ\otimes_\ZZ\ZZ/n\ZZ} & 0
		\arrow[from=1-1, to=1-2]
		\arrow["{\times n}", from=1-2, to=1-3]
		\arrow[from=1-3, to=1-4]
		\arrow[from=1-4, to=1-5]
		\arrow["f", from=2-2, to=2-3]
		\arrow[from=1-2, to=2-2]
		\arrow[from=2-1, to=2-2]
		\arrow[from=1-3, to=2-3]
		\arrow[from=2-3, to=2-4]
		\arrow[from=1-4, to=2-4]
		\arrow[from=2-4, to=2-5]
	\end{tikzcd}\]
	after tracking through the canonical isomorphisms $\ZZ\otimes_\ZZ M\cong M$. But we can see that $f$ here sends $[k]_n$ lifts to $1\otimes[k]_n$, which goes to $n\otimes[k]_n=1\otimes[0]_n$ and therefore is $[0]_n$ downstairs. So $f$ is the zero map and not injective for any $n>1$.
\end{example}
But sometimes left-exactness will be preserved, and this is a property worthy of a name.
\begin{definition}[Flat]
	Fix $R$ a ring. Then an $R$-module $M$ is \textit{flat} if and only if the functor $M\otimes_R-$ is exact.
\end{definition}
\begin{remark}
	As above, we note that $M\otimes_R-$ will always be right-exact, so $M$ will be flat if and only if it preserves the injectivity at the end of a short exact sequence. In other words, $A\into B$ induces $M\otimes_RA\into M\otimes_RB$.
\end{remark}
\begin{example}
	The ring $R$ is a flat module because $R\otimes_RM\cong M$ (canonically). Explicitly, the following diagram commutes because the map $M\cong R\otimes_RM$ is $m\mapsto1\otimes m$.
	% https://q.uiver.app/?q=WzAsNCxbMCwwLCJBIl0sWzEsMCwiQiJdLFswLDEsIlJcXG90aW1lc19SQSJdLFsxLDEsIlJcXG90aW1lc19SQiJdLFswLDEsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzIsMywiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMCwyXSxbMSwzXV0=&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		A & B \\
		{R\otimes_RA} & {R\otimes_RB}
		\arrow[from=1-1, to=1-2]
		\arrow[from=2-1, to=2-2]
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
	\end{tikzcd}\]
	It follows $R\otimes_RA\to R\otimes_RB$ is injective when $A\into B$ is injective because this map is the composite $R\otimes_RA\cong A\into B\cong R\otimes_RB$, which is injective as the composite of injective maps.
\end{example}
\begin{example}
	Any free $R$-module $R^n$ is also flat by using direct sums. In particular, if we have $A\to B$, then the following diagram commutes.
	% https://q.uiver.app/?q=WzAsNCxbMCwwLCJSXm5cXG90aW1lc19SQSJdLFsxLDAsIlJeblxcb3RpbWVzX1JCIl0sWzAsMSwiKFJcXG90aW1lcyBBKV5uIl0sWzEsMSwiKFJcXG90aW1lcyBCKV5uIl0sWzAsMV0sWzIsM10sWzAsMl0sWzEsM11d&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{R^n\otimes_RA} & {R^n\otimes_RB} \\
		{(R\otimes_R A)^n} & {(R\otimes_R B)^n}
		\arrow[from=1-1, to=1-2]
		\arrow[from=2-1, to=2-2]
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
	\end{tikzcd}\]
	Indeed, the map $R^n\otimes_R A\to(R\otimes_R A)^n$ is by $(r_k)_{k=1}^n\otimes a\mapsto(r_k\otimes a)_{k=1}^n$, so the commutativity follows. But we see that $A\into B$ means the individual maps $R\otimes_RA\to R\otimes_RB$ are injective, so the bottom row is injective. Tracking the isomorphisms through, we see the top row is also forced to be injective.
\end{example}

\subsection{Localization via Tensoring}
Now let's return to discussing localization, which plays nicely with the tensor product and flatness.
\begin{proposition}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed subset. Then, for any $R$-module $M$, we have a canonical $R\left[U^{-1}\right]$-module isomorphism
	\[R\left[U^{-1}\right]\otimes_RM\cong M\left[U^{-1}\right]\]
	by $r/u\otimes m\mapsto r/u\cdot m$. (Here, $R\left[U^{-1}\right]\otimes_RM$ is given $R\left[U^{-1}\right]$ by multiplication on the left coordinate.)
\end{proposition}
\begin{proof}
	We define our maps in both directions explcitly. To go $\varphi:M\left[U^{-1}\right]\to R\left[U^{-1}\right]\otimes_RM$, we define
	\[\boxed{\varphi:m/u\mapsto1/u\otimes m}.\]
	For now, we have to check that this is well-defined and an $R\left[U^{-1}\right]$-module homomorphism.
	\begin{itemize}
		\item Well-defined: suppose that $\frac{m_1}{u_1}=\frac{m_2}{u_2}$. Then there is $u\in U$ so that $uu_2m_1=uu_1m_2$. It follows that
		\[\frac1{u_1}\otimes m_1=\left(\frac1{uu_1u_2}\cdot uu_2\right)\otimes m_1=\frac1{uu_1u_2}\otimes uu_2m_1=\frac1{uu_1u_2}\otimes uu_1m_2,\]
		and now running this in reverse shows $\frac1{u_1}\otimes m_1=\frac1{u_2}\otimes m_2$.
		\item Homomorphic: fix $\frac{m_1}{u_1},\frac{m_2}{u_2}\in M\left[U^{-1}\right]\otimes_RM$ and $\frac{s_1}{v_1},\frac{s_2}{v_2}\in R\left[U^{-1}\right]$. Then we compute
		\begin{align*}
			\varphi\left(\frac{s_1}{v_1}\cdot\frac{m_1}{u_1}+\frac{s_2}{v_2}\cdot\frac{m_2}{u_2}\right) &= \varphi\left(\frac{s_1m_1}{v_1u_1}+\frac{s_2m_2}{v_2u_2}\right) \\
			&= \varphi\left(\frac{v_2u_2s_1m_1+v_1u_1s_2m_2}{v_1u_1v_2u_2}\right) \\
			&= \frac1{v_1u_1v_2u_2}\otimes(v_2u_2s_1m_1+v_1u_1s_2m_2) \\
			&= \frac1{v_1u_1v_2u_2}\otimes v_2u_2s_1m_1+\frac1{v_1u_1v_2u_2}\otimes v_1u_1s_2m_2 \\
			&= \frac{s_1}{v_1u_1}\otimes m_1+\frac{s_2}{v_2u_2}\otimes m_2 \\
			&= \frac{s_1}{v_1}\left(\frac1{u_1}\otimes m_1\right)+\frac{s_2}{v_2}\left(\frac1{u_2}\otimes m_2\right) \\
			&= \frac{s_1}{v_1}\varphi\left(\frac{m_1}{u_1}\right)+\frac{s_2}{v_2}\varphi\left(\frac{m_2}{u_2}\right),
		\end{align*}
		which is what we wanted.
	\end{itemize}
	In the other direction, we note that we have a $R$-bilinear map $\psi:R\left[U^{-1}\right]\times M\to M\left[U^{-1}\right]$ by
	\[(r/u,m)\mapsto rm/u.\]
	Quickly, this is well-defined because $\frac{r_1}{u_1}=\frac{r_2}{u_2}$ promises $u$ such that $uu_2r_1=uu_1r_2$, so $uu_2r_1m=uu_1r_2m$, so $\frac{r_1m}{u_1}=\frac{r_2m}{u_2}$. Now, to check $R$-bilinaerity, it suffices to check that
	\[\psi(r/u,r_1m_1+r_2m_2)=\frac{r(r_1m_1+r_2m_2)}u=r_1\cdot\frac{rm_1}u+r_2\cdot\frac{rm_2}{u_2}=r_1\psi(r/u,m_1)+\psi(r/u,m_2),\]
	and
	\[\psi\left(s_1\cdot\frac{r_1}{u_1}+s_2\cdot\frac{r_2}{u_2},m\right)=\psi\left(\frac{u_2s_1r_1+u_1s_2r_2}{u_1u_2},m\right)=s_1\cdot\frac{r_1}{u_1}\cdot m+\frac{r_2}{u_2}\cdot m\]
	after some moving around, which is what we needed.

	The point is that we are promised an $R$-module homomorphism $\psi:R\left[U^{-1}\right]\otimes_RM\to M\left[U^{-1}\right]$ by
	\[\boxed{\psi:r/u\otimes m\mapsto rm/u}\]
	and extending linearly to the full tensor product. It suffices to show $\psi$ is inverse to to $\varphi$, which will show $\varphi$ is an $R\left[U^{-1}\right]$-module isomorphism, and the same will hold for $\psi$, finishing
	\begin{itemize}
		\item Given $m/u\in M\left[U^{-1}\right]$, we note that $(\psi\circ\varphi)(m/u)=\psi(1/u\otimes m)=1m/u=m/u$, so $\psi\circ\varphi=\id_{M\left[U^{-1}\right]}$.
		\item Given $\sum_{k=1}^n(r_k/u_k\otimes m_k)\in R\left[U^{-1}\right]\otimes_RM$, we see that
		\[(\varphi\circ\psi)\left(\sum_{k=1}^n\frac{r_k}{u_k}\otimes m_k\right)=\varphi\left(\sum_{k=1}^n\frac{r_km_k}{u_k}\right)=\sum_{k=1}^n\frac1{u_k}\otimes r_km_k=\sum_{k=1}^n\frac{r_k}{u_k}\otimes m_k,\]
		so $\varphi\circ\psi=\id_{R\left[U^{-1}\right]\otimes_RM}$.
		\qedhere
	\end{itemize}
\end{proof}
\begin{remark} \label{lem:functorialiso}
	The above canonical isomorphism is functorial in the following sense. If we have a map $\varphi:A\to B$, then the following diagram commutes, where all arrows are the induced maps.
	% https://q.uiver.app/?q=WzAsNCxbMCwwLCJSXFxsZWZ0W1Veey0xfVxccmlnaHRdXFxvdGltZXNfUkEiXSxbMSwwLCJSXFxsZWZ0W1Veey0xfVxccmlnaHRdXFxvdGltZXNfUkIiXSxbMCwxLCJBXFxsZWZ0W1Veey0xfVxccmlnaHRdIl0sWzEsMSwiQlxcbGVmdFtVXnstMX1cXHJpZ2h0XSJdLFswLDFdLFsyLDNdLFswLDJdLFsxLDNdXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		{R\left[U^{-1}\right]\otimes_RA} & {R\left[U^{-1}\right]\otimes_RB} \\
		{A\left[U^{-1}\right]} & {B\left[U^{-1}\right]}
		\arrow[from=1-1, to=1-2]
		\arrow[from=2-1, to=2-2]
		\arrow[from=1-1, to=2-1]
		\arrow[from=1-2, to=2-2]
	\end{tikzcd}\]
	Indeed, we take $\frac ru\otimes a\mapsto\frac ru\otimes\varphi(a)\mapsto\frac{r\varphi(a)}u$ along the top, and we take $\frac ru\otimes a\mapsto\frac{ra}u\mapsto\frac{\varphi(ra)}u=\frac{r\varphi(a)}u$ along the bottom.
\end{remark}
The above is nice because it means we technically would only need to check that $R\left[U^{-1}\right]$ exists in order to define localization of general modules. In other words, we have a somewhat unified paradigm to think about localization by merely focusing on tensor products.

As a quick example, we can see that localization commutes with direct sums.
\begin{proposition} \label{prop:localdirectsums}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed subset with $\mathcal M$ a collection of $R$-modules. Then
	\[\left(\bigoplus_{M\in\mathcal M}M\right)\left[U^{-1}\right]\cong\bigoplus_{M\in\mathcal M}M\left[U^{-1}\right]\]
	by sending $\frac1u(m_M)_{M\in\mathcal M}\mapsto\left(\frac{m_M}u\right)_{M\in\mathcal M}$.
\end{proposition}
\begin{proof}
	The main point is that tensor products commute with direct sums. Indeed, we have the canonical isomorphisms
	\[\left(\bigoplus_{M\in\mathcal M}M\right)[U^{-1}]\cong\left(\bigoplus_{M\in\mathcal M}M\right)\otimes_RR[U^{-1}]\stackrel*\cong\bigoplus_{M\in\mathcal M}M\otimes_RR[U^{-1}]\cong\prod_{i=1}^nM\left[U^{-1}\right],\]
	where in $\stackrel*\cong$ we used the fact that tensor products commute with arbitrary direct sums. Actually tracking these isomorphisms through, we see that $\frac1u(m_M)_{M\in\mathcal M}$ goes to $(m_M)_{M\in\mathcal M}\otimes1/u$ goes to $(m_M\otimes1/u)_{M\in\mathcal M}$ goes to $(m_M/u)_{M\in\mathcal M}$, which is what we wanted.
\end{proof}

\subsection{Localization via Flatness}
The following result looks like it's about localization but is actually about flatness.
\begin{proposition} \label{prop:localexact}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed subset. Then localization is an exact functor: given a short exact sequence of $R$-modules
	\[0\to A\to B\to C\to 0,\]
	then we have a short exact sequence of $R\left[U^{-1}\right]$-modules
	\[0\to A\left[U^{-1}\right]\to B\left[U^{-1}\right]\to C\left[U^{-1}\right]\to 0.\]
\end{proposition}
\begin{proof}
	For visual reasons, note that we have the following commutative diagram where the vertical arrows are $R\left[U^{-1}\right]$-module isomorphisms. (The diagram commutes by \autoref{lem:functorialiso}.)
	% https://q.uiver.app/?q=WzAsMTAsWzEsMSwiUlxcbGVmdFtVXnstMX1cXHJpZ2h0XVxcb3RpbWVzX1JBIl0sWzIsMSwiUlxcbGVmdFtVXnstMX1cXHJpZ2h0XVxcb3RpbWVzX1JCIl0sWzMsMSwiUlxcbGVmdFtVXnstMX1cXHJpZ2h0XVxcb3RpbWVzX1JDIl0sWzEsMCwiQVxcbGVmdFtVXnstMX1cXHJpZ2h0XSJdLFswLDAsIjAiXSxbMCwxLCIwIl0sWzIsMCwiQlxcbGVmdFtVXnstMX1cXHJpZ2h0XSJdLFszLDAsIkNcXGxlZnRbVV57LTF9XFxyaWdodF0iXSxbNCwxLCIwIl0sWzQsMCwiMCJdLFswLDFdLFs0LDNdLFs1LDBdLFszLDBdLFszLDZdLFs2LDFdLFs2LDddLFs3LDJdLFs3LDldLFsxLDJdLFsyLDhdXQ==&macro_url=https%3A%2F%2Fraw.githubusercontent.com%2FdFoiler%2Fnotes%2Fmaster%2Fnir.tex
	\[\begin{tikzcd}
		0 & {A\left[U^{-1}\right]} & {B\left[U^{-1}\right]} & {C\left[U^{-1}\right]} & 0 \\
		0 & {R\left[U^{-1}\right]\otimes_RA} & {R\left[U^{-1}\right]\otimes_RB} & {R\left[U^{-1}\right]\otimes_RC} & 0
		\arrow[from=2-2, to=2-3]
		\arrow[from=1-1, to=1-2]
		\arrow[from=2-1, to=2-2]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-2, to=1-3]
		\arrow[from=1-3, to=2-3]
		\arrow[from=1-3, to=1-4]
		\arrow[from=1-4, to=2-4]
		\arrow[from=1-4, to=1-5]
		\arrow[from=2-3, to=2-4]
		\arrow[from=2-4, to=2-5]
	\end{tikzcd}\]
	This is to say that it suffices to show that the bottom row is exact. The right-exactness of the bottom row follows from the fact that it is induced by the tensoring functor $R\left[U^{-1}\right]\otimes_R-$.

	Thus, we only need to show that localization preserves embeddings. Letting $\varphi:A\into B$ be the original map and $\overline\varphi:A\left[U^{-1}\right]\to B\left[U^{-1}\right]$ be the induced map, then we need to check that $\ker\overline\varphi$ is trivial. Well, if $\overline\varphi\left(\frac au\right)=0$ for some $\frac au\in A\left[U^{-1}\right]$, then
	\[\varphi(a)=\overline\varphi(a)=\overline\varphi\left(u\cdot\frac au\right)=u\cdot\overline\varphi\left(\frac au\right)=0.\]
	Because $\ker\varphi$ is trivial, we are forced to $a=0$, so $\frac au=0$, so indeed $\ker\overline\varphi$ is trivial.
\end{proof}
\begin{corollary}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively subset. Then $R\left[U^{-1}\right]$ is flat as an $R$-module.
\end{corollary}
\begin{proof}
	The commutative diagram in the proof of \autoref{prop:localexact} has been shown to have exact rows (over the course of the entire proof). The exactness of the bottom row shows $R\left[U^{-1}\right]$ is flat.
\end{proof}
\begin{corollary} \label{cor:localizekercoker}
	Fix $R$ a ring and $U\subseteq R$ a multiplicative subset. Then let $\varphi:A\to B$ be an $R$-module homomorphism and $\overline\varphi:A\left[U^{-1}\right]\to B\left[U^{-1}\right]$ be the localized morphism. Then
	\[(\ker\varphi)\left[U^{-1}\right]\cong\ker\overline\varphi\quad\text{and}\quad(\coker\varphi)\left[U^{-1}\right]\cong\coker\overline\varphi.\]
	In particular, if $\varphi$ is injective/surjective/isomorphic, then $\overline\varphi$ is injective/surjective/isomorphc.
\end{corollary}
\begin{proof}
	We deal with the kernel and the cokernel separately.
	\begin{itemize}
		\item The main point is that we have the short exact sequence
		\[0\to\ker\varphi\to A\stackrel\varphi\to\im\varphi\to0.\]
		Localizing, we get the short exact sequence
		\[0\to(\ker\varphi)\left[U^{-1}\right]\to A\left[U^{-1}\right]\stackrel{\overline\varphi}\to(\im\varphi)\left[U^{-1}\right]\to0.\]
		By exactness, we see that $(\ker\varphi)\left[U^{-1}\right]\cong\ker\overline\varphi$.
		
		Thus, $\varphi$ being injective implies $\ker\varphi=0$ implies $\ker\overline\varphi=0$ implies $\overline\varphi$ is injective.

		\item The main point is that we have the short exact sequence
		\[0\to A/\ker\varphi\stackrel\varphi\to B\to\coker\varphi\to0,\]
		where $\stackrel\varphi\to$ is actually the induced map. Localizing, we get the short exact sequence
		\[0\to(A/\ker\varphi)\left[U^{-1}\right]\stackrel{\overline\varphi}\to B\left[U^{-1}\right]\to(\coker\varphi)\left[U^{-1}\right]\to0.\]
		By exactness again, we see that $(\coker\varphi)\left[U^{-1}\right]\cong\coker\varphi$.
		
		Thus, $\varphi$ being surjective implies $\coker\varphi=0$ implies $\coker\overline\varphi=0$ implies $\overline\varphi$ is surjective.
	\end{itemize}
	Combining the two points implies that, if $\varphi$ is isomorphic (namely, bijective), then $\overline\varphi$ will be as well.
\end{proof}
Flatness also gives us the following result, which again looks like it's about localization but is really about flatness.
\begin{corollary}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed subset. Then, taking $M_1,\ldots,M_n\subseteq M$ finitely many $R$-modules of some $R$-module $M$, we get
	\[\bigcap_{i=1}^nM_i\left[U^{-1}\right]=\left(\bigcap_{i=1}^nM_i\right)\left[U^{-1}\right].\]
	Note these intersections make sense because the $M_i$ all live inside of $M$.
\end{corollary}
\begin{proof}
	The main point is that intersecitons can be realized as a kernel. Namely, consider the left-exact sequence
	\[0\to\bigcap_{i=1}^nM_i\to M\to\prod_{i=1}^nM/M_i.\tag{$*$}\label{eq:lesintersect}\]
	It is not too hard to check manually that this sequence is in fact left-exact: the map $\bigcap M_i\to M$ is an embedding and hence injective, and $x\in\ker\left(M\to\prod M/M_i\right)$ if and only if $x\in M_i$ for each $M_i$ if and only if $x\in\bigcap M_i$.
	
	Now, we would like to localize \autoref{eq:lesintersect}. Before doing so, we note that \autoref{prop:localdirectsums} gives us the canonical isomorphism
	\[\left(\prod_{i=1}^nM/M_i\right)[U^{-1}]\cong\prod_{i=1}^n(M/M_i)\left[U^{-1}\right],\]
	which is legal because finite products are in fact coproducts. (Here is where we use the finiteness condition!) As in \autoref{prop:localdirectsums}, we can actually track through these isomorphisms as sending $\frac1u([x_k]_{M_i})_{i=1}^n$ to $\left(\frac1u[x_k]_{M_i}\right)_{i=1}^n$.
	
	Continuing, we note that we can compute $(M/M_i)\left[U^{-1}\right]$ by localizing the short exact sequence
	\[0\to M_i\to M\to M/M_i\to 0,\]
	which will tell us that $\frac M{M_i}\left[U^{-1}\right]\cong\frac{M\left[U^{-1}\right]}{M_i\left[U^{-1}\right]}$ by $\frac1u[x]_{M_i}\mapsto\left[\frac xu\right]_{M_i\left[U^{-1}\right]}$. Stitching these isomoprhisms together gives us an isomorphism
	\[\left(\prod_{i=1}^nM/M_i\right)[U^{-1}]\cong\prod_{i=1}^n\frac{M\left[U^{-1}\right]}{M_i\left[U^{-1}\right]}\]
	by taking $\frac1u\left([x_k]_{M_i}\right)_{i=1}^n$ to $\left([\frac{x_k}u]_{M_i\left[U^{-1}\right]}\right)_{i=1}^n$.

	Only now we do localize \autoref{eq:lesintersect}. Upon localization, we get the left-exact sequence\footnote{Being exact implies being left-exact. If this causes discomfort, replace the left-exact sequence $0\to A\to B\to C$ with the short exact sequence $0\to A\to B\to\im(B\to C)\to0$.}
	\[0\to\left(\bigcap_{i=1}^nM_i\right)\left[U^{-1}\right]\to M\left[U^{-1}\right]\to\left(\prod_{i=1}^nM/M_i\right)\left[U^{-1}\right]\cong\prod_{i=1}^n\frac{M\left[U^{-1}\right]}{M_i\left[U^{-1}\right]},\]
	By exactness, we see that to prove the result it remains to compute the kernel of the composite
	\[M\left[U^{-1}\right]\to\left(\prod_{i=1}^nM/M_i\right)\left[U^{-1}\right]\cong\prod_{i=1}^n\frac{M\left[U^{-1}\right]}{M_i\left[U^{-1}\right]}.\]
	Well, this map sends $\frac xu$ to $\frac1u([x]_{M_i})_{i=1}^n$ to $\left([\frac xu]\right)_{i=1}^n$, so the only way for to be in the kernel is for $\frac xu\in M_i\left[U^{-1}\right]$ for each $M_i$. It follows that the kernel is
	\[\bigcap_{i=1}^nM_i\left[U^{-1}\right],\]
	which is what we wanted.
\end{proof}
We need to be careful because localization need not commute with infinite interseciotns.
\begin{example}
	Set $R:=k[x]$ and $U=R\setminus\{0\}$. The main issue is that
	\[\bigcap_{a\in k}(x-a)=(0).\]
	Now, on one hand, $(x-a)\left[U^{-1}\right]=k(x)$ because $U$ is allowed to divide by $(x-a)$. On the other hand, $(0)\left[U^{-1}\right]=(0)$ because no amount of division can make $0$ nonzero. Thus,
	\[\left(\bigcap_{a\in k}(x-a)\right)\left[U^{-1}\right]=(0)\left[U^{-1}\right]=(0)\ne k(x)=\bigcap_{a\in k}(x-a)\left[U^{-1}\right].\]
\end{example}

\subsection{Some Homological Algebra}
We start by discussing a particular adjuction. For the discussion here, fix a ring homomorphism $\psi:R\to S$. Now, if $M$ is an $S$-module, we can give $M$ an $R$-action by
\[r\cdot m:=\psi(r)m,\]
making the $R$-module $\op{Res}_RM$. In the other direction, if $N$ is an $R$-module, we can create an $S$-module $\op{Ind}_R^SN:=S\otimes_RN$, where we get an $S$-action by multiplying on the left coordinate.

Here is our claim.
\begin{proposition}
	Let $R$ and $S$ be rings with a map $\varphi:R\to S$. Then, given an $R$-module $M$ and an $S$-module $N$, we have a canonical isomorphism
	\[\op{Hom}_R(M,\op{Res}_RN)\cong\op{Hom}_S(S\otimes_RM,N).\]
	In other words, tensoring is left-adjoint to restriction.
\end{proposition}
\begin{proof}
	We simply construt the two maps manually.
	\begin{itemize}
		\item Fix $\varphi\in\op{Hom}_R(M,\op{Res}_RN)$. Then we define $\widetilde\varphi\in\op{Hom}_S(S\otimes_RM,S)$ by defining
		\[\widetilde(s\otimes m)=s\varphi(m).\]
		Again, one has to check that this is well-defined, but we will not do so here.

		\item In the other direction, we notice that we havve a map $M\to S\otimes_RM$ by $m\mapsto 1\otimes m$. But composing this map with $\widetilde\varphi$ will give a map $M\to N$ which should provide us with an inverse.\todo{excuse me}
		\qedhere
	\end{itemize}
\end{proof}

Next let's discuss base change. Again, fix a ring homomorphism $\varphi:R\to S$ to make $S$ into an $R$-algebra. Given two $R$-modules named $M$ and $N$, we can form $S$-modules
\[S\otimes_R\op{Hom}_R(M,N)\qquad\text{and}\qquad\op{Hom}_S(S\otimes_RM,S\otimes_RN).\]
In general, there need not be an isomorphism between these $S$-modules, but there is a canonical map from the left to the right.
\begin{lemma} \label{lem:basechange}
	Fix everything as above. Then there is a canonical map
	\[\alpha:S\otimes_R\op{Hom}_R(M,N)\to\op{Hom}_S(S\otimes_RM,S\otimes_RN).\]
\end{lemma}
\begin{proof}
	We start by considering the restriction $\op{Res}_R\op{Hom}_S(S\otimes_RM,S\otimes_RN)$, for which we notice that we have a canonical map
	\[\gamma:\op{Hom}_R(M,N)\to\op{Res}_R\op{Hom}_S(S\otimes_RM,S\otimes_RN),\]
	where the point to check is that $\op{Res}_R$ is a safe move. But then the adjunction above provides a canonical map
	\[\widetilde\gamma:S\otimes_R\op{Hom}_R(M,N)\to\op{Hom}_S(S\otimes_RM,S\otimes_RN),\]
	which finishes. \todo{excuse me}
\end{proof}
We would like this to be an isomorphism. One condition will be that $S$ is flat over $R$; for the other condition we have the following definition.
\begin{definition}[Finitely presented]
	An $R$-module $M$ is \textit{finitely presented} if and only if there are $M$ is finitely generated, and we can find $R^m$ an $R^n$ making the following right-exact sequence
	\[R^m\to R^n\to M\to 0.\]
	In other words, the kernel of $R^n\onto M$ is finitely generated.
\end{definition}
\begin{example}
	For example, if $R$ is Noetherian, then the kernel in $R^n$ will be a submodule and hence finitely generated.\todo{find a counterexanple}
\end{example}
Now, here is the culmination of base change.
\begin{proposition}
	Work in the set-up of \autoref{lem:basechange}. Then if $S$ is flat and $M$ is finitely presented, then the $\alpha$ from \autoref{lem:basechange} is an isomorphism.
\end{proposition}
\begin{proof}
	We begin by writing down the finite presentation
	\[R^m\to R^n\to M\to 0\]
	of $M$. Now, this gives us a left-exact sequence\todo{}
	\[0\to\op{Hom}_R(M,N)\to\op{Hom}_R(R^n,N)\to\op{Hom}_R(R^m,N),\]
	and by flatness of $S$, we get another left-exact sequence
	\[0\to S\otimes_R\op{Hom}_R(M,N)\to S\otimes_R\op{Hom}_R(R^n,N)\to\op{Hom}_R(R^m,N).\]
	Taking $\op{Hom}_S$s now, we can use the tensor-hom adjunction to give us
	\[0\to\op{Hom}_S(S\otimes_RM,S\otimes_RN)\to\op{Hom}_S(S^n\otimes_RN)\to\op{Hom}_S(S^m,S\otimes_RN).\]
	But now we have vertical isomorphisms with the previous short exact sequence in the last two entries, which induces an isomorphism $S\otimes_R\op{Hom}_R(M,N)\cong\op{Hom}_S(S\otimes_RM,S\otimes_N)$, which ends up being $\alpha$.
\end{proof}

\subsection{Support of a Module}
We have the following definition.
\begin{definition}[Support]
	Fix $R$ a ring and $M$ an $R$-module. Then we define the \textit{support} of $M$ to be
	\[\op{Supp}M:=\{\mf p\in\op{Spec}R:M_\mf p\ne0\}.\]
\end{definition}
There is an analogous notion of maximal support using maximal ideals instead of prime ideals.

We can provide a more concrete condition for $M_\mf p=0$. For this, we have the following definition.
\begin{definition}[Annihilator]
	Fix $R$ a ring and $M$ an $R$-module. Then, given an element $m\in M$, we define the \textit{annihilator} of $R$ to be
	\[\op{Ann}m:=\{r\in R:rm=0\}.\]
	Analogously, we define $\op{Ann}M:=\{r\in R:rm=0\text{ for all }m\in M\}=\bigcap_{m\in M}\op{Ann}m$.
\end{definition}
\begin{remark}
	It is not hard to check that these are ideals. If $r_1,r_2\in R$ and $x_1,x_2\in\op{Ann}m$, then
	\[(r_1x_1+r_2x_2)m=r_1(x_1m)+r_2(x_2m)=0\]
	verifies that $r_1x_1+r_2x_2\in\op{Ann}m$, so $\op{Ann}m$ is closed under $R$-linear combination. So $\op{Ann}m$ is an ideal, and the fact $\op{Ann}M$ is an ideal follows by taking the (arbitrary) intersection.
\end{remark}
So here is a characerization of $\op{Supp}M$.
\begin{proposition} \label{prop:generalsupport}
	Fix $R$ a ring and $M$ an $R$-module. Then, given $\mf p\in\op{Spec}R$, we have $M_\mf p\ne0$ if and only if $\op{Ann}m\subseteq\mf p$ for some $m\in M$. In other words,
	\[\op{Supp}M=\bigcup_{m\in M}\{\mf p\in\op{Spec}R:\op{Ann}m\subseteq\mf p\}.\]
\end{proposition}
\begin{proof}
	We proceed by contraposition, showing that $M_\mf p=0$ if and only if $\op{Ann}m\not\subseteq\mf p$ for each $m\in M$.
	
	Note that $M_\mf p=0$ if and only if $\frac mu=0$ for each $m\in M$ and $u\in U$. But note that if $\frac m1=0$ for each $m\in M$, then it follows
	\[\frac mu=\frac1u\cdot\frac1m=0\]
	for any $u\in U$. Thus, it suffices to check that $\frac m1=0$ for each $m\in M$.

	Well, fixing any $m\in M$, we see that $\frac m1=\frac01$ if and only if there is some $u\notin\mf p$ such that $um=0$. In other words, $\frac m1=\frac01$ is equivalent to
	\[(R\setminus\mf p)\cap\op{Ann}m\ne\emp,\]
	which is equivalent to $\op{Ann}m\not\subseteq\mf p$.
\end{proof}
The above characterization of the support is a bit annoying, geometrically speaking, because we are taking an arbitrary union of Zariski-closed sets $\{\mf p\in\op{Spec}R:\op{Ann}m\subseteq\mf p\}$. In the case where $M$ is finitely generated (which is essentially a size constraint on $M$), we can make this arbitrary union into a finite one.
\begin{proposition} \label{prop:fingensupport}
	Fix $R$ a ring and $M$ a finitely generated $R$-module. Then
	\[\op{Supp}M=\{\mf p\in\op{Spec}R:\op{Ann}M\subseteq\mf p\}.\]
\end{proposition}
\begin{proof}
	Of course, taking any $m\in M$, if $\op{Ann}m\subseteq\mf p$ for some $m\in M$, then $\op{Ann}M\subseteq\op{Ann}m\subseteq\mf p$. So \autoref{prop:generalsupport} tells us that
	\[\op{Supp}M=\bigcup_{m\in M}\{\mf p\in\op{Spec}R:\op{Ann}m\subseteq\mf p\}\subseteq\{\mf p\in\op{Spec}R:\op{Ann}M\subseteq\mf p\}.\]
	The other direction requires using that $M$ is finitely generated.

	Well, let $\mf p\notin\op{Supp}M$, and we show that $\op{Ann}M\not\subseteq\mf p$. The fact that $\mf p\notin\op{Supp}M$ implies that $\op{Ann}m\not\subseteq\mf p$ for each $m\in M$; in particular, letting $M$ be generated by $x_1,\ldots,x_n$, we see that each $x_k\in M$ promises $u_k$ such that
	\[u_k\in\op{Ann}x_k\setminus\mf p.\]
	In other words, $u_k\notin\mf p$ and $u_kx_k=0$. But now (by finiteness!) we can set
	\[u:=\prod_{k=1}^nu_k.\]
	Because each of the factors is not in $\mf p$, we conclude $u\notin\mf p$. However, $ux_k=0$ for each of the generators $x_k$, so for any $m=\sum a_kx_k\in M$, we see
	\[um=\sum_{k=1}^nua_kx_k=\sum_{k=1}^na_k\cdot0=0.\]
	It follows that $u\in\op{Ann}M\setminus\mf p$, so $\op{Ann}M\not\subseteq\mf p$.
\end{proof}
In particular, this is a Zariski-closed subset of $\op{Spec}R$!

We close this subsection with some examples.
\begin{example}
	Consider the ring $M:=R$ as an $R$-module. Certainly $0\in\op{Ann}R$, but for $r\in R$ to kill $1$, we need $r=0$, so actually $\op{Ann}R=(0)$. But $(0)$ is contained in every prime ideal of $R$, so $\op{Supp}R=\op{Spec}R$. (Yes, $M=R$ is finitely generated over $R$.)
\end{example}
\begin{ex} \label{ex:emptysupport}
	Fix $R$ a ring and $M=(0)$ the zero module. Then everyone in $R$ will kill $0$, so $\op{Ann}0=R$. It follows from \autoref{prop:generalsupport} that $\op{Supp}(0)=\emp$ because no prime contains $R$.
\end{ex}
To set up our last example, we have the following definition and then statement.
\begin{definition}[Simple]
	Fix $R$ a ring. Then an $R$-module $M$ is said to be \textit{simple} if and only if all $R$-submodules of $M$ are either $(0)$ or $M$.
\end{definition}
\begin{exe}
	Fix $R$ a ring and $M$ a simple nonzero $R$-module. Then the following are true.
	\begin{listalph}
		\item We have that $M\cong R/\op{Ann}M$.
		\item We have that $\op{Ann}M$ is a maximal ideal.
		\item We have that $\op{Supp}M=\{\op{Ann}M\}$.
	\end{listalph}
\end{exe}
\begin{proof}
	We take the claims more or less one at a time.
	\begin{listalph}
		\item Because $M$ is nonzero, we may find $x\in M\setminus\{0\}$. Now, $x$ induces an $R$-module homomorphism map $R\to M$ by $r\mapsto rx$ (indeed, $rs\mapsto rsx$ and $r_1+r_2\mapsto r_1x+r_2x$), and the kernel of this map is $\{r\in R:rx=0\}=\op{Ann}x$. Thus, we have the left-exact sequence of $R$-modules
		\[0\to\op{Ann}x\to R\to M.\]
		However, $M$ is simple! Thus, because the image of $R\to M$ will end up being an $R$-submodule of $M$---and nonzero because it contains $1x=x\ne0$---we see that the image of $R\to M$ must be all of $M$. So in fact we have the short exact sequence
		\[0\to\op{Ann}x\to R\to M\to 0.\]
		In particular, we just showed that $M=\{rx:r\in R\}=Rx$. Of course, $\op{Ann}M\subseteq\op{Ann}x$, but in fact equality holds: each $a\in\op{Ann}x$ will have $a(rx)=r(ax)=0$ for each $rx\in Rx=m$.
	
		Anyways, the point is that $R/\op{Ann}M\cong M$ (non-canonically) by $r\mapsto rx$.

		\item We show that $I:=\op{Ann}M$ is a maximal ideal. Certainly $I\ne R$ because then $M\cong R/R=(0)$ would be zero. Thus, $I$ is proper, so we can find a maximal ideal $\mf m$ such that $I\subseteq\mf m$. But then we consider the composite map $\varphi:M\to R/\mf m$ by
		\[M\cong R/I\to R/\mf m.\]
		Consider $\ker\varphi$. On one hand, note that $\ker\varphi\ne M$ because $\varphi$ is the composite of surjective maps and therefore surjective, and $R/\mf m$ is nonzero ($M$ being nonzero forces $R$ nonzero), so $\varphi$ cannot send all of $M$ to $0$.

		But $\ker\varphi$ is an $R$-submodule of $M$, so instead we must have $\ker\varphi=(0)$. So the composite $\varphi$ is injective, so the map $R/I\to R/\mf m$ is injective. But then $x\in\mf m$ implies $[x]_I\mapsto[x]_\mf m=[0]_\mf m$, so $x\in I$ by injectivity. Thus, $\mf m=I$, and so $I$ is in fact maximal.

		\item Because $R\onto R/\op{Ann}M\cong M$, we see that $M$ is finitely generated, so \autoref{prop:fingensupport} tells us that
		\[\op{Supp}M=\{\mf p\in\op{Spec}R:\op{Ann}M\subseteq\mf p\}.\]
		Now, $\op{Ann}M$ is maximal, so $\op{Ann}M\in\op{Supp}M$, but any prime ideal containing $\op{Ann}M$ must equal $\op{Ann}M$ by maximality. So $\op{Supp}M=\{\op{Ann}M\}$.
		\qedhere
	\end{listalph}
\end{proof}
\begin{remark}
	We can complete our classification of simple $R$-modules: for each maximal ideal $\mf m\subseteq R$, we can see $R/\mf m$ is a simple $R$-module. Indeed, any $R$-submodule $M\subseteq R/\mf m$ is in fact an $R/\mf m$-module, for each $x\in\mf m$ and $m\in M$ has $xm=[0]_\mf m=0$. Thus, $M$ is an $(R/\mf m)$-subspace of $R/\mf m$, so for dimension reasons, $M=(0)$ or $M=R/\mf m$.
\end{remark}

\subsection{New Supports from Old}
Let's see how the support behaves with some of our module constructions. For example, the support behaves well in short exact sequences.
\begin{proposition}
	Fix $R$ a ring. Suppose we have a short exact sequence
	\[0\to A\to B\to C\to 0\]
	of $R$-modules. Then $\op{Supp}B=\op{Supp}A\cup\op{Supp}C$.
\end{proposition}
\begin{proof}
	The main point is that localization is an exact functor. Namely, if $\mf p$ is any prime of $R$, then we get a short exact sequence
	\[0\to A_\mf p\to B_\mf p\to C_\mf p\to0.\]
	In particular, $A_\mf p=C_\mf p=0$ implies $B_\mf p=0$; and conversely, $B_\mf p=0$ implies $A_\mf p=C_\mf p=0$. Thus, $B_\mf p\ne0$ if and only if $A_\mf p\ne0$ or $C_\mf p\ne0$, which is exactly the claim that $\op{Supp}B=\op{Supp}A\cup\op{Supp}C$.
\end{proof}
And here we can see that supports behave with (arbitrary!) direct sums.
\begin{proposition}
	Fix $R$ a ring and $\mathcal M$ a collection of $R$-modules. Then
	\[\op{Supp}\bigoplus_{M\in\mathcal M}M=\bigcup_{M\in\mathcal M}\op{Supp}M.\]
\end{proposition}
\begin{proof}
	Fix a prime $\mf p$. By \autoref{prop:localdirectsums}, we see that
	\[\left(\bigoplus_{M\in\mathcal M}M\right)_\mf p\cong\bigoplus_{M\in\mathcal M}M_\mf p.\]
	In particular, $\left(\bigoplus_{M\in\mathcal M}M\right)_\mf p$ will be nonzero if and only if at least one of the individual $M_\mf p$ are nonzero. This is exactly the claim.
\end{proof}
Additinally, we can learn something from the module itself by studying the support.
\begin{proposition}
	Fix an $R$-module $M$. Then $M=0$ if and only if $M_\mf m=0$ for all maximal ideals $\mf m\subseteq R$. In particular, 
\end{proposition}
\begin{proof}
	We have already discussed the forwards direction in \autoref{ex:emptysupport}. In the other direction, supose that the $R$-module $M$ has $M_\mf m=0$ for every maximal ideal $\mf m\subseteq R$.

	Well, pick up any $m\in M$. Then $\op{Ann}m$ is an $R$-ideal. Using the proof of \autoref{prop:generalsupport}, we see that each maximal ideal $\mf m$ has $\op{Ann}m\not\subseteq\mf m$, so $\op{Ann}m$ is not contained in any maximal ideal! Thus, we must have
	\[\op{Ann}m=R,\]
	so $1\in\op{Ann}m$, so $m=1m=0$. So all elements of $M$ are zero, so $M=0$.
\end{proof}
\begin{remark}
	In fact, the above implies $M=0$ if and only if $\op{Supp}M=\emp$. Indeed, we note that $\op{Supp}M=\emp$ will directly imply that $M_\mf m=0$ for each maximal ideal $\mf m$, from which $M=0$ follows by the above argument.
	
	In the other direction, if $\op{Supp}M\ne\emp$, then there is a prime $\mf p\in\op{Supp}M$. Thus, by \autoref{prop:generalsupport}, there is some $m$ so that
	\[\op{Ann}m\subseteq\mf p.\]
	Placing $\mf p$ inside of a maximal ideal $\mf m$, we see $\op{Ann}m\subseteq\mf m$, so $M_\mf m\ne0$ as well. So indeed, $M\ne0$.
\end{remark}
\begin{corollary}
	Fix $\varphi:M\to N$ an $R$-module homomorphism and $\mf m\subseteq R$ a maximal ideal. Then we are promised a localized map $\varphi_\mf m:M_\mf m\to N_\mf p$. Then $\varphi_\mf m$ is injective/surjective/isomorphic for all maximal ideals $\mf m$ if and only if $\varphi$ is as well.
\end{corollary}
\begin{proof}
	The main point is to repeatedly use \autoref{cor:localizekercoker}. Note $\varphi$ is injective if and only if $\ker\varphi=0$ if and only if $\ker\varphi_\mf m=(\ker\varphi)_\mf m=0$ for all maximal ideals $\mf m\subseteq R$ if and only if $\varphi_\mf m$ is injective for all $\mf m$.
	
	Repeatig the same argument with $\coker$ gives the analogous result for surjectivity. Combining the results for injectivity and surjectivity gives the result for being an isomorphism. This finishes.
\end{proof}
We continue our fact-collection.
\begin{proposition}
	Fix $R$ a ring and $R$-modules $M$ and $N$. Then
	\[\op{Supp}(M\otimes_RN)\subseteq\op{Supp}M\cap\op{Supp}N.\]
	In fact, if $M$ and $N$ are finitely generated, then equality holds.
\end{proposition}
\begin{proof}
	We show that $\op{Supp}(M\otimes_RN)\subseteq\op{Supp}M\cap\op{Supp}N$ and omit the other direction because I can't find a reference (and can't prove it myself). We take $\mf p\notin\op{Supp}M\cup\op{Supp}N$ and show that $\mf p\notin\op{Supp}(M\otimes_RN)$. Without loss of generality, we can actually take $\mf p\notin\op{Supp}M$.

	Well, we are given that $M_\mf p=N_\mf p=0$, so for each $m\in M$, there exists $u\notin\mf p$ such that $um=0$ (using \autoref{prop:generalsupport}). But then each $m\otimes n$ has
	\[u\cdot(m\otimes n)=(um)\otimes n=0,\]
	each $m\otimes n$ has some $u_{m\otimes n}\notin\mf p$ such that $u(m\otimes n)=0$. Extending linearly, any element $\sum_{k=1}^nm_k\otimes n_k$ in $M\otimes_RN$ will have
	\[u:=\prod_{k=1}^nu_{m_k\otimes n_k}\]
	with $u\notin\mf p$ (because $\mf p$ is prime) while
	\[u\cdot\sum_{k=1}^nm_k\otimes n_k=\sum_{k=1}^n(um_k)\otimes n_k=0.\]
	So we have indeed checked by \autoref{prop:generalsupport} that $\mf p\notin\op{Supp}(M\otimes_RN)$.
\end{proof}

\subsection{Tensoring Algebras}
For the next construction, we note that if $S$ and $T$ are $R$-algebras, then $S\otimes_RT$ is an $R$-algebra, where our multiplication is defined by
\[(s_1\otimes t_1)(s_2\otimes t_2)=(s_1s_2)\otimes(t_1t_2).\]
One can run through the checks that this will be an $R$-algebra.

Concretely, we have the following.
\begin{exe}
	If we have two free $k$-algebras $k[x_1,\ldots,x_n]$ and $k[y_1,\ldots,y_m]$, then we claim that
	\[[x_1,\ldots,x_n]\otimes_kk[y_1,\ldots,y_m]\]
	is freely generated by the elements of the form $x_\bullet\otimes1$ and $1\otimes y_\bullet$.
\end{exe}
\begin{remark}
	Geometrically, we can write this as $A\left(\AA^n(k)\right)\otimes_kA\left(\AA^m(k)\right)\cong A\left(\AA^n(k)\times\AA^m(k)\right)$, which makes more immediate sense.
\end{remark}
More generally, the following is true.
\begin{proposition}
	Fix affine algebraic sets $X$ and $Y$. Then $A(X\times Y)=A(X)\otimes_kA(Y)$.
\end{proposition}
\begin{proof}
	Omitted.
\end{proof}
\begin{remark}
	One can generalize this construction to fiber products.
\end{remark}
Next class we will finish up localization by discussing modules of finite length.