% !TEX root = ../notes.tex

We continue following the Eisenbud machine.

\subsection{Affine Space}
To begin our discussion, we start with some geometry.
\begin{definition}[Affine space]
	Given a field $k$ and positive integer $n$, we define $n$-dimensional \textit{affine space} over $k$ to be $\AA^d(k):=k^n.$
\end{definition}
Now, given affine space $\AA^n(k)$, we are interested in studying subsets which are solutions to some set of polynomial equations
\[f_1,\ldots,f_n\in k[x_1,\ldots,x_d].\]
This gives rise to the following definition.
\begin{definition}[Algebraic]
	A subset $X\subseteq\AA^n(k)$ is (affine) \textit{algebraic} if and only if it is the set of solutions to some system of polynomials equations $f_1,\ldots,f_n\in k[x_1,\ldots,x_d]$.
\end{definition}
\begin{example}
	The hyperbola
	\[\left\{(x,y)\in\RR^2:x^2-y^2-1=0\right\}\]
	is an algebraic set. Geometrically, it looks like the following.
	\begin{center}
		\begin{asy}
			import graph;
			unitsize(0.7cm);
			draw((-3.5,0)--(3.5,0)); draw((0,-3.5)--(0,3.5));
			pair L(real y)
			{
				return (-sqrt(1+y*y), y);
			}
			pair R(real y)
			{
				return (+sqrt(1+y*y), y);
			}
			draw(graph(L, -2.8, 2.8), arrow=Arrows());
			draw(graph(R, -2.8, 2.8), arrow=Arrows());
		\end{asy}
	\end{center}
\end{example}
\begin{example} \label{ex:notalgclosed}
	The set $\emp\subseteq\AA^1(\RR)$ is algebraic becasue it is the set of solutions to the equation $x^2+1=0$ in $\RR$.
\end{example}
The above example is a little disheartening because it feels like $x^2+1$ really ought to have a solution, namely $i\in\CC$. More explicitly, there are no obvious algebraic obstructions that make $x^2+1$ not have a solution. So with this in mind, we make the following convention.
\begin{convention}
	In the following discussion on the Nullstellensatz, $k$ will always be an algebraically closed field.
\end{convention}

\subsection{Nullstellensatz}
The Nullstellensatz is very important.
\begin{remark}
	Because the Nullstellensatz is important, its name is in German (which was the language of Hilbert).
\end{remark}

Now, the story so far is that we can take a set of polynomials and make algebraic sets as their solution set. We can in fact go in the opposite direction.
\begin{definition}[\texorpdfstring{$I(X)$}{I(X)}]
	If $X\subseteq\AA^n(k)$ is an (affine) algebraic set, we define
	\[I(X):=\{f\in k[x_1,\ldots,x_n]:f(X)=0\}.\]
\end{definition}
It is not hard to check that $I(X)\subseteq k[x_1,\ldots,x_n]$ is in fact an ideal. Namely, if $f,g\in I(X)$ and $r,s\in k[x_1,\ldots,x_n]$, then we need to know $rf+sg\in I(X)$ as well. Well, for any $x\in X$, we see
\[(rf+sg)(x)=rf(x)+sg(x)=0,\]
so $rf+sg\in I(X)$ indeed.

One might hope that all ideals would be able to take the form $I(X)$, but this is not the case. For example, if $f^m(X)=0$, then $f(X)=0$ because $k$ is a field. Thus, $I$ will satisfy the property that $f^m\in I$ implies $f\in I$. To keep track of this obstruction, we have the following definition.
\begin{definition}[Radical]
	Fix $R$ a ring. Given an $R$-ideal $I$, we define the \textit{radical of $I$} to be
	\[\op{rad}I:=\left\{x\in R:x^n\in I\text{ for some }n\ge1\right\}\supseteq I.\]
	If $I=\op{rad}I$, then we call $I$ a \textit{radical ideal}.
\end{definition}
To make sense, this definition requires a few sanity checks.
\begin{itemize}
	\item We check $\rad I$ is in fact an ideal. Well, given $f,g\in\rad I$, there exists positive integers $m$ and $n$ such that $f^m,g^n\in I$. Then, for any $r,s\in R$, we see
	\[(rf+sg)^{m+n}=\sum_{k=0}^{m+n}\left[\binom{m+n}kr^ks^{m+n-k}\cdot f^kg^{m+n-k}\right].\]
	However, for any $k$, we see that either $k\ge m$ or $m+n-k\ge n$, so all terms of this sum contain an $f^m$ or $g^n$ factor, so the sum is in $I$. So indeed, $rf+sg\in\rad I$.
	\item We check that $\rad I$ is a radical ideal. Well, if $f^n\in\rad I$ for some positive integer $n$, then $f^{mn}=\left(f^n\right)^m\in I$ for some positive integer $m$, from which $f\in\rad I$ follows.
\end{itemize}
It is not too hard to generate examples where the radical is strictly larger than the original ideal.
\begin{example}
	Fix $R:=\ZZ[\sqrt2]$ and $I=(2)=2\ZZ[\sqrt2]=\{2a+2b\sqrt2:a,b\in\ZZ\}$. Then $\left(\sqrt2\right)^2=2\in I$ while $\sqrt2\notin I$, so $I\subsetneq\rad I$.
\end{example}
Here is an alternative characterization of being radical.
\begin{lemma}
	Fix $R$ a ring. Then an ideal $I\subseteq R$ is radical if and only if $R/I$ is reduced.
\end{lemma}
\begin{proof}
	This proof is akin to the one showing $I\subseteq R$ is prime if and only if $R/I$ is an integral domain.

	Anyways, $I$ is radical if and only if $x^n\in I$ for $x\in R$ and $n\ge1$ implies $x\in I$. Translating this condition into $R/I$, we are saying that $[x]_I^n\in[0]_I$ for $[x]_I\in R/I$ and $n\ge1$ implies that $[x]_I=[0]_I$. This is exactly the condition for $R/I$ to be radical.
\end{proof}
With all of the machinery we have in place, we can now state the idea of Hilbert's Nullstellensatz.
\begin{theorem}[Nullstellensatz, I]
	Fix $k$ an algebraically closed field. Then there is a bijection between radical ideals of $k[x_1,\ldots,x_n]$ and (affine) algebraic sets $\AA^n(k)$.
\end{theorem}
So far we have defined a map from algebraic sets to radical ideals by $X\mapsto I(X)$. The reverse map is as follows.
\begin{definition}[\texorpdfstring{$Z(I)$}{Z(I)}]
	Given a subset $S\subseteq k[x_1,\ldots,x_n]$, we define the \textbf{zero set} of $S$ by
	\[Z(S):=\{x\in\AA^n(k):f(x)=0\text{ for all }f\in I\}.\]
\end{definition}
Note that replacing $S$ with the ideal it generates $(S)$ makes no difference to $Z(S)$ (i.e., linear combinations of the constraints do not make the problem harder), so we will may focus on the case where $S$ is an ideal.

With these maps in hand, we can restate the Nullstellensatz.
\begin{theorem}[Nullstellensatz, II]
	Fix $k$ an algebraically closed field. Then for ideals $I\subseteq k[x_1,\ldots,x_n]$, we have
	\[I(Z(I))=\op{rad}I.\]
	In particular, if $I$ is radical, then $I(Z(I))=I$.
\end{theorem}
\begin{remark}
	Yes, it is important that $k$ is algebraically closed here. Essentially this comes from \autoref{ex:notalgclosed}: the ideal $\left(x^2+1\right)$ is not of the form $Z(X)$ for any subset $X\subseteq\AA^1(\RR)$ because $x^2+1$ has no roots and would need $X=\emp$, but $Z(\emp)=\RR[x]$.
\end{remark}
\begin{example}
	We have that $I(Z(R))=R$ because $Z(R)=\emp$ (no points satisfy $1=0$) and $I(\emp)=R$ (all functions vanish on $\emp$).
\end{example}
\begin{remark}[Nir] \label{rem:othernullstellensatz}
	One might object that $I(Z(I))=\rad I$ only contains one direction of the bijection, but in fact it is not too hard to show directly that $Z(I(X))=X$ for algebraic sets $X$. We argue as follows.
	\begin{itemize}
		\item Each $x\in X$ will cause all polynomials in $I(X)$ to vanish by construction of $I(X)$, so $X\subseteq Z(I(X))$.
		\item Now set $X=Z(S)$. Each $f\in S$ has $f(x)=0$ for each $x\in S$, so $f\in I(X)$ as well. So $S\subseteq I(X)$, so $Z(I(X))\subseteq Z(S)=X$.
	\end{itemize}
\end{remark}

\subsection{More on Affine Space}
Let's talk about $\AA^n(k)$ a bit more. We mentioned that this should be a geometric object, so let's give it a topology.
\begin{definition}[Zariski topology, I]
	Given affine space $\AA^n(k)$, we define the \textit{Zariski topology} as having closed sets which are the algebraic sets.
\end{definition}
\begin{remark}[Nir]
	Here is one reason why we might do this: without immediate access to better functions (the field $k$ might have no easy geometry, like $k=\FF_p(t)$) it makes sense to at least require polynomial functions to be continuous and $k$ to be Hausdorff. In particular, given a polynomial $f$, we see that
	\[Z(f)=f^{-1}(\{0\})\]
	should be closed. In fact, for any subset $S\subseteq k[x_1,\ldots,x_n]$ of polynomials
	\[Z(S)=\bigcap_{f\in S}Z(f)\]
	will also have to be closed. In particular, all algebraic sets are closed. One can then check that polynomials do remain continuous in this topology also, as promised.
\end{remark}
We have the following checks to make sure that the algebraic sets do actually form a topology (of closed sets).
\begin{itemize}
	\item The empty set is closed: $\emp$ is the set of solutions to the equation $1=0$.
	\item The full space is closed: $\AA^n(k)$ is the set of solutions to the equation $0=0$.
	\item Arbitrary intersection of closed sets is closed: given algebraic sets $X(S)$ for given subsets $S\subseteq\mathcal S$ of $k[x_1,\ldots,x_n]$, we note
	\[\bigcap_{S\in\mathcal S}X(S)=X\left(\bigcup_{S\in\mathcal S}S\right),\]
	so the union is in fact an algebraic set.
	\item Finite unions of closed sets are closed: given algebraic sets $X(S_1),\ldots,X(S_n)$, we note
	\[\bigcup_{i=1}^nX(S_i)=X\left(\prod_{i=1}^n(S_i)\right),\]
	where $(S_i)$ is the ideal generated by $S_i$. In particular, $\prod_i(S_i)$ is generated by elements $s_1\cdot\ldots\cdot s_n$ such that $s_i\in S_i$ for each $i$, so any point in any of the $X(S_i)$ will show up in the given algebraic set.
\end{itemize}
Now that we've checked we actually have a topology, we remark that it is a pretty strange topology.
\begin{proposition}
	Let $k$ be an algebraically closed field. Given affine space $\AA^n(k)$ the Zariski topology.
	\begin{itemize}
		\item The space $\AA^n(k)$ is not Hausdorff.
		\item The space $\AA^n(k)$ is compact.
	\end{itemize}
\end{proposition}
\begin{proof}
	We take the claims individually.
	\begin{itemize}
		\item Because $\AA^n(k)$ has more than one point, it suffices to show that there are no disjoint nonempty Zariski open subsets of $\AA^n(k)$. In other words, given two Zariski open sets $\AA^n(k)\setminus Z(I)$ and $\AA^n(k)\setminus Z(J)$, we claim that
		\[\left(\AA^n(k)\setminus Z(I)\right)\cap\left(\AA^n(k)\setminus Z(J)\right)=\emp\]
		implies $\AA^n(k)\setminus Z(I)=\emp$ or $\AA^n(k)\setminus Z(J)=\emp$. Taking complements, we know that
		\[Z(IJ)=Z(I)\cup Z(J)=\AA^n(k)=Z((0)).\]
		But now, by the Nullstellensatz (!), we see that $\rad(IJ)=\rad((0))$. But $k[x_1,\ldots,x_n]$ is an integral domain, so $\rad((0))=(0)$.
		
		Now, this means $f^n\in IJ$ for some $n\in\NN$ requires $f=0$, which means that $IJ=(0)$, so because $k[x_1,\ldots,x_n]$ is an integral domain, $I=(0)$ or $J=(0)$. (Explicitly, $I$ and $J$ cannot both have nonzero terms.) Without loss of generality, take $I=(0)$.

		SO to finish, we see $Z(I)=Z((0))=\AA^n(k)$, so $\AA^n(k)\setminus Z(I)=\emp$.
		\item Suppose we are given an open cover $\left\{\AA^n(k)\setminus Z(I)\right\}_{I\in\mathcal S}$ indexed by some collection $\mathcal S$ of ideals of $k[x_1,\ldots,x_n]$. The fact that these sets form an open cover is equivalent to saying
		\[Z\left(\sum_{I\in\mathcal S}I\right)=\bigcap_{I\in\mathcal S}Z(I)=\emp.\]
		Now, by the Nullstellensatz (we will use this trick again later on!), it follows
		\[1\in R=I(\emp)=I\left(Z\left(\sum_{I\in\mathcal S} I\right)\right)=\rad\sum_{I\in\mathcal S} I,\]
		so it follows $1\in\sum I$.

		However, we can reduce this to a finite condition: $1\in\sum_I$ merely means there are elements $\{f_i\}_{i=1}^N$ such that $f_i\in I_i$ for some $I_i\in\mathcal S$ such that $\sum_if_i=1$. This means that in fact $1\in I_1+\cdots+I_N$, so
		\[\emp=Z(I_1+\cdots+I_N)=\bigcap_{i=1}^NZ(I_i).\]
		Thus, the finite number of sets $\AA^n(k)\setminus Z(I_i)$ for each $1\le i\le N$ provides us with a finite subcover of $\AA^n(k)$.
		\qedhere
	\end{itemize}
\end{proof}
In another direction, we note can also understand algebraic sets $X\subseteq\AA^n(k)$ by their ring of functions. Again, the only functions we have easy access to are polynomials, so we take the following definition.
\begin{definition}[Coordinate ring]
	Given an algebraic set $X\subseteq\AA^n(k)$, we define the \textit{coordinate ring} on $X$ as
	\[A(X):=k[x_1,\ldots,x_n]/I(X).\]
	In other words, we are looking at polynomials on $\AA^n(k)$ and identifying them whenever they are equal on $X$.
\end{definition}
Note that, because $I(X)$ is a radical ideal, the ring $A(X)$ will be reduced.

\subsection{Corollaries of the Nullstellensatz}
Let's return to talking about talking about the Nullstellensatz. To convince us that the Nullstellensatz is important, here are some nice corollaries.

\subsubsection{Criteria for Polynomial System Solutions}
The following is the feature of this subsubsection.
\begin{corollary}
	A system of polynomial equations
	\[\begin{cases}
		f_1(x_1,\ldots,x_n) = 0, \\
		\qquad\quad~\vdots \\
		f_r(x_1,\ldots,x_n) = 0,
	\end{cases}\]
	has no solutions if and only if there exists $p_1,\ldots,p_r\in k[x_1,\ldots,x_n]$ such that
	\[\sum_{i=1}^rp_if_i=1.\]
\end{corollary}
\begin{proof}
	In the reverse direction, we proceed by contraposition: if there is a solution $x\in\AA^n(k)$ such that $f_i(x)=0$ for each $f_i$, then any set of polynomials $p_1,\ldots,p_n\in k[x_1,\ldots,x_n]$ will give
	\[\sum_{i=1}^rp_i(x)f_i(x)=0\ne1,\]
	so it follows $\sum_{o=1}^np_if_i\ne1$. Observe that we did not use the Nullstellensatz here.

	The forwards direction is harder. The main point is that we are given $Z((f_1,\ldots,f_r))=\emp$, so
	\[\rad(f_1,\ldots,f_r)=I(Z((f_1,\ldots,f_n)))=I(\emp)=R,\]
	so the Nullstellensatz gives $1\in\rad(f_1,\ldots,f_r)$. Then it follows $1=1^n\in(f_1,\ldots,f_r)$ for some positive integer $n$, so there exists $p_1,\ldots,p_r\in k[x_1,\ldots,x_n]$ such that
	\[\sum_{i=1}^rp_if_i=1.\]
	This is what we wanted.
\end{proof}

\subsubsection{Maximal Ideals Are Points}
To set up the next corollary, we claim that any point $a=(a_1,\ldots,a_n)\in\AA^n(k)$ makes a closed set corresponding to the ideal
\[I(\{a\})\stackrel?=(x_1-a_1,\ldots,x_n-a_n)\subseteq k[x_1,\ldots,x_n]=A(\AA^n(k)).\]
Indeed, $I(\{a\})$ certainly contains $x_i-a_i$ for each $i$; conversely, if $f\in I(\{a\})$, then
\[f(x_1,\ldots,x_n)\equiv f(a_1,\ldots,a_n)=0\pmod{x_1-a_1,\ldots,x_n-a_n},\]
so $f\in(x_1-a_1,\ldots,x_n-a_n)$.
\begin{example}
	In fact, in the case of $\CC[x]$, it is not too hard to see that such ideals are maximal: given $z\in\CC$, suppose that $I\subseteq\CC[x]$ had $(x-z)\subseteq I$. If each $f\in I$ has $f(z)=0$, then we are done; otherwise if there is $f\in I$ with $f(z)\ne0$, then $f(x)$ and $(x-z)$ are coprime in a principal ideal domain, so
	\[1\in(f)+(x-z)\subseteq I,\]
	meaning $I=\CC[x]$.
\end{example}
The above example gives us the hope that maximal ideals might turn out to all be of the above form. Indeed, this is true, with the help of the Nullstellensatz.
\begin{corollary}
	Fix $X\subseteq\AA^n(k)$ an (affine) algebraic set. Then points $a=(a_1,\ldots,a_n)\in X$ are in bijection with maximal ideals $\mf m_a\subseteq A(X)$ by
	\[a\mapsto\mf m_a:=I(\{a\})/I(X)=(x_1-a_1,\ldots,x_n-a_n)/I(X).\]
\end{corollary}
\begin{proof}
	The input from the Nullstellensatz will come from the following lemma.
	\begin{lemma} \label{lem:zeroempty}
		Suppose that $I\subseteq A\left(\AA^n(k)\right)$ has $Z(I)=\emp$. Then $I=A\left(\AA^n(k)\right)$.
	\end{lemma}
	\begin{proof}
		By the Nullstellensatz,
		\[1\in A\left(\AA^n(k)\right)=I(\emp)=I(Z(I))=\rad I,\]
		so $1\in I$ follows.
	\end{proof}
	Now, we have alreadys shown that $I(\{a\})=(x_1-a_1,\ldots,x_n-a_n)$. Additionally, for $x\in X$, we have $I(X)\subseteq I(\{a\})$, so $I(\{a\})/I(X)$ is an ideal which makes sense. Thus, we may write $I(\{a\})/I(X)=(x_1-a_1,\ldots,x_n-a_n)/I(X)$.
	
	Before continuing, we also check that $Z(I(\{a\}))=\{a\}$ as well. (This shows that $\{a\}$ is an algebraic set.) Well, set $a=(a_1,\ldots,a_n)$, and we note that $x_i-a_i\in I(\{a\})$ for each $i$, so any $b=(b_1,\ldots,b_n)\in Z(I(\{a\}))$ must vanish on each $x_i-a_i$, so
	\[b_i-a_i=0\]
	for each $i$. Thus, $b=a$.

	We now check that $a\mapsto\mf m_a$ is a bijection.
	\begin{itemize}
		\item Well-defined: we show that $\mf m_a$ is a maximal ideal. It is proper because $1\notin\mf m_a$. Now suppose we have $I\subseteq A(X)$ such that $\mf m_a\subseteq I$. So note that $I+I(X)\subseteq A\left(\AA^n(k)\right)$ is an ideal (namely, the pre-image) containing $I(\{a\})$.

		Now, observe that $I(\{a\})\subseteq I+I(X)$, so
		\[Z(I+I(X))\subseteq Z(I(\{a\}))=\{a\}.\]
		We now have two cases.
		\begin{itemize}
			\item If $Z(I+I(X))=\emp$, then \autoref{lem:zeroempty} gives $I+I(X)=A(\AA^n(k))$, so $I/I(X)=A(X)$.
			\item Otherwise if $Z(I+I(X))=\{a\}$, then $I+I(X)\subseteq I(\{a\})$. Thus $I\subseteq\mf m_a$, finishing.
		\end{itemize}
		\item Injective: suppose $a,b\in X$ have $\mf m_a=\mf m_b$. But then
		\[I(\{a\})=\mf m_a+I(X)=\mf m_b+I(X)=I(\{b\}),\]
		so $\{a\}=Z(I(\{a\}))=Z(I(\{b\}))=\{b\}$, so $a=b$ follows.
		\item Surjective: suppose that $\mf m\subseteq A(X)$ is a maximal ideal. Then we look at the pre-image ideal $I:=\mf m+I(X)\subseteq A\left(\AA^n(k)\right)$. We claim that $Z(I)$ is a singleton.
		\begin{itemize}
			\item We show that $Z(I)\ne\emp$. Indeed, $Z(I)=\emp$ implies by \autoref{lem:zeroempty} that $1\in I$, so $[1]_{I(X)}\in\mf m$, which violates the fact that $\mf m\subseteq A(X)$ is proper.
			\item We show all elements of $Z(I)$ are equal. Suppose $a,b\in Z(I)$; because $I(X)\subseteq I$, we see $a,b\in X$ is forced by \autoref{rem:othernullstellensatz}. Then $\{a\},\{b\}\subseteq Z(I)$, so
			\[I\subseteq I(\{a\})\cap I(\{b\}),\]
			so $\mf m=I/I(X)$ is contained in $\mf m_a=I(\{a\})/I(X)$ and $\mf m_b=I(\{b\})/I(X)$. But $\mf m_a$ and $\mf m_b$ are distinct maximal ideals, so we see $\mf m\subseteq\mf m_a\cap\mf m_b\subsetneq\mf m_a\subsetneq A(X)$, violating the fact that $\mf m$ is maximal.
		\end{itemize}
		Thus, set $Z(I)=\{a\}$; note $a\in X$ because $I(X)\subseteq I$ (by \autoref{rem:othernullstellensatz} again). Now, $I\subseteq I(\{a\})$, so we see $\mf m=I/I(X)\subseteq I(\{a\})/I(X)=\mf m_a$, so the maximality of $\mf m$ forces $\mf m=\mf m_a$.
		\qedhere
	\end{itemize}
\end{proof}
The reason the above is nice is because, instead of having to look at the geometry of $X$, it is now legal to study the algebra of $A(X)$.

\subsection{The Spectrum of a Ring}
We continue trying to move the geometry of affine sets $X\subseteq\AA^n(k)$ into the coordinate ring $A(X)$.

Later in life we will want to consider maps $\varphi:X\to Y$ between affine sets. In affine space, we again remark that really only the functions we have access to are polynomials, so our only morphisms will be functions which are polynomials in each coordinate.

Now let's move $\varphi$ to geometry. Note that $A(X)$ and $A(Y)$ arre intended to describe functions $X\to k$ and $Y\to k$ respectively, so a morphism $\varphi:X\to Y$ induces a ring homomorphism
\[\varphi:A(Y)\rightarrow A(X)\]
by $f\mapsto f\circ\varphi$. (This is a ring homomorphism because $\varphi$ is made of polynomials.) So under the paradigm that points should become maximal ideals, we would like to recover $\varphi$ as some kind of map of maximal ideals $A(X)\to A(Y)$. The natural way is to simply pull back along $\varphi$, writing
\[\mf m\subseteq A(X)\mapsto\varphi^{-1}\mf m\subseteq A(Y).\]
However, this is a problem: $\varphi^{-1}\mf m$ need not be maximal!
\begin{example}
	If $\mf p\subseteq R$ is a prime but not maximal ideal (e.g., $(x)\subseteq k[x,y]$), we can define the composite
	\[R\onto R/\mf p\into\op{Frac}(R/\mf p).\]
	Now, $(0)$ is maximal in $\op{Frac}(R/\mf p)$, but its pre-image in $R$ is $\mf p$, which is not maximal by construction.
\end{example}
However, if we weaken requiring our points to be prime ideals $\mf p$ instead of maximal ideals, we do have that $\varphi^{-1}\mf p$ is a prime ideal: $ab\in\varphi^{-1}\mf p$ implies $\varphi(a)\varphi(b)=\varphi(ab)\in\mf p$ implies $a\in\varphi^{-1}\mf p$ or $b\in\varphi^{-1}\mf p$.

So instead of making our geometry on $A(X)$ defined by maximal ideals, we use prime ideals. This gives the following definition.
\begin{definition}[Spectrum of a ring]
	Given a ring $R$, we define \textit{spectrum of $R$} by
	\[\op{Spec}R:=\{\mf p\subseteq R:\mf p\text{ is a prime ideal}\}.\]
\end{definition}
In fact, $\op{Spec}R$ also has a Zariski topology as follows.
\begin{definition}[Zariski topology, II]
	Given a ring $R$, we define the \textit{Zariski topology} to have closed sets
	\[X(I):=\{\mf p\in\op{Spec}R:I\subseteq\mf p\}\]
	for $R$-ideals $I$.
\end{definition}
\begin{remark}[Nir]
	As for motivation for why we might define our topology like this, recall the case of affine varieties: we have $a\in X(I)$ if and only if $I\subseteq I(\{a\})$. So when we translate $X(I)$ into the algebraic side, we call the maximal ideal $\mf m_a=I(\{a\})$ our ``point'' and see that
	\[X(I)=\{\mf m_:I\subseteq\mf m_a\}.\]
	It is a different story why we use prime ideals instead of maximal ones, which we discussed above.
\end{remark}
The checks that the $X(I)$ do actually define closed sets for a topology are essentially the same as for the first version of the Zariski topology. The main points are that
\[\bigcap_{I\in\mathcal S}X(I)=X\left(\sum_{I\in\mathcal S}I\right)\qquad\text{and}\qquad\bigcup_{k=1}^NX(I_k)=X\left(\prod_{k=1}^NI_k\right)\]
give that arbitrary intersection of closed sets is closed and finite union of closed sets is closed.\footnote{The second equality requires some care. The main point is to show, for $\mf p$ prime, $IJ\subseteq\mf p$ is equivalent to $I\subseteq\mf p$ or $J\subseteq\mf p$. The reverse is easy. For the forwards, suppose $IJ\subseteq\mf p$ and $J\not\subseteq\mf p$ so that we have $j\in J\setminus\mf p$. Then $jI\subseteq IJ\subseteq\mf p$ forces $I\subseteq\mf p$.}

Again, the Zariski topology is very weird, like with affine space.
\begin{proposition}
	Fix $R$ a ring. Given $\op{Spec}R$ the Zariski topology.
	\begin{itemize}
		\item If $R$ is an integral domain which is not a field, then $\op{Spec}R$ is not Hausdorff.
		\item The space $\op{Spec}R$ is compact.
	\end{itemize}
\end{proposition}
\begin{proof}
	We take the claims one at a time.
	\begin{itemize}
		\item The fact that $R$ is a field means that $\op{Spec}R$ has more than one point. So again, it suffices to show that there are no disjoint open subsets of $\op{Spec}R$. Indeed, suppose
		\[(\op{Spec}R\setminus X(I))\cap(\op{Spec}R\setminus X(J))=\emp,\]
		and we claim $\op{Spec}R\setminus X(I)=\emp$ or $\op{Spec}R\setminus X(J)=\emp$.

		Again, we know that $X(IJ)=X(I)\cup X(J)=\op{Spec}R$, so by definition, we see $IJ\subseteq\mf p$ for each prime $\mf p$, or
		\[IJ\subseteq\bigcap_\mf p\mf p.\]
		Now, because $R$ is an integral domain, we see that $(0)$ is a prime ideal, so $IJ=(0)$ follows. Thus, because $R$ is an integral domain again, $I=(0)$ or $J=(0)$, so without loss of generality, we take $I=(0)$. But then
		\[\op{Spec}R\setminus X(I)=\op{Spec}R\setminus\op{Spec}R=\emp,\]
		as desired.

		\item Suppose that the Zariski open sets $\{\op{Spec}R\setminus X(I)\}_{I\in\mathcal S}$ cover $\op{Spec}R$, for some collection $\mathcal S$ of ideals. Now, the sets $\{\op{Spec}R\setminus X(I)\}_{I\in\mathcal S}$ covering $\AA^n(k)$ is equivalent to
		\[X\left(\sum_{I\in\mathcal S}I\right)=\bigcap_{I\in\mathcal S}X(I)=\emp.\]
		However, $X\left(\sum I\right)=\emp$ implies that there is no prime ideal $\mf p$ such that $\sum I\subseteq\mf p$, but any proper ideal is contained in some maximal and hence prime ideal. Thus, we must have that
		\[\sum_{I\in\mathcal S}I=R.\]
		In particular, $1$ is in this ideal, so we can express $1$ as the sum of some elements $x_i\in I_i$ for $\{I_i\}_{i=1}^N\subseteq\mathcal S$; i.e.,
		\[1=\sum_{i=1}^Nx_i\in\sum_{i=1}^NI_i.\]
		Thus, $\sum_{i=1}^NI_i=R$, meaning $X\left(\sum_{i=1}^NI_i\right)=\emp$, so reversing the argument we see that $\{\op{Spec}R\setminus X(I_i)\}_{i=1}^N$ will be a finite subcover. This finishes.
		\qedhere
	\end{itemize}
\end{proof}

\subsection{Projective Space}
To define projective varities, we need to define projective space first.
\begin{definition}[Projective space]
	Fix $k$ a field and $n$ a positive integer. Then we define $n$-dimensional \textit{projective space} $\PP^n(k)$ to be the one-dimensional subspaces of $k^{n+1}$.
\end{definition}
Concretely, we will think about lines in homogeneous coordinates, in the form
\[(a_0:a_1:\ldots:a_n)\in\PP^n(k)\]
to represent the subspace $k(a_0,a_1,\ldots,a_n)\subseteq\AA^{n+1}(k)$. As such multiplying the point $(a_0:a_1:\ldots:a_n)$ by some constant $c\in k^\times$ will give the same line and should be the same point in $\PP^n(k)$. Additionally, we will ban the point $(0:0:\ldots:0)$ from projective space because it is not the basis for any line.

We would like to have a better geometry understanding of $\PP^n(k)$. Note that we have a sort of embedding $\AA^n(k)\into\PP^n(k)$ by
\[(x_1,x_2,\ldots,x_n)\mapsto(x_1:x_2:\ldots:x_n:1).\]
For geometric concreteness, we can imagine $\AA^2(\RR)\into\PP^2(\RR)$ as the plane $z=1$ in $\RR^3$, where each point on the plane gives rise to a unique line in $\RR^3$. Here is the image, with a chosen red line going through a point $v$ on the $z=1$ plane.
\begin{center}
	\begin{asy}
		import three;
		unitsize(1.4cm);
		currentprojection=perspective(1,5/4,3/4);
		draw((-3,0,0)--(3,0,0), EndArrow3);
		label("$x$", (3,0,0), (2,0,0));
		draw((0,-3,0)--(0,3,0), EndArrow3);
		label("$y$", (0,3,0), (0,2,0));
		draw((0,0,-2)--(0,0,3), EndArrow3);
		label("$z$", (0,0,3), (0,0,1.5));

		label("$1$", (0,0,1/2), (0.2,0,0), blue);
		draw((0,0,0)--(0,0,1), blue+linewidth(1));
		draw(surface((3,-2,1)--(3,3,1)--(-2,3,1)--(-2,-2,1)--cycle), blue+opacity(0.4));
		draw((3,0,1)--(-2,0,1), dashed);
		draw((0,3,1)--(0,-2,1), dashed);

		triple v = (-1,2,1);
		dot("$v$", v, (0,0,1), red);
		draw(-v -- 1.5*v, red);
		draw((0, v.y, 1) -- v, dashed);
		draw((v.x, 0, 1) -- v, dashed);
	\end{asy}
\end{center}
However, not all lines in $\AA^3(\RR)$ can be described like this, for there are still lots of points of the form $(x:y:0)$, which are ``points at infinity.'' Nevertheless, we can collect the remaining points into $\PP^2(\RR)$, which visually just means the lines that live on the $xy$-plane in the above diagram.

In general, we see that we can decompose $\PP^n(k)$ into an $\AA^n(k)$ component as a ``$z=1$ hyperplane'' and then the points at infinity living on $\PP^{n-1}(k)$. Namely,
\[\PP^n(k)\,\text{``}{=}\text{''}\,\AA^n(k)\sqcup\PP^{n-1}(k).\]
Note that the above decomposition is not canonical: one has to choose which points to get to be infinity.

Anyways, as usual we interested in studying the algebraic sets but this time of projective space, but because of the constant factors allowed to wiggle, we see that we really should only be looking at homogeneous equations. More concretely, if $f\in k[x_0,\ldots,x_n]$, we want
\[f(a_0:\ldots:a_n)=0\]
to be unambiguous, so $f(a_0,\ldots,a_n)=0$ should be imply $f(ca_0,\ldots,ca_n)=0$ for any $c\in k^\times$. The easiest way to ensure this is to force all monomials of $f$ to have some fixed degree, say $d$, so that
\[f(cx_0,\ldots,cx_n)=c^df(x_0,\ldots,x_n).\]
These polynomials are the homogeneous ones, and they give the following definition.
\begin{definition}[Projective variety]
	A subset $X\subseteq\PP^n(k)$ is a \textit{projective variety} if and only if it is the solution set to some set of homogeneous (!) polynomials equations of $k[x_0,\ldots,x_n]$.
\end{definition}
Here is an example.
\begin{exe}
	We view the solutions to $xy-1=0$ in $\AA^2(\RR)\subseteq\PP^2(\RR)$ in projective space.
\end{exe}
\begin{proof}
	More explicitly, we are viewing $\AA^2(k)\subseteq\PP^2(k)$ by sending $(x,y)\mapsto(x:y:1)$. We can make the coordinates more familiar by setting $x,y\mapsto x/z,y/z$ so that we are looking for solutions $(x/z:y/z:1)=(x:y:z)$ to the equation
	\[xy=z^2.\]
	In $\RR^3$, this curve looks like the following.
	\begin{center}
		\begin{asy}
			import three;
			unitsize(1.4cm);
			currentprojection=perspective(1,-0.5,0.5);
			draw((-3,0,0)--(3,0,0), EndArrow3);
			label("$x$", (3,0,0), (2,0,0));
			draw((0,-3,0)--(0,3,0), EndArrow3);
			label("$y$", (0,3,0), (0,2,0));
			draw((0,0,-2)--(0,0,2), EndArrow3);
			label("$z$", (0,0,2), (0,0,1));
			
			//create segment
			path3 top = (2.5,0,0) -- (0,0,0);
			path3 bot = -(2.5,0,0) -- (0,0,0);
			//create surface of revolution
			surface topSurface = surface(top, c=O, axis=(1,1,0));
			surface botSurface = surface(bot, c=O, axis=(1,1,0));
			//draw surface
			draw(topSurface, orange+opacity(0.8));
			draw(botSurface, orange+opacity(0.8));
		\end{asy}
	\end{center}
	The hyperbola for $xy=1$ comes from slicing the $z=1$ plane from this cone.
\end{proof}

\subsection{Graded Rings}
We have the following definition.
\begin{definition}[Graded ring]
	A ring $R$ is \textit{graded} by the abelian groups $R_0,R_1,\ldots$ if and only if
	\[R\cong\bigoplus_{d=0}^\infty R_d\]
	as abelian groups and $R_iR_j\subseteq R_{i+j}$ for any $i,j\in\NN$.
\end{definition}
\begin{remark}[Nir]
	In fact, $R_0$ turns out to be a subring of $R_0$. We can check this directly, as follows.
	\begin{itemize}
		\item Certainly $0\in R_0$ and $R_0+R_0\subseteq R_0$ because $R_0\subseteq R$ is an additive subgroup.
		\item If $1_R\in R_i$, then $R_i\subseteq R_iR_i\subseteq R_{2i}$, so $i=0$ or $R_i=R_{2i}=\{0\}$ by disjointness. So either $1\in R_0$ or $1\in R_0=\{0\}$ forces $R=\{0\}$, so $1\in R_0$ anyways.
		\item We see $R_0R_0\subseteq R_0$, so $R_0$ is closed under multiplication.
	\end{itemize}
	Alternatively, we could set $I:=\{0\}\oplus R_1\oplus R_2\cdots$, remark that $I$ is an ideal, and then we see $R_0\cong R/I$.
\end{remark}
\begin{example}
	The ring $R=k[x_1,\ldots,x_n]$ is ``graded by degree'' by setting $R_d$ to be the space of all homogeneous $n$-variable polynomials of degree $d$ (unioned with $\{0\}$).
\end{example}
With graded rings, it is natural to ask what other ring-theoretic constructions we can grade.
\begin{definition}[Graded ideal]
	Fix $R$ a graded ring. We say that an ideal $I$ is \textit{graded} if and only if
	\[I\cong\bigoplus_{d=0}^\infty(R_d\cap I),\]
	where the isomorphism is the natural one (i.e., $(x_0,x_1,\ldots)\mapsto x_0+x_1+\cdots$).
\end{definition}
\begin{example}
	Given the graded ring $R=R_0\oplus R_1\oplus R_2\oplus\cdots$, the ideal
	\[I:=R_1\oplus R_2\oplus R_3\oplus\cdots\]
	is called the \textit{irrelevant ideal}; it is graded because look at it. To check $I$ is an ideal, it is closed under addition by construction; it is closed under multiplication by $R$ because $R_iR_j\subseteq R_{i+j}$ for $i\ge1$ implies $i+j\ge1$.
\end{example}
\begin{remark}
	The above ideal is called irrelevant because, in the case where $R=k[x_0,\ldots,x_n]$,
	\[Z(I)=\left\{(a_0:\ldots:a_n)\in\PP^n(k):f(a_0,\ldots,a_n)\text{ for each homogeneous }f\in I\right\}=\emp.\]
	Indeed, any element of $Z(I)$ would have to satisfy $x_i=0$ for each $x_i$, which is illegal in projective space.
\end{remark}
The point of the definition of a graded ideal is that, when $I\subseteq R$ is a graded ideal,
\[\frac RI\cong\bigoplus_{d=0}^\infty\frac{R_d}{R_d\cap I}\]
will also be a graded ring, with the given grading. This isomorphism comes from combining the isomorphism $R\cong\bigoplus_dR_d$ and $I\cong\bigoplus_d(R_d\cap I)$.

Here is another ring-theoretic construction which we can grade.
\begin{definition}[Graded module]
	Fix $R=R_0\oplus R_1\oplus\cdots$ a graded ring. Then an $R$-module $M$ is \textit{graded} if and only if we can write
	\[M\cong\bigoplus_{d\in\ZZ}M_d\]
	such that $R_iM_j\subseteq M_{i+j}$ for any $i\in\NN$ and $j\in\ZZ$.
\end{definition}

As a quick application, here is one reason to care about graded rings: they play nice with the Noetherian condition.
\begin{proposition}
	A graded ring $R=R_0\oplus R_1\oplus\cdots$ is Noetherian if and only if $R_0$ is Noetherian and $R$ is a finitely generated $R_0$-algebra.
\end{proposition}
\begin{proof}
	The backwards direction is \autoref{prop:fgalgebraisnoetherian}. For the forwards direction, take $R=R_0\oplus R_1\oplus\cdots$ a Noetherian, graded ring. We note that quotienting $R$ by the irrelevant ideal reveals that $R_0$ is a quotient of $R$, so $R_0$ is a Noetherian ring.

	It remains to show that $R$ is a finitely generated $R_0$-algebra. The idea is to imitate the Hilbert's finiteness theorem. Before doing anything, we adopt the convention that, for an arbitrary element
	\[f=f_0+f_1+\cdots\in R,\]
	we let $\deg f$ equal the largest $d$ for which $f_d\ne0$.
	
	We now proceed with the proof. Because $R$ is Noetherian, the irrelevant ideal
	\[I:=R_1\oplus R_2\oplus\cdots\]
	is finitely generated over $R$, so fix $I:=(r_1,\ldots,r_N)$. We claim that
	\[R\stackrel?=R_0[r_1,\ldots,r_N].\]
	For $\supseteq$, there is nothing to say. For $\subseteq$, pick up some $f\in R$, and we show that $f\in R_0[r_1,\ldots,r_N]$. By decomposing $f$ into its grading $f=f_0+f_1+\cdots$, we may assume that $f$ lives in one of the $R_d$.

	So now we induct on $d$. For $d=0$, we have $f\in R_0\subseteq R_0[r_1,\ldots,r_N]$ and are done immediately. So take $d>0$. Then $f\in I=(r_1,\ldots,r_N)$, so we may write
	\[f=\sum_{i=1}^Ng_ir_i\]
	for some $g_1,\ldots,g_N\in R$. By decomposing the $g_\bullet$ into their gradings, we see that we may assume that only the $\deg f-\deg r_i$ component is nonzero because all other components will cancel anyways.
	
	In particular, $g_i$ is homogeneous with degree $\deg f-\deg r_i$, so $g_i\in R_i$ with $i<d$. So by our induction, $g_i\in R_0[r_1,\ldots,r_N]$, and $f\in R_0[r_1,\ldots,r_N]$ by the decomposition of $f$ in $I$. This finishes the proof.
\end{proof}

\subsection{The Hilbert Function}
For this subsection, let $R:=k[x_0,\ldots,x_n]$ (note the zero-indexing!) be a ring graded by degrree, and let $M=\cdots\oplus M_{-1}\oplus M_0\oplus M_1\oplus\cdots$ be a finitely generated graded $R$-module. It follows that
\[\dim_kM_d<\infty\]
for each $d\in\ZZ$. Indeed, $R$ is Noetherian, so $M$ is Noetherian ($M$ is finitely generated over $R$), so we note that the $R$-submodule
\[M_d':=\bigoplus_{e\ge d}M_e\subseteq M\]
is a finitely generated as an $R$-module. (This is an $R$-submodule because it is closed under addition, and $R_iM_j\subseteq M_{i+j}$ for $i\in\NN$ and $j\in\ZZ$ gives closure under $R$-multiplication.) But the only way $rm\in M_d$ for $r\in R$ and $m\in M_d'$ is for $r\in R_0=k$ and $m\in M_d$, so the (finite number of) generators of $M_d'$ in $M_d$ will generate $M_d$ as a $k$-module.

This gives us the following definition.
\begin{definition}[Hilbert function]
	Let $M$ be a finitely generated module over $R:=k[x_0,\ldots,x_n]$, where $R$ is graded by degree. Then we define the \textit{Hilbert function} of $M$ as
	\[H_M(d):=\dim_kM_d.\]
\end{definition}
\begin{exe} \label{exe:hilbfuncex}
	Let $M=R=k[x_0,\ldots,x_n]$; i.e., view $R$ as an $R$-module. Then we compute $H_M(d)$.
\end{exe}
\begin{proof}
	Here, $M$ and $R$ have the same grading (because $M=R$), so we are computing
	\[H_M(d)=\dim_kR_d.\]
	To see this, we note that we can expand any polynomial $f\in R_d$ as a unique $k$-linear combination of the degree-$d$ monomials: after all, we can express generic polynomials in a unique $k$-linear combination of monomials, and $R_d$ requires everything involved to have degree $d$.

	Thus, $\dim_kR_d$ has basis consisting of the degree-$d$ monomials in $k[x_0,\ldots,x_n]$. Thus, we are counting tuples $(a_0,\ldots,a_n)$ of nonnegative integers (uniquely) associated to the monomial
	\[x_0^{a_0}\cdots x_n^{a_n}\]
	such that $a_0+\cdots+a_n=d$. But this is now merely a combinatorics problem! We claim that that this is $\binom{n+d}d$.
	
	Indeed, for any such tuple $(a_0,\ldots,a_n)$, imagine placing (in a single row) $a_0$ stones, then a stick, then $a_1$ stones, then a stick, and so on, ending by placing the last $a_n$ stones. In total, we are placing $d$ stones and $n$ sticks, and the arrangement of sticks and stones uniquely describes the tuples. So now we see there are
	\[\binom{n+d}d\]
	ways to put down $d$ sticks among $n+d$ ``slots'' of either sticks or stones. So indeed, we find that
	\[\boxed{H_M(d)=\binom{n+d}d},\]
	as desired.
\end{proof}
The above example found that $H_m(d)$ is a polynomial in $d$ of degree $r$. This happens in general.
\begin{theorem} \label{thm:hilbertpoly}
	Let $M$ be a finitely generated graded module over the ring $R:=k[x_0,\ldots,x_n]$, where $R$ is graded by degree. Then there exists a polynomial $P_M(d)$ of degree at most $n-1$ which agrees with $H_M(d)$ for sufficiently large $d$.
\end{theorem}
\begin{proof}
	The proof is by induction on $n$, where we will apply dimension-shifting of the grading for the inductive step. Our base case is $n=-1$, which makes $M$ into a graded $R=R_0=k$-vector space. But $M$ is thus finite-dimensional, the summation
	\[M=\bigoplus_{d\in\ZZ}M_d\]
	of $R_0=k$-vector spaces $M_d$ must have only finitely many nonzero terms, so $H_M(d)=0$ for sufficiently large $d$. So indeed, $H_M$ agrees with the polynomial $P_M\equiv0$ of degree $-\infty\le-1$ for sufficiently large inputs.

	Now, we will need to dimension-shift our grading in the proof that follows, so we have the following definition.
	\begin{definition}[Twist]
		Given a graded $R$-module $M$, we define the $d$th \textit{twist} $M(d)$ of $M$ to be the same underlying module but with grading given by
		\[M(d)_e:=M_{d+e}.\]
		To sanity check, we remark that $M=\bigoplus_{e\in\ZZ}M(d)_e=\bigoplus_{e\in\ZZ}M_{d+e}$ and $R_iM(d)_e=R_iM_{d+e}\subseteq M_{i+d+e}=M(d)_{i+e}$ verifies that we have in fact graded $M$.
	\end{definition}
	Note the Hilbert function is well-behaved by shifting: $H_{M(d)}(e)=\dim_kM(d)_e=\dim_kM_{d+e}=H_M(e+d)$.

	For the inductive step, the main point is to kill the $x_n$ coordinate in creative ways. Namely, $M$ being finitely generated over $k[x_0,\ldots,x_n]$ implies that $M/x_nM$ will be finitely generated over $k[x_0,\ldots,x_{n-1}]$ because any summation involving the $x_n$ letter got killed. So we start with exact sequence
	\[M\to M/x_nM\to 0.\]
	We do take a moment to remark $M/x_rM$ is in fact a graded module by
	\[\frac M{x_nM}\cong\frac{\bigoplus_{d\in\ZZ}M_d}{\bigoplus_{d\in\ZZ}x_nM_d}=\frac{\bigoplus_{d\in\ZZ}M_d}{\bigoplus_{d\in\ZZ}x_nM_{d-1}}\cong\bigoplus_{d\in\ZZ}\frac{M_d}{x_nM_{d-1}},\]
	so $M\onto M/x_nM$ is a map of graded modules. In particular, by disjointness, the pre-image of $M_d$ under multiplication by $x_n$ lives in $M_{d-1}$; note $x_nM_{d-1}\subseteq M_d$.
	
	Now, to take our sequence backwards, we would like to prepend by $M\stackrel{x_n}\to$, but this is not legal because multiplication by $x_n$ map will change the grading: we have $x_rM_{d-1}\subseteq M_d$. So instead we have to write down
	\[M(-1)\stackrel{x_n}\to M\to M/x_nM\to 0.\]
	This is in fact exact as graded modules because $M(-1)_d=M_{d-1}$ goes to $x_nM_{d-1}$ goes to $0$ in $M_d/x_nM_{d-1}$.
	
	To finish our short exact sequence, we let $K(-1)$ be the (twisted) kernel of $M(-1)\stackrel{x_n}\to M$ multiplication by $x_n$, and we get to write
	\[0\to K(-1)\to M(-1)\stackrel{x_n}\to M\to M/x_rM\to 0.\label{eq:finalses}\tag{$*$}\]
	We take a moment to recognize $K(-1)\subseteq M(-1)$ is finitely generated over $k[x_0,\ldots,x_n]$ because it is a submodule of the Noetherian module $M(-1)$. But any generator of $K(-1)$ multiplied by $x_n$ will simply vanish, so the same generators will finitely generate $K(-1)$ over $k[x_0,\ldots,x_{n-1}]$.

	Now, taking the Hilbert function everywhere in \autoref{eq:finalses}, counting dimensions gives
	\[H_{K(-1)}(d)-H_{M(-1)}(d)+H_M(d)-H_{M/x_rM}(d)=0.\]
	We can rewrite this as
	\[H_M(d)-H_M(d-1)=H_{M/x_nM}(d)-H_K(d-1),\]
	so we see that the first finite difference of $H_M$ agrees with $H_{M/x_nM}(d)-H_K(d-1)$, and the latter agrees with a polynomial of degree at most $n-1$ for sufficiently large $d$ by inductive hypothesis. So theory of finite differences tells us that $H_M(d)$ will agree with a polynomial of degree at most $n$, finishing the induction.
\end{proof}
\autoref{thm:hilbertpoly} justifies the following definition.
\begin{definition}[Hilbert polynomial]
	Let $M$ be a finitely generated graded module over the ring $R:=k[x_0,\ldots,x_n]$, where $R$ is graded by degree. The polynomial promised by \autoref{thm:hilbertpoly} is called the \textit{Hilbert polynomial} of $M$.
\end{definition}
\begin{remark}
	Geometrically, most of the time $M$ will end up being the coordinate ring of a projective variety, in which case the degree of the above Hilbert polynomial is the ``degree'' of the projective variety. So heuristically, most of the time the degree of the Hilbert polynomial will not achieve its maximum.
\end{remark}
Let's do some examples.
\begin{exe}
	Take $M:=k[x,y,z]/\left(x^2+y^2+z^2\right)$ as a $R:=k[x,y,z]$-submodule. We compute the Hilbert function for $M$.
\end{exe}
\begin{proof}
	For brevity, set $I:=\left(x^2+y^2+z^2\right)$. Note that $I$ is a graded ideal: if $fin k[x,y,z]$ is divisible by $x^2+y^2+z^2$, then we can write $f(x,y,z)=\left(x^2+y^2+z^2\right)q(x,y,z)$. Expanding $q=q_0+q_1+\cdots$ into its homogeneous parts, we see that
	\[f(x,y,z)=\sum_{d=2}^\infty\left(x^2+y^2+z^2\right)q_{d-2}\]
	provides a decomposition of $f$ into homogeneous parts, and by uniqueness this must be the decomposition of $f$. But each of these parts is manifestly divisible by $\left(x^2+y^2+z^2\right)$, so we have decomposed $f$ into $(I\cap R_0)\oplus(I\cap R_1)\oplus\cdots$.

	We have the following.
	\begin{itemize}
		\item We see $M_0=R_0/(I\cap R_0)$ is simply $k$, so $\dim M_0=1$.
		\item We see $M_1=R_1/(I\cap R_1)$ has basis $\{x,y,z\}$ because $I$ hasn't killed anything yet, so it has dimension $\dim M_1=3$.
		\item We see $R_2$ has basis $\left\{xy,yz,zx,x^2,y^2,z^2\right\}$, but $z^2\equiv-x^2-y^2\pmod I$ means that in $M_2=R_2(I\cap R_2)$, we can kill $z^2$. However, we can do this anywhere else (more rigorous justification below), so $\dim M_2=5$.
	\end{itemize}
	For the general case, fix a degree $d\ge2$. We note that there is a short exact sequence
	\[0\to R_{d-2}\stackrel{x^2+y^2+z^2}\to R_d\to\frac{R_d}{\left(x^2+y^2+z^2\right)R_{d-2}}\to0.\]
	Note the first map is well-defined because $\left(x^2+y^2+z^2\right)R_{d-2}\subseteq R_2R_{d-2}\subseteq R_d$. In fact, we claim that $\left(x^2+y^2+z^2\right)R_{d-2}=I\cap R_d$, for any $f\in I\cap R_d$ has $f(x,y,z)/\left(x^2+y^2+z^2\right)$ homogeneous of degree $d-2$. So this short exact sequence is actually
	\[0\to R_{d-2}\to R_d\to M_d\to 0.\]
	Thus, the short exact sequence gives $\dim M_d=\dim R_d-\dim R_{d-2}$, which by \autoref{exe:hilbfuncex} is $\binom{n+2}2-\binom n2=\frac{n^2+3n+2}2-\frac{n^2-n}2=2n+1$.
\end{proof}
\begin{remark}
	Continuing with the previous remark, we see the degree of the Hilbert polynomial of $M$ above is $1$, so the associated projective variety $Z\left(x^2+y^2+z^2\right)$ ought have dimension $1$. Well, $x^2+y^2+z^2=0$ defines a cone in affine $3$-space (more or less), which is dimension one of projective $2$-space upon recalling that lines becomes points.
\end{remark}
\begin{exe}[Eisenbud 1.19]
	Define $M:=k[x,y,z]/\left(xz-y^2,yx-z^2,xw-yz\right)$ as a $R:=k[x,y,z]$-module. We compute the Hilbert function for $M$.
\end{exe}
\begin{proof}
	We outline. For brevity, we set $I:=\left(xz-y^2,yx-z^2,xw-yz\right)$. The key observation is that it happens that $I$ is a free $k[x,w]$-module, with basis $\{1,y,z\}$.

	Thus, viewing $M$ as a $T:=k[x,w]$-module, checking the basis, gives that $M=T\oplus T(-1)\oplus T(-1)$ corresponding to our basis elements $\{1,y,z\}$. (Multiplication by $y$ or $z$ will shift the grading, hence $T(-1)$.) It follows that the Hilbert function is $H_M(n)=3n+1$.
\end{proof}
We will start with localization next class.