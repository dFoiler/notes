% !TEX root = ../notes.tex

Today we localize.

\subsection{Geometric Motivation}
Let's do an example from geometry.

Fix $X\subseteq\AA^n(k)$ an algebraic set and $U\subseteq X$ an open subset. We want to define functions on $U$.
\begin{example}
	Concretely, we might take $X=\AA^1(k)$ and $U=X\setminus\{0\}$. In this case, we have $A(X)=k[x]$, but we see that upon removing $0$ allows $\frac1x$ to be a function, giving
	\[A(U)=k[x,1/x].\]
	These turn out to be all the functions ``we care about.''
\end{example}
An alternative way to do this construction is to simply add a new function $y$ to $A(X)$ and then mod out in the freest possile way by the requirement $xy=1$, giving
\[A(U)=\frac{k[x,y]}{(xy-1)}.\]
Magically, these are the functions out of the hyperbola $xy=1$ in the plane $\AA^2(k)$, so amazingly localization has turned into functions from the open set $\AA^1(k)\setminus\{0\}$ to functions from the closed subset $\{(x,y)\in\AA^2(k):xy=1\}$. This magic, however, is special: it does not happen if we take $X=\AA^2(k)$ and $U=X\setminus\{(0,0)\}$.

Anyways, our point is that localization is one way we can talk about functions of spaces, especially of open sets. More generally, if we want to describe the space of functions out of the open set $\AA^n(k)\setminus Z(I)\subseteq\AA^n(k)$ for some $I\subseteq k[x_1,\ldots,x_n]$, then again ``the only functions we care about'' are
\[A\left(\AA^n(k)\setminus Z(I)\right)=A\left(\AA^n(k)\right)[1/f\text{ for each }f\in I].\]
In particular, we are allowed to append inverses of $I$ because the points on which $I$ vanishes are no longer in the space of interest. This process of appending inverses is ``localization.''

\subsection{Localization of Rings}
Let's build towards the definition of localization.
\begin{definition}[Multiplicatively closed]
	Fix $R$ a ring. Then a subset $U\subseteq R$ is \textit{multiplicatively closed} if any (finite) product of elements in $U$ also lives in $U$.
\end{definition}
Note that, by convention, the empty product $1$ will need to live in $U$. So, by induction, $U$ is multiplicatively closd if and only if $1\in U$ and for $x,y\in U$ to imply $xy\in U$.
\begin{remark}
	We do permit $0\in U$ and more generally zero-divisors to live in $U$. This tends to not be very interesting for localization.
\end{remark}
And here is our main character.
\begin{definition}[Localization, rings]
	Fix $R$ a ring and $U\subseteq R$ multiplicatively closed. Then we define $R\left[U^{-1}\right]$ to be the set of ordered pairs $(r,u)\in R\times U$ notated $\frac ru$ (with $r\in R$ and $u\in U$) modded out by the equivalence relation
	\[\frac{r_1}{u_1}=\frac{r_2}{u_2}\iff\text{there exists }v\in U\text{ such that }v(u_2r_1-u_1r_2)=0.\]
\end{definition}
In the discussion that follows, $R$ will be a ring and $U$ will always be multiplicatively closed.
\begin{remark}[Nir] \label{lem:localizeequiv}
	One needs the $v$ in the definition above to make $\equiv$ transitive. We run the checks.
	\begin{itemize}
		\item Reflexive: $\frac ru\equiv\frac ru$ because $1(ur-ur)=0$.
		\item Symmetric: $\frac{r_1}{u_1}\equiv\frac{r_2}{u_2}$ implies some $v\in U$ has $vu_2r_1=vu_1r_2$ implies $vu_1r_2=vu_2r_1$ implies $\frac{r_2}{u_2}=\frac{r_1}{u_1}$.
		\item Transitive: $\frac{r_1}{u_1}\equiv\frac{r_2}{u_2}$ implies some $v_1\in U$ has $v_1u_2r_1=v_1u_1r_2$, and $\frac{r_2}{u_2}\equiv\frac{r_3}{u_3}$ implies some $v_2\in U$ has $v_2u_3r_2=v_2u_2r_3$. Thus,
		\[(v_1v_2u_2)u_3r_1=(v_2u_3)v_1u_2r_1=(v_2u_3)v_1u_1r_2=(v_1u_1)v_2u_3r_2=(v_1u_1)v_2u_2r_3=(v_1v_2u_2)u_1r_3,\]
		so $\frac{r_1}{u_1}\equiv\frac{r_3}{u_3}$.
	\end{itemize}
\end{remark}
We can turn $R\left[U^{-1}\right]$ into a ring by using the standard addition and multiplication operations of these numbers. Namely, we define
\[\frac{r}{u}+\frac{s}{v}:=\frac{vr+us}{uv}\qquad\text{and}\qquad\frac ru\cdot\frac sv:=\frac{rs}{uv}.\]
For completeness, we check that these operations do not depend the exact operation.
\begin{itemize}
	\item Suppose $\frac{r_1}{u_1}=\frac{r_2}{u_2}$ and $\frac{s_1}{v_1}=\frac{s_2}{v_2}$ so that we are promised $u,v\in U$ such that $uu_2r_1=uu_1r_2$ and $vv_2s_1=vv_1s_2$. Now we observe that
	\begin{align*}
		(uv)(u_2v_2)(v_1r_1+u_1s_1) &= (vv_1v_2)(uu_2r_1)+(uu_1u_2)(vv_2s_1) \\
		&= (vv_1v_2)(uu_1r_2)+(uu_1u_2)(vv_1s_2) \\
		&= (uv)(u_1v_1)(v_2r_2+u_2s_2),
	\end{align*}
	so it follows $\frac{r_1}{u_1}+\frac{s_1}{v_1}=\frac{v_1r_1+u_1s_1}{u_1v_1}=\frac{v_2r_2+u_2s_2}{u_2v_2}=\frac{r_1}{u_1}+\frac{s_1}{v_1}$.
	\item Again suppose $\frac{r_1}{u_1}=\frac{r_2}{u_2}$ and $\frac{s_1}{v_1}=\frac{s_2}{v_2}$ so that we are promised $u,v\in U$ such that $uu_2r_1=uu_1r_2$ and $vv_2s_1=vv_1s_2$. But now we have
	\[(uv)(u_2v_2)(r_1s_1) = (uu_2r_1)(vv_2s_1)=(uu_1r_2)(vv_1s_2)=(uv)(u_1v_1)(r_2s_2),\]
	so it follows $\frac{r_1}{u_1}\cdot\frac{s_1}{v_1}=\frac{r_1s_1}{u_1v_1}=\frac{r_2s_2}{u_2v_2}=\frac{r_2}{u_2}\cdot\frac{s_2}{v_2}$.
\end{itemize}
Now, one can also show that by hand that these operations do in fact form a ring, but this is essentially by construction given how we already know how addition and multiplication of fractions should work. We will not do this check.
\begin{remark}
	Observe that because $1\in U$, there is a canonical map $R\to R\left[U^{-1}\right]$ by $r\mapsto r/1$. This need not be injective; e.g., take $U=\{0,1\}$, in which case $\frac r1=\frac01$ for each $r\in R$ because $0(1r-0\cdot1)=0$.
\end{remark}

We might also want to localize by sets which are not multiplicatively closed.
\begin{definition}[Multiplicative closure]
	Fix $R$ a ring. Then for any $U\subseteq R$, we define the \textit{multiplicative closure} $\overline U$ to be the set of all (finite) products of $U$.
\end{definition}
We quickly note that, for any subset $U\subseteq R$, the multiplicative closure $\overline U$ is multiplicatively closed. Indeed, any finite product in $\overline U$ is a finite product of finite products of $U$, which can be strung together into just a very large finite product of $U$. It follows that finite products in $\overline U$ stay in $\overline U$.

The multiplicative closure lets us adopt the following definition.
\begin{definition}[Localization, again]
	Fix $R$ a ring and $U\subseteq R$ an arbitrary subset. Then we define $R\left[U^{-1}\right]:=R\big[\overline U^{-1}\big]$.
\end{definition}

\subsection{Examples of Localization}
Here are some standard examples of localization.

For our first example, we note that when $R$ is an integral domain, the subset $U=R\setminus\{0\}$ is multiplicatively closed: $a\ne0$ and $b\ne0$ implies $ab\ne0$ because $R$ is an integral domain. So we have the following.
\begin{definition}[Field of fractions]
	If $R$ is an integral domain, then $R\setminus\{0\}$ is multiplicatively closed. So we define the \textit{field of fractions}
	\[K(R):=R\left[(R\setminus\{0\})^{-1}\right].\]
\end{definition}
\begin{example}
	We have that $K(\ZZ)=\QQ$.
\end{example}
\begin{example}
	We have that $K(k[x])=k(x)$.
\end{example}
What makes the above example work is that $(0)$ is a prime ideal of $R$ when $R$ is an integral domain (indeed, $ab\in(0)$ implies $ab=0$ implies $a=0\in(0)$ or $b=0\in(0)$).

More generally, for $\mf p\subseteq R$ a prime ideal, we see that $a,b\notin\mf p$ implies $ab\notin\mf p$, so $R\setminus\mf p$ is multiplicatively closed. So we have the following.
\begin{definition}[Localization at a prime]
	Fix $R$ a ring and $\mf p\subseteq R$ a prime ideal. Then $R\setminus\mf p$ is be multiplicatively closed, so we define the \textit{localization at a prime}
	\[R_\mf p:=R\left[(R\setminus\mf p)^{-1}\right].\]
\end{definition}
As mentioned above, we can realize the field of fractions from this construction.
\begin{example}
	When $R$ is an integral domain, $(0)$ is prime, and $R_{(0)}=K(R)$.
\end{example}
\begin{example}
	We have that
	\[\ZZ_{(p)}:=\left\{\frac ab:a,b\in\ZZ\text{ and }p\nmid b\right\}.\]
\end{example}
Here are some basic properties of $R_\mf p$.
\begin{proposition}
	Fix $R$ a ring and $\mf p\subseteq R$ a prime ideal. Then $R_\mf p$ is a local ring; in particular, $R_\mf p$ has unique maximal ideal
	\[\mf pR_\mf p:=\left\{\frac ru:r\in\mf p\text{ and }u\notin\mf p\right\}.\]
\end{proposition}
\begin{proof}
	Very quickly, we note that $\mf pR_\mf p\ne R_\mf p$ because $\frac11\notin\mf pR_\mf p$. Indeed, for any representative $\frac11=\frac ru$, we see some $v\notin\mf p$ has $vr=vu\notin\mf p$, so $r\notin\mf p$, implying $\frac ru\notin\mf p$.
	
	The main point is to show that all proper ideals are contained in $\mf pR_\mf p$. Equivalently, suppose that $I\subseteq R$ is an ideal not contained in $\mf pR_\mf p$, and we show that $I=R_\mf p$. Well, we are promised some $\frac xu\in I\setminus\mf pR_\mf p$ where $x,u\notin\mf p$. But then by closure if $I$ under $R_\mf p$-multiplication, we see
	\[\frac11=\frac ux\cdot\frac xu\in I,\]
	so indeed, $I=R_\mf p$.

	We already checked tht $\mf pR_\mf p$ is a proper ideal, so it immediately follows that $\mf pR_\mf p$ is a maximal ideal: any ideal $I$ with $\mf pR_\mf p\subsetneq I\subseteq R_\mf p$ will immediately force $I=R_\mf p$ by the above. Further, $\mf pR_\mf p$ is the unique maximal ideal because any maximal ideal $\mf m$ is proper, so it follows
	\[\mf m\subseteq\mf pR_\mf p\subseteq R_\mf p.\]
	This gives $\mf m=\mf pR_\mf p$ by the maximality of $\mf m$, so we are done.
\end{proof}
\begin{example}
	When $R$ is an integral domain and $\mf p=(0)$ is the (prime) zero ideal, we see that, indeed $\mf pR_\mf p=(0)$ is the unique maximal ideal in the field of fractions $K(R)=R_\mf p$.
\end{example}
The uniquely special maximal ideal $\mf pR_\mf p$ gives rise to the following definition for these local rings.
\begin{definition}[Residue field]
	Fix $R$ a local ring with unique maximal ideal $\mf m$. Then we define the \textit{residue field} to be $\kappa:=R/\mf m$.
\end{definition}
\begin{example}
	We have that $\ZZ_{(p)}/p\ZZ_{(p)}\cong\ZZ/p\ZZ$. In particular, observe that the characteristic has changed.
\end{example}
\begin{remark}
	Geometrically, we view primes $\mf p$ as living in the ``space'' $\op{Spec}R$. Then here $R_\mf p$ is intended to look like a ``neighborhood'' or ``germ'' at the point $\mf p$. Hence the name localization.
\end{remark}

As we hoped for in the motivation, we note that the above examples tend to feature $R\left[U^{-1}\right]$ as the ring $R$ where the elements of $U$ have become invertible. In fact, this notion can be formalized into a universal property for localization.
\begin{proposition} \label{prop:localuniprop}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed subset. Let $\varphi:R\to R\left[U^{-1}\right]$ be the canonical map. Now, suppose we are given a ring map $\psi:R\to S$ such that $\psi(U)\subseteq R^\times$. Then there is a unique ring morphism $\gamma$ making the diagram commute.
	% https://q.uiver.app/?q=WzAsMyxbMCwwLCJSIl0sWzEsMCwiUlxcbGVmdFtVXnstMX1cXHJpZ2h0XSJdLFsxLDEsIlMiXSxbMCwyLCJcXHBzaSIsMl0sWzAsMSwiXFx2YXJwaGkiXSxbMSwyLCJcXGdhbW1hIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV1d
	\[\begin{tikzcd}
		R & {R\left[U^{-1}\right]} \\
		& S
		\arrow["\psi"', from=1-1, to=2-2]
		\arrow["\varphi", from=1-1, to=1-2]
		\arrow["\gamma", dashed, from=1-2, to=2-2]
	\end{tikzcd}\]
\end{proposition}
\begin{proof}
	We tackle uniqueness and existence separately.
	\begin{itemize}
		\item We show that the map $\gamma$ is unique. For any $r\in R$, observe that we are forced into
		\[\gamma(r/1)=\gamma(\varphi(r))=\psi(r),\]
		so $\gamma$ is forced on elements of the form $\frac r1$. Further, for any $\frac ru\in R\left[U^{-1}\right]$, we see that
		\[\psi(u)\gamma\left(\frac ru\right)=\gamma\left(\frac u1\right)\gamma\left(\frac ru\right)=\gamma\left(\frac r1\right)=\psi(r),\]
		so we see $\gamma\left(\frac ru\right)=\psi(u)^{-1}\psi(r)$ forces everything in $R\left[U^{-1}\right]$.
		\item We now show that the map
		\[\gamma\left(\frac ru\right):=\psi(u)^{-1}\psi(r)\]
		is in fact a well-defined $R$-module homomorphism. Note that $\psi(u)\in S^\times$ by definition of $\psi$, so at the very least the above expression makes physical sense.
		\begin{itemize}
			\item We show $\gamma$ is well-defined. Suppose that $\frac{r_1}{u_1}=\frac{r_2}{u_2}$ so that we need to show $\gamma\left(\frac{r_1}{u_1}\right)=\gamma\left(\frac{r_2}{u_2}\right)$. In other words, we need to show
			\[\psi(u_1)^{-1}\psi(r_1)\stackrel?=\psi(u_2)^{-1}\psi(r_2).\]
			This is equivalent to showing that
			\[\psi(u_2r_1)=\psi(u_2)\psi(r_1)\stackrel?=\psi(u_1)\psi(r_2)=\psi(u_1r_2).\]
			Now, we know $\frac{r_1}{u_1}=\frac{r_2}{u_2}$, so there is $u\in U$ such that $uu_2r_1=uu_1r_2$, so it follows that
			\[\psi(u)\psi(u_2r_1)=\psi(u)\psi(u_1r_2),\]
			so multiplying both sides by $\psi(u)^{-1}$ finishes.
			\item We show $\gamma$ is a ring homomorphism. Quickly, we see $\gamma\left(\frac11\right)=\psi(1)^{-1}\psi(1)=1$. Additionally, for any $\frac ru,\frac sv\in R\left[U^{-1}\right]$, we see
			\begin{align*}
				\gamma\left(\frac ru+\frac sv\right) &= \gamma\left(\frac{vr+us}{uv}\right) \\
				&= \psi(uv)^{-1}\psi(vr+us) \\
				&= \psi(v)^{-1}\psi(v)\psi(u)^{-1}\psi(r)+\psi(u)^{-1}\psi(u)\psi(v)^{-1}\psi(s) \\
				&= \gamma\left(\frac ru\right)+\gamma\left(\frac sv\right).
			\end{align*}
			Similarly,
			\begin{align*}
				\gamma\left(\frac ru\cdot\frac sv\right) &= \gamma\left(\frac{rs}{uv}\right) \\
				&= \psi(uv)^{-1}\psi(rs) \\
				&= \psi(u)^{-1}\psi(r)\cdot\psi(v)^{-1}\psi(s) \\
				&= \gamma\left(\frac ru\right)\cdot\gamma\left(\frac sv\right).
			\end{align*}
			This finishes our checks.
			\qedhere
		\end{itemize}
	\end{itemize}
\end{proof}

\subsection{Localization of Modules}
We can also localize modules, in essentially the same way.
\begin{definition}[Localization, modules]
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed subset. Then, given an $R$-module $M$, we define $M\left[U^{-1}\right]$ to be the set of ordered pairs notated $\frac mu$ (with $m\in M$ and $u\in U$) modded out by the equivalence relation
	\[\frac{m_1}{u_1}=\frac{m_2}{u_2}\iff\text{there exists }v\in U\text{ such that }v(u_2m_1-u_1m_2)=0.\]
\end{definition}
Again, the extra $v$ in the definition is to make $\equiv$ an equivalence relation; this check is the same as the check in \autoref{lem:localizeequiv} by replacing all $r$s with $m$s.

One can define addition by fractions in the same by-hand way, writing
\[\frac{m_1}{u_1}+\frac{m_2}{u_2}=\frac{u_1m_2+u_2m_1}{u_1u_2}.\]
Again, it is not too hard to check that this is well-defined (it is essentially the same as the check we did earlier) and gives an abelian group law (which we will actively choose to not write out). Further, $M\left[U^{-1}\right]$ even has an $R\left[U^{-1}\right]$ structure by
\[\frac rv\cdot\frac mu:=\frac{rm}{vu}.\]
Thus, localizing at $U$ will be able to define a functor from $R$-modules to $R\left[U^{-1}\right]$-modules.

We remark that we still have a canonical $R$-module homomorphism $\varphi:M\to M\left[U^{-1}\right]$ by $\varphi:m\mapsto m/1$: to check this is an $R$-module homomorphism, pick up $r_1,r_2\in R$ and $m_1,m_2\in M$, and we see that
\[\varphi(r_1m_1+r_2m_2)=\frac{r_1m_1+r_2m_2}1=\frac{r_1}1\cdot\frac{m_1}1+\frac{r_2}1\cdot\frac{m_1}1=\frac{r_1}1\cdot\varphi(m_1)+\frac{r_2}1\cdot\varphi(m_2).\]
Again, the canonical map $\varphi$ need not be injective, but we can describe its kernel.
\begin{lemma}
	Fix an $R$-module $M$ and $U\subseteq R$ a multiplicatively closd subset. Then the kernel of the canonical map $\varphi:M\to M\left[U^{-1}\right]$ is
	\[\ker\varphi=\{m\in M:um=0\text{ for some }u\in U\}.\]
\end{lemma}
\begin{proof}
	We see $m\in\ker\varphi$ if and only if $\frac m1=\frac01$ if and only if there exists $u\in U$ such that $um=0$.
\end{proof}
Concretely, viewing a ring $R$ as an $R$-module, we see the kernel of the canonical map $R\to R\left[U^{-1}\right]$ consists of the $r\in R$ such that $ru=0$ for some $u\in U$.
\begin{example}
	If $0\in U$, then all of $R$ lives in the kernel of the canonical map $R\to R\left[U^{-1}\right]$.
\end{example}
\begin{example}
	If $R$ is an integral domain, then the map $R\to K(R)$ is injective because $ru=0$ for $r\in R$ and $u\in R\setminus\{0\}$ implies $r=0$.
\end{example}

\subsection{Localization of Ideals}
We would like to classify ideals under localization. Recall that, given a morphism $\varphi:R\to S$, the pre-image of an ideal $J\subseteq S$ will be an ideal $\varphi^{-1}(J)\subseteq R$.\footnote{If $r_1,r_2$ and $x_1,x_2\in\varphi^{-1}(J)$, then $\varphi(r_1x_1+r_2x_2)=r_1\varphi(x_1)+r_2\varphi(x_2)\in J$ by closure, so $r_1x_1+r_2x_2\in\varphi^{-1}(J)$.}
\begin{remark}
	In contrast, given an ideal $I\subseteq R$, we need not have $\varphi(I)$ an ideal of $S$. Indeed, in the inclusion $\ZZ\into\QQ$, we have $\ZZ\subseteq\ZZ$ is an ideal, but the image $\ZZ\subseteq\QQ$ is not an ideal because the image contains $1$ but is not the full ring $\QQ$.
\end{remark}
In fact, we discussed above that prime ideals go to prime ideals. We can also show that this map of ideals preserves inclusions and unions and intersections, which holds on the level that $\varphi$ is a function of sets.
\begin{lemma}
	Fix $f:A\to B$ a function and $S,T\subseteq B$. Then the following are true.
	\begin{itemize}
		\item $f^{-1}(S\cap T)=f^{-1}(S)\cap f^{-1}(T)$.
		\item $f^{-1}(S\cup T)=f^{-1}(S)\cup f^{-1}(T)$.
		\item If $S\subseteq T$, then $f^{-1}(S)\subseteq f^{-1}(T)$.
	\end{itemize}
\end{lemma}
\begin{proof}
	We take these one at a time.
	\begin{itemize}
		\item Note $x\in f^{-1}(S\cap T)$ if and only if $f(x)\in S\cap T$ if and only if $f(x)\in S$ and $f(x)\in T$ if and only if $x\in f^{-1}(S)$ and $x\in f^{-1}(T)$ if and only if $\in f^{-1}(S)\cap f^{-1}(T)$.
		\item Rewrite the above argument replacing all $\cap$ with $\cup$ and all ``and'' with ``or.''
		\item Note $S\subseteq T$ is equivalent to $S=S\cap T$, which gives
		\[f^{-1}(S)=f^{-1}(S\cap T)=f^{-1}(S)\cap f^{-1}(T)\subseteq f^{-1}(T),\]
		finishing.
		\qedhere
	\end{itemize}
\end{proof}

Now, in our case, we are focusing on the canonical morphism $\varphi:R\to R\left[U^{-1}\right]$. We have the following sequence of propositions.
\begin{lemma} \label{lem:localidealsa}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed set, and let $\varphi:R\to R\left[U^{-1}\right]$ be the canonical map.
	
	Then given any $R\left[U^{-1}\right]$-ideal $I$, pre-image followed by localization does nothing:
	\[I=\varphi^{-1}(I)\left[U^{-1}\right].\]
	It follows that the map from $R\left[U^{-1}\right]$-ideals to $R$-ideals by $I\mapsto\varphi^{-1}(I)$ is injective.
\end{lemma}
\begin{proof}
	Fix $I\subseteq R\left[U^{-1}\right]$ an ideal. Formally, $\varphi^{-1}(I)$ is the set of elements $x\in R$ such that $\frac x1\in I$, so
	\[\varphi^{-1}(I)\left[U^{-1}\right]=\left\{\frac xu:\frac x1\in I\text{ and }u\in U\right\}.\]
	We identify this with a subset of $R\left[U^{-1}\right]$ in the obvious way, and we note that this identification preserves the $R\left[U^{-1}\right]$-module structure because we defined localization of modules with the same $R\left[U^{-1}\right]$-action and addition law as the ring $R\left[U^{-1}\right]$ itself.

	We now show $I=\varphi^{-1}(I)\left[U^{-1}\right]$ by taking the inclusions separately.
	\begin{itemize}
		\item We show that $\varphi^{-1}(I)\left[U^{-1}\right]\subseteq I$. Indeed, any $\frac xu\in\varphi^{-1}(I)\left[U^{-1}\right]$ will have $\frac x1\in I$, so $\frac xu=\frac1u\cdot\frac x1\in I$ because $I$ is closed under $R\left[U^{-1}\right]$.
		\item It remains to show $I\subseteq\varphi^{-1}(I)\left[U^{-1}\right]$. Well, fix some $\frac ru\in I$. Then, because $I$ is a $R\left[U^{-1}\right]$-ideal, we see
		\[\frac r1=\frac u1\cdot\frac ru\in I,\]
		so it follows that $r\in\varphi^{-1}(I)$, and so $\frac ru\in\varphi^{-1}(I)\left[U^{-1}\right]$. This finishes.
	\end{itemize}
	We finish by showing that $I\mapsto\varphi^{-1}(I)$ is injective. Indeed, if $I,J\subseteq R\left[U^{-1}\right]$ are ideals such that $\varphi^{-1}(I)=\varphi^{-1}(J)$ implies that
	\[I=\varphi^{-1}(I)\left[U^{-1}\right]=\varphi^{-1}(J)\left[J^{-1}\right]=J,\]
	so we are done.
\end{proof}
\begin{lemma} \label{lem:localidealsb}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed set, and let $\varphi:R\to R\left[U^{-1}\right]$ be the canonical map.
	
	Further, fix an $R$-ideal $J$. The following are equivalent.
	\begin{listroman}
		\item $J=\varphi^{-1}(I)$ for some $R\left[U^{-1}\right]$-ideal $I$.
		\item $J=\varphi^{-1}\left(J\left[U^{-1}\right]\right)$.
		\item If $ru\in J$ for some $r\in R$ and $u\in U$, then $r\in J$. In other words, $U\cap J=\emp$ and $U/J\subseteq R/J$ contains no zero-divisors.
	\end{listroman}
\end{lemma}
\begin{proof}
	We show our implications separately.
	\begin{itemize}
		\item We show that (ii) implies (i). For this, we only need to show that $J\left[U^{-1}\right]$ is an ideal of $R\left[U^{-1}\right]$. But this is true because $J\left[U^{-1}\right]$ is an $R\left[U^{-1}\right]$-module, and we can see set-wise that it is a subset of $R\left[U^{-1}\right]$, and the operations match up by how $J\left[U^{-1}\right]$ is defined.

		Thus, $J\left[U^{-1}\right]$ is a $R\left[U^{-1}\right]$-submodule of $R\left[U^{-1}\right]$, which is exactly an $R\left[U^{-1}\right]$-ideal.

		\item We show that (i) implies (ii). Fix $I\subseteq R\left[U^{-1}\right]$ an ideal, and let $J:=\varphi^{-1}(I)$. Then we claim that $J=\varphi^{-1}\left(J\left[U^{-1}\right]\right)$. Well, we see
		\[J\left[U^{-1}\right]=\varphi^{-1}(I)\left[U^{-1}\right]=I\]
		by \autoref{lem:localidealsa}, so it follows $J=\varphi^{-1}(U)=\varphi^{-1}\left(J\left[U^{-1}\right]\right)$.

		\item We show that (ii) implies (iii). We are given an $R$-ideal $J$ such that $J=\varphi^{-1}\left(J\left[U^{-1}\right]\right)$. Now, given any $u\in U$, we show that $[u]_J\in R/J$ is not a zero-divisor.
		
		Indeed, suppose that $ru\in J$ for any $r\in R$ and $u\in U$. But then
		\[\frac r1=\frac{ru}u\in J\left[U^{-1}\right],\]
		so it follows $r\in\varphi^{-1}\left(J\left[U^{-1}\right]\right)=J$. This finishes.

		\item We show that (iii) implies (ii). Fix an $R$-ideal $J$ such that $ru\in J$ with $r\in R$ and $u\in U$ implies $r\in J$. We show that $J=\varphi^{-1}\left(J\left[U^{-1}\right]\right)$.

		We can show $J\subseteq\varphi^{-1}\left(J\left[U^{-1}\right]\right)$ without the hypothesis: any $x\in J$ has $\frac x1\in J\left[U^{-1}\right]$, so $x\in\varphi^{-1}\left(J\left[U^{-1}\right]\right)$.

		The reverse inclusion is harder. Fix some $x\in\varphi^{-1}\left(J\left[U^{-1}\right]\right)$, which implies $\frac x1\in J\left[U^{-1}\right]$. But then we can find some $\frac yu\in J\left[U^{-1}\right]$ such that
		\[\frac x1=\frac yu,\]
		so it follows there is some $v\in U$ such that $v(ux-y)=0\in J$. So by hypothesis on $J$ and $U$, we see that $ux-y\in J$ is forced, so $ux\in J$, so $x\in J$. This finishes.
		\qedhere
	\end{itemize}
\end{proof}
And finally here is our classification of ideals under localization.
\begin{theorem}
	Fix $R$ a ring and $U\subseteq R$ a multiplicatively closed set, and let $\varphi:R\to R\left[U^{-1}\right]$ be the canonical map. Then $\varphi^{-1}$ provides a bijection between the prime ideals of $R$ which are disjoint from $U$ and the prime ideals of $R\left[U^{-1}\right]$.
\end{theorem}
\begin{proof}
	This will follow from the above properties. Observe that $\varphi^{-1}$ will indeed send prime ideals of $R\left[U^{-1}\right]$ to prime ideals of $R$, and this mapping is injective.

	Thus, it remains to show that the image of $\varphi^{-1}$ on $\op{Spec}R\left[U^{-1}\right]$ is as described. Well, by \autoref{lem:localidealsb}, these are exactly the prime $R$-ideals $\mf p$ such that, if $ru\in \mf p$ for some $r\in\mf p$ and $u\in U$, then $r\in\mf p$. Call these primes ``good,'' which we want to show is equivalent to being disjoint from $U$.

	Certainly, if $\mf p$ is a prime disjoint from $U$, then $ru\in\mf p$ for $r\in\mf p$ and $u\in U$, then $u\notin\mf p$ will force $r\in\mf p$; thus, $\mf p$ is good. So conversely, if $\mf p$ is not disjoint from $U$, then set $u\in U\cap\mf p$, and we see
	\[1u\in\mf p\]
	while $1\notin\mf p$ (prime ideals are proper), so it follows that $\mf p$ is not good.
\end{proof}
Here is a reason to care about the above our study of ideals under localization.
\begin{corollary}
	Any localization of a Noetherian ring $R$ is still a Noetherian ring.
\end{corollary}
\begin{proof}
	Fix an ideal $I\subseteq R\left[U^{-1}\right]$, and we show that it is finitely generated. Well, $\varphi^{-1}(I)\subseteq R$ is an ideal, which is finitely generated because $R$ is Noetherian, so fix generators
	\[\varphi^{-1}(I)=(x_1,\ldots,x_n).\]
	Now we claim that
	\[I=(x_1/1,\ldots,x_n/1)\]
	as an $R\left[U^{-1}\right]$-ideal. Certainly $(x_1/1,\ldots,x_n/1)\subseteq I$. In the other direction, given any $\frac xu\in I$, we see that $\frac x1=\frac u1\cdot\frac xu\in I$, so $x\in\varphi^{-1}(I)$. but then we can write
	\[x=\sum_{k=1}^nr_kx_k\]
	for some constants $r_k$. It follows
	\[\frac xu=\sum_{k=1}^n\frac{r_k}u\cdot\frac{x_k}1\in(x_1/1,\ldots,x_n/1),\]
	finishing.
\end{proof}

\subsection{The \textrm{Hom}-Functor}
Later in life we will discuss localization as a tensor product, but before then we must talk about the tensor product, so for now we will talk about the \textrm{Hom}-functor.
\begin{warn}
	The following two subsections do not contain many proofs. This is mostly due to laziness; the interested are referred to my 250A notes or any other standard algebra reference.
\end{warn}
Here is our definition.
\begin{definition}[\textrm{Hom}]
	Fix $R$ a ring. Then, for $R$-modules $M$ and $N$, we define $\op{Hom}_R(M,N)$ to be the abelian group of $R$-module homomorphisms $M\to N$.
\end{definition}
In fact, we can endow $\op{Hom}_R(M,N)$ with an $R$-module structure, essentially because our rings are commutative. Namely, we define
\[(r\varphi)(m):=r\cdot\varphi(m).\]
It is not too hard to verify that this does in fact define a ring action.
\begin{definition}[\textrm{End}]
	Fix $R$ a ring. Then we define the \textit{endomorphisms} of an $R$-module $M$ to be $\op{End}_R(M):=\op{Hom}_R(M,M)$.
\end{definition}
Note that $\op{End}_R(M)$ is in fact a (non-commutative) $R$-algebra, where our multiplication is given by composition.

Here are some basic facts with short explanations as is necessary.
\begin{enumerate}
	\item We have that $\op{Hom}_R(R,M)\cong M$ canonically by $\varphi\mapsto\varphi(1)$.
	\item Given two morphisms $\alpha:M_2\to M_1$ and $\beta:N_1\to N_2$, then we have a map $\op{Hom}_R(M_1,N_1)\to\op{Hom}_R(M_2,N_2)$ by $\varphi\mapsto\beta\circ\varphi\circ\alpha$. In fact, this is an $R$-module homomorphism.
	\item We have that
	\[\op{Hom}_R\left(\bigoplus_{\alpha\in I}M_\alpha,N\right)\cong\prod_{\alpha\in I}\op{Hom}_R(M_\alpha,N)\]
	for any collection of $R$-modules $\{M_\alpha\}_{\alpha\in I}$. The main point is that, to define a map $\bigoplus_\alpha M_\alpha\to N$, is is exactly the same information as describing what to do with each $M_\beta\into\bigoplus_\alpha M_\alpha\to N$ copy.
	\item In fact, $\op{Hom}$ is a left-exact functor. Namely, exact sequences
	\[0\to A\to B\to C\]
	yields the exact sequence
	\[0\to\op{Hom}_R(M,A)\to\op{Hom}_R(M,B)\to\op{Hom}_R(M,C).\]
	Similarly,
	\[0\to\op{Hom}_R(C,M)\to\op{Hom}_R(B,M)\to\op{Hom}_R(A,M)\]
	is exact. Note the reversed of direction of arrows here. The easiest way to see this is by the tensor-hom adjuction: hom is a right adjoint, so it preserves limits, so it preserves kernels, so it is left-exact.
\end{enumerate}
\begin{remark}
	However, $\op{Hom}_R$ does not fully preserve short exact sequences. In the first, case we are saying that a morphism $\op{Hom}_R(M,C)$ might not be extendable to a map $\op{Hom}_R(M,B)$. By way of example, consider the short exact sequence of $\ZZ$-modules
	\[0\to2\ZZ\to\ZZ\to\ZZ/2\ZZ\to0.\]
	Then taking $\op{Hom}_\ZZ(\ZZ/2\ZZ,-)$ gives
	\[0\to0\to0\to\ZZ/2\ZZ\to0,\]
	which is not exact in the last term.
\end{remark}

\subsection{Tensor Product}
We should probably start by defining tensor products, which requires defining bilinear maps.
\begin{definition}[Bilinear]
	Fix $A,B,C$ as $R$-modules for some ring $R$. Then a map $\varphi:A\times B\to C$ is \textit{$R$-bilinear} if and only if is $R$-linear in both arguments. Namely, we require
	\[\varphi(r_1a_1+r_2a_2,b)=r_1\varphi(a_1,b)+r_2\varphi(a_2,b)\]
	and
	\[\varphi(a,r_1b_1+r_2b_2)=r_1\varphi(a,b_1)+r_2\varphi(a,b_2).\]
\end{definition}
This lets us define the tensor product to more or less be the object universal with respect to giving bilinear maps.
\begin{definition}[Tensor product]
	Fix $R$ a ring and $A$ and $B$ as $R$-modules. Then we define $A\otimes_RB$ to be the free module generated generated by $a\otimes b$ for $a\in A$ and $b\in B$ modulo the relation
	\[(a_1m_1+a_2m_2)\otimes(b_1n_1+b_2n_2)=a_1b_1(m_1\otimes n_1)+a_1b_2(m_1\otimes n_2)+a_2b_1(m_2\otimes n_1)+a_2b_2(m_2\otimes n_2).\]
\end{definition}
Elements of the tensor product $A\otimes B$ are in general not very easy to understand and in general they can be described as being some finite sum of elements $a\otimes b$ for various $a\in A$ and $b\in B$. In the case where $A$ and $B$ are vector spaces over a field, then the tensor of two basis vectors will create a basis (we will prove this below), but this is essentially the only general example.

Nevertheless, let's do an example.
\begin{example}
	We work in $\ZZ$-mod, and we compute $\ZZ/2\ZZ\otimes_\ZZ\ZZ/3\ZZ$. It will be enough to consider elements of the form $m\otimes n$. The main point is that
	\[2(m\otimes n)=2m\otimes n=0\qquad\text{and}\qquad3(m\otimes n)=m\otimes3n=0,\]
	so $m\otimes n=0$ follows. Thus, $\ZZ/2\ZZ\otimes_\ZZ\ZZ/3\ZZ=0$.
\end{example}
As with $\op{Hom}_R$, the tensor product $\otimes_R$ has the following list of nice properties. Again, we provide short explanations as is necessary.
\begin{enumerate}
	\item We have that $M\cong R\otimes_RM$ by $m\mapsto m\otimes1$.
	\item Given morphisms $\alpha:M_1\to M_2$ and $\beta:N_1\to N_2$, we can define a map
	\[\alpha\otimes\beta:M_1\otimes_R N_1\to M_2\otimes_R N_2\]
	by extending $m\otimes n\mapsto\alpha m\otimes\beta n$ linearly to the full tensor product. The map $\alpha\otimes\beta$ can be checked to be an $R$-module homomorphism.
	\item We have that $M\otimes_R N\cong N\otimes_R M$ by $m\otimes n\mapsto n\otimes m$.
	\item We have that
	\[\left(\bigoplus_{\alpha\in I}M_\alpha\right)\otimes_RN\cong\bigoplus_{\alpha\in I}(M_\alpha\otimes_R N).\]
	The most hands-free way to see this is the tensor-hom adjuction: tensoring is a left adjoint, so it preserves colimits, so it preserves coproducts.
	\item The functor $-\otimes_RM$ is right-exact: given an exact sequence
	\[A\to B\to C\to 0,\]
	we have an exact sequence
	\[A\otimes_RM\to B\otimes_RM\to C\otimes_RM\to 0.\]
	Here the maps are the induced ones. The easiest way to see this is by the tensor-hom adjuction: tensoring is a left adjoint, so it preserves colimits, so it preserves cokernels, so it is right-exact.
\end{enumerate}
% To see this, note $B\otimes_RM\to C\otimes_RM$ is surjective by lifting some $m\otimes_Rc$ for $m\in M$ and $c\in C$ by taking some pre-image $b\in B$ for $c$ and then conjuring $m\times b\mapsto m\otimes c$.

% For exactness in the middle, we let $f:A\to B$ be the first map and consider the induced map
% \[M\otimes C\to\frac{M\otimes B}{M\otimes\im f}\]
% in order to split the short exact sequence or something.
Here are some example applications.
\begin{exe}
	Fix $a$ and $b$ integers. Then
	\[\ZZ/a\ZZ\otimes_\ZZ\ZZ/b\ZZ\cong\ZZ/\gcd(a,b)\ZZ.\]
\end{exe}
\begin{proof}
	Tensoring the right-exact sequence
	\[\ZZ\stackrel{\times a}\to\ZZ\to\ZZ/a\ZZ\to0\]
	by $\ZZ/b\ZZ$ gives the right-exact sequence
	\[\ZZ\otimes_\ZZ\ZZ/b\ZZ\stackrel{\times a}\to\ZZ\otimes_\ZZ\ZZ/b\ZZ\to\ZZ/a\ZZ\otimes_\ZZ\ZZ/b\ZZ\to0.\]
	Using the canonical isomorphisms $\ZZ\otimes_\ZZ M\cong M$ for abelian groups $M$ and tracking our morphisms through, we get the right-exact sequence
	\[\ZZ/b\ZZ\stackrel{\times a}\to\ZZ/b\ZZ\to\ZZ/a\ZZ\otimes_\ZZ\ZZ/b\ZZ\to0.\]
	It follows that
	\[\ZZ/a\ZZ\otimes_\ZZ\ZZ/b\ZZ\cong\frac{\ZZ/b\ZZ}{a\ZZ/b\ZZ}=\frac{\ZZ/b\ZZ}{(a\ZZ+b\ZZ)/b\ZZ}\cong\frac\ZZ{a\ZZ+b\ZZ}.\]
	This finishes.
\end{proof}
\begin{remark}
	The above example also shows that the functor $-\otimes_RM$ need not be fully exact. For example, tensoring
	\[0\to\ZZ\stackrel{\times2}\to\ZZ\]
	by $\ZZ/2\ZZ$ gives the sequence of maps
	\[0\to\ZZ\otimes_\ZZ\ZZ/2\ZZ\stackrel{\times2}\to\ZZ\otimes_\ZZ\ZZ/2\ZZ.\]
	However, the map $\stackrel{\times2}\to$ now takes $k\otimes\ell\mapsto2k\otimes\ell=k\otimes2\ell=0$, so this sequence is not exact.
\end{remark}
\begin{example} \label{ex:tensorvecspaces}
	Let $V$ and $W$ to be two $k$-vector spaces with bases $\{v_\alpha\}_{\alpha\in I}$ and $\{w_\beta\}_{\beta\in J}$. This means that
	\[V\cong\bigoplus_{\alpha\in I}kv_\alpha\qquad\text{and}\qquad W\cong\bigoplus_{\beta\in J}kw_\beta,\]
	so the above facts let us write
	\[V\otimes_kW\cong\bigoplus_{\alpha\in I,\beta\in J}(kv_\alpha\otimes_kkw_\beta).\]
	Now, $kv_\alpha\otimes_kkw_\beta\cong kv_\alpha\cong k$ canonically by $xv_\alpha\otimes w_\beta\mapsto xv_\alpha\mapsto x$, so we can view each $kv_\alpha\otimes_kkw_\beta$ as a one-dimensional $k$-vector space. Tracking the above isomorphism forwards, we see that the elements $v_\alpha\otimes w_\beta\in V\otimes_kW$ are forming a $k$-basis.
\end{example}
Next time we will show $M\left[U^{-1}\right]$ is canonically isomorphic to $R\left[U^{-1}\right]\otimes_RM$ to continue our discusion of localization.