\documentclass[../notes.tex]{subfiles}

\begin{document}

% !TEX root = ../notes.tex













I want to be a frog because of no schoolwork, no stress, no problems.

\subsection{Noetherian Rings}
Today we're talking about Noetherian rings. Here is our motivation.
\begin{example}
	Fix $k$ a field. Then $k[x]$ is a principal ideal domain because it is Euclidean. However, $k[x,y],$ is not principally generated: for example, $(x,y)$ is not generated by one element. Similarly, $k[x,y,z]$ has $(x,y,z)$ which needs three elements, and so on.
\end{example}
We might hope that $k[x_1,\ldots,x_n]$ requires $n$ elements to generate, but this is not true.
\begin{exercise}
	Fix $k$ a field. For any $n\in\NN,$ there exist ideals of $k[x,y]$ not generated by $n$ elements.
\end{exercise}
\begin{proof}
	We claim that
	\[I:=\left(x^n,x^{n-1}y,\ldots,xy^{n-1},y^n\right)\subseteq k[x,y]\]
	is not generated by $n$ elements.
	
	This is surprisingly annoying because one could imagine that some kind of massive cancellation among specially chosen polynomials might be able to do this. Anyways, we modify the proof from \href{https://math.stackexchange.com/a/1622173/869257}{here}. The trick is to move everything into a vector space, where we have better control. Set $\mf m:=(x,y),$ which consists of all polynomials with vanishing constant term. As such, we see that
	\[\frac{k[x,y]}{\mf m}\cong k\]
	by sending $x\mapsto0$ and $y\mapsto0$; indeed, the morphism $k[x,y]\to k$ is simply evaluating at $(0,0),$ giving out the constant term, so the kernel consists of $\mf m.$ The point is that $\mf m$ is a maximal ideal because it its quotient gives a field.

	Thus, we can assign $I/\mf mI$ a $k[x,y]$-action as the quotient module, but this action vanishes on $\mf m$ by definition on $\mf mI,$ so in fact we have an action by $k[x,y]/\mf m\cong k,$ so $I/\mf mI$ is a $k$-vector space. The key claim is that
	\[\dim_kI/\mf mI\stackrel?=n+1.\]
	Indeed, we see that the residue classes of $x^ky^{n-k}$ certainly span $I$ and hence span $I/\mf mI,$ so $\dim_kI/\mf I\le n+1.$ To finish, we claim that the residue classes for $x^ky^{n-k}$ are in fact $k$-linearly independent. Well, suppose we have $\{a_k\}_{k=0}^n$ such that
	\[f:=\sum_{k=0}^na_kx^ky^{n-k}\in\mf mI.\]
	If $f$ is nonzero, then it has degree $n$ because each monomial has degree $n.$ However, each nonzero element of $\mf mI$ has degree at least $n+1$ because nonzero elements of $I$ have degree at least $n,$ and nonzero elements of $\mf m$ have degree at least $1.$ So $f\ne0$ would imply that $\deg f=n$ and at least $n+1,$ which makes no sense.

	So we have that $f=0$ (as a polynomial in $k[x,y]$) so it follows that the $a_\bullet=0$ identically, giving us our linear independence. Thus, the residue classes for $x^ky^{n-k}$ form a basis, so we see that
	\[\dim_kI/\mf mI=n+1.\]
	To convert the result, we note that if $I$ were generated by $m$ elements, then we can take the residue classes of these elements in $I/\mf mI$ to span $I/\mf mI$ with $m$ elements. But using the dimension here, we see that $m\ge n+1,$ so $I$ cannot be generated by fewer than $n+1$ elements.
\end{proof}
The point is that there is no absolute finite bound on ideals for $k[x,y],$ though there is the following result.
\begin{theorem}[Hilbert basis]
	Every ideal in some polynomial ring $k[x_1,\ldots,x_n]$ is finitely generated.
\end{theorem}
\begin{remark}
	Hilbert's proof of this theorem was somewhat complicated. Noether went back and provided a simpler proof.
\end{remark}
The above sorts of rings have a name.
\begin{definition}[Noetherian]
	We say that a ring $R$ is \textit{Noetherian} if and only if all ideals are finitely generated.
\end{definition}
This turns out to be a really nice and reasonable smallness property for $R.$ In practice, most rings in number theory or algebraic geometry are Noetherian, so it's good enough for our purposes.
\begin{nex}
	The ring $k[x_1,x_2,\ldots]$ with infinitely many transcendental elements, then the ideal
	\[I=(x_1,x_2,\ldots)\]
	is not finitely generated. Indeed, any finite set of polynomials $\{f_k\}_{k=1}^n$ must have each $f_\bullet$ have only finitely many monomials and hence only use finally many $x_\bullet.$ So any linear combination of the $\{f_k\}_{k=1}^n$ will only use finitely many of the $x_\bullet$ and hence cannot fully cover $I.$
\end{nex}
As a warning, we note that being finitely generated as an ideal and finitely generated as an algebra without identity are different.
\begin{ex}
	In $k[x,y],$ we consider the following objects generated by $y.$ 
	\begin{itemize}
		\item The ideal generated by $y$ includes all polynomials which are a multiple of $y.$ To generate this as a $k$-algebra without identity, we would need all elements of the form $x^ky$ for $k\ge0.$ To generate this as a $k$-vector space, we would need all elements of the form $x^ky^\ell$ for $k\ge0$ and $\ell\ge1.$
		\item The $k$-algebra generated by $y$ includes $k[y],$ notably including $1$ even though the ideal does not. To generate $k[y]$ as a $k$-vector space, we need all powers $y^\bullet.$
		\item The $k$-vector space generated by $y$ includes elements of the form $cy$ for $c\in k.$
	\end{itemize}
\end{ex}

\subsection{Noetherian Grab-Bag}
Noether's version of the Hilbert basis theorem is as follows.
\begin{restatable}[Hibert basis, II]{thm}{hilbert} \label{thm:hilbasis}
	If $R$ is Noetherian, then $R[x]$ is also Noetherian.
\end{restatable}
\begin{ex}
	The ring $\ZZ[x]$ is Noetherian because $\ZZ$ is Noetherian. In particular, $\ZZ$ is Noetherian because it is a principal ideal domain, so all ideals are generated by a single element.
\end{ex}
We note that, inductively, we also have the following.
\begin{cor}
	Fix $k$ a field. Then $k[x_1,\ldots,x_n]$ is Noetherian.
\end{cor}
\begin{proof}
	Induct on $n$ using \autoref{thm:hilbasis}. For $n=0,$ we see that $k$ only has two ideals, $(0)$ and $(1).$ For the inductive step, we have that $k[x_1,\ldots,x_n]$ is Noetherian and note that
	\[k[x_1,\ldots,x_n][x_{n+1}]\]
	is Noetherian by \autoref{thm:hilbasis}. This is what we wanted.
\end{proof}

Here are some equivalent conditions for a ring being Noetherian; there are a few important ones to keep track of.
\begin{proposition}
	The following are equivalent.
	\begin{enumerate}[label=(\alph*)]
		\item $R$ is Noetherian.
		\item Every ideal of $R$ is finitely generated.
		\item Every nonempty set of ideals has a maximal ideal.
		\item Any increasing chain of ideals notated
		\[I_1\subseteq I_2\subseteq\cdots\]
		of $R$ must stabilize.
	\end{enumerate}
\end{proposition}
We remark that ``not (d)'' provides a increasing chain of ideals
\[I_1\subseteq I_2\subseteq\cdots\]
which does not stabilize. But this may be turned into an infinite strictly ascending chain of ideals: set $n_1:=1,$ and for each $n_k,$ the lack of stabilization implies there is $n_{k+1}>n_k$ such that $I_{n_k}\subsetneq I_{n_{k+1}},$ so we have the infinite strictly ascending chain
\[I_1\subsetneq I_2\subsetneq\cdots.\]
And of course, we conversely have that an infinite strictly ascending chain violates (d) immediately.
\begin{proof}
	We have the following implications.
	\begin{itemize}
		\item To start, we note that (a) and (b) are equivalent by definition of Noetherian.
		\item The fact that (c) and (d) are equivalent holds because the set of ideals of a ring is partially ordered set.
		\begin{itemize}
			\item We show not (d) implies not (c). If we have an infinite, non-stabilizing chain of ideals
			\[I_1\subsetneq I_2\subsetneq I_3\subsetneq\cdots,\]
			then we note that this chain is a nonempty set of ideals with no maximal ideal. Indeed, each $I_N$ is not maximal because $I_N\subsetneq I_{N+1}.$
			\item We show not (c) implies not (d). Suppose $S$ is a nonempty set of ideals with no maximal ideals. We start with $I_1\in S,$ which exists because $S$ is nonempty.
			
			Now, we recursively note that for each $k\in\ZZ^+,$ we note that $I_k$ is not maximal in $S,$ so there is an ideal $I_{k+1}\in S$ such that $I_K\subsetneq I_{k+1}.$ So we get a strictly increasing chain
			\[I_1\subsetneq I_2\subsetneq I_3\subsetneq\cdots,\]
			successfully violating (d). Technically this argument uses some Axiom of choice to construct all of these ideals at once.\footnote{There are actually reasons to care about this use of choice: in algebraic geometry, there are structures called topoi we might want to work in, which don't have an Axiom of choice.}
		\end{itemize}
		\item We next show that (b) implies (d). Well, given an a chain of ideals
		\[I_1\subseteq I_2\subseteq I_3\subseteq\cdots,\]
		and because this is a chain, we see that
		\[I:=\bigcup_{k\in\ZZ^+}I_k\]
		is itself an ideal, which we can check by hand: we see $I$ contains $0\in I_1$ and so is nonempty; then for any $a,b\in I$ and $r,s\in R,$ there is $N$ such that $a,b\in I_N$ because our ideals are in a chain, so $ra+sb\in I_N\subseteq I.$ Thus, $I$ is an $R$-submodule of $R$ and hence an ideal.
		
		Now, $I$ is finitely generated because $R$ is Noetherian (!), so set
		\[I:=(a_1,\ldots,a_n).\]
		Each $a_k$ lives in some $I_{n_k},$ so setting $N:=\max_k\{n_k\},$ we see that $a_k\in I_{n_k}\subseteq I_N$ for each $k.$ Thus, for each $n>N,$ we have
		\[I_n\subseteq\bigcup_{k\in\ZZ^+}I_k=I=(a_1,\ldots,a_n)\subseteq I_N\subseteq I_n,\]
		so $I_n=I_N$ follows. Thus, our chain does stabilize.
		\item We now show that not (d) implies not (b). Indeed, suppose that $I$ is not finitely generated, and we construct an infinite strictly ascending chain of ideals.
		
		Start with $a_1:=0\in I.$ Now, we recursively note that any finite set $\{a_k\}_{k=1}^n\subseteq I$ cannot generate $I,$ so we can always for $n\in\ZZ^+$ find some
		\[a_{n+1}\in I\setminus(a_1,\ldots,a_n).\]
		Continuing in this manner, we get a strictly ascending chain
		\[(a_1)\subsetneq(a_1,a_2)\subsetneq(a_1,a_2,a_3)\subsetneq\cdots,\]
		which contradicts (d). Indeed, this chain is strictly ascending because, for each $n\in\ZZ^+,$ we see that $a_{n+1}\notin(a_1,\ldots,a_n)$ implies that $(a_1,\ldots,a_n)\subsetneq(a_1,\ldots,a_{n+1}).$
		\qedhere
	\end{itemize}
\end{proof}
Let's see an example.
\begin{ex}
	Fix $R=k[x_1,x_2,\ldots]$ to have infinitely many variables. Then
	\[(x_1,x_2,\ldots)\]
	is not finitely generated as discussed earlier. From the above work, we see that this gives rise to the infinite strictly ascending chain
	\[(x_1)\subsetneq(x_1,x_2)\subsetneq(x_1,x_2,x_3)\subsetneq\cdots.\]
	And of course, there is no maximal element among the above chain using the logic described above.
\end{ex}

\subsection{Artinian Rings}
As an aside, we note that we can flip around the condition for Noetherian and ask for decreasing chains to stabilize.
\begin{definition}[Artinian]
	A ring $R$ is called \textit{Artinian} if and only if all descending chains of ideals stabilize.
\end{definition}
\begin{example}
	Fields are Artinian because they only have two ideals.
\end{example}
This is a very strong condition; some of our favorite rings are not Artinian.
\begin{nex}
	The integers $\ZZ$ has the infinite strictly decreasing chain
	\[(2)\supsetneq(4)\supsetneq(8)\supsetneq\cdots.\]
\end{nex}
\begin{remark}
	The Artinian condition is so strong that it implies the Noetherian condition.
\end{remark}
We won't be talking about Artinian rings any more for now, but it might come up in commutative algebra.

\subsection{Hilbert Basis Theorem}
Let's jump into the Hilbert basis theorem. Recall Noether's statement.
\hilbert*
\begin{proof}
	Given an ideal $I\subseteq R[x],$ our goal is to find a finite set of generators. Well, we set
	\[I_0:=\{0\}\cup\{\text{leading coefficient of }f:f\in R[x]\text{ and }\deg f=0\}.\]
	This is simply $I\cap R[x]$ and might appear silly, but more generally, we define
	\[I_k:=\{0\}\cup\{\text{leading coefficient of }f:f\in R[x]\text{ and }\deg f=k\}.\]
	We have the following two observations.
	\begin{itemize}
		\item The $I_k$ are ideals for each $k\in\ZZ^+.$ By construction, they contain $0.$ Then if we have $a,b\in I_k$ and $r,s\in R,$ then we need $ar+bs\in I_k.$ If $ar+bs=0,$ then we are done. Otherwise, we can find polynomials $f$ and $g$ of degree $k$ with leading coefficients $a$ and $b$ respectively. Then the polynomial
		\[af+bg\]
		has leading term $\left(ar+bs\right)x^k,$ so indeed, $ar+bs\in I_k.$
		\item We have that $I_k\subseteq I_{k+1}$ for each $k\in\ZZ^+.$ Indeed, $0\in I_{k+1},$ and for $r\in I_k\setminus\{0\},$ we can find $f(x)$ of degree $k$ with leading coefficient $r.$ Then $x\cdot f(x)$ has degree $k+1$ with leading coefficient $r,$ so $r\in I_{k+1}.$
	\end{itemize}
	Thus, we have an ascending chain of ideals
	\[I_0\subseteq I_1\subseteq I_3\subseteq\cdots,\]
	and we note that $R$ Noetherian implies that this sequence must stabilize to some $I_N.$

	This use of the chain condition more or less tells us that we only care about $\{I_k\}_{k=1}^N.$ Each $I_k$ is finitely generated, so we fix
	\[I_k=(r_{k,1},r_{k,2},\ldots,r_{k,n_k}),\]
	and then, for each $\ell,$ we find polynomials $f_{k,\ell}$ with leading coefficient $r_{k,\ell}$ of degree $k.$ (If $r_{k,\bullet}=0,$ just take $f_{k,\bullet}=0,$ though this doesn't matter.) Now we claim that $I$ is generated by
	\[S:=\bigcup_{k=0}^N\left\{f_{k,1},f_{k,2},\ldots,f_{n_k}\right\}\subseteq I,\]
	which will be good enough because $S$ is finite.

	Essentially, $S$ generates $I$ by induction. Fix $p\in I.$ If $p=0,$ then of course $p\in(S).$ Otherwise, we induct on $\deg p$; if $\deg p=0,$ then $p\in I_0,$ so we can write $p$ as an $R$-linear combination of the $f_{0,\bullet},$ finishing. Otherwise, $\deg p>0,$ and we have two cases.
	\begin{itemize}
		\item If $d:=\deg p\le N,$ then name the leading coefficient $r\in I_d.$ In particular, we have some $R$-linear combination
		\[r=\sum_{\ell=1}^{n_d}a_\ell r_{k,\ell},\]
		so
		\[f:=\sum_{\ell=1}^{n_d}a_\ell f_{k,\ell}\in(S)\]
		will have leading term $rx^d,$ matching $p.$ Thus, $p-f$ will thus have smaller degree by cancelling out the leading term, so $p-f\in(S)$ by induction, so $p\in(S).$
		\item If $d:=\deg p>N,$ then again name the leading coefficient $r\in I_d.$ But by the stabilization, we see that $r\in I_N,$ so we have an $R$-linear combination
		\[r=\sum_{\ell=1}^{n_N}a_\ell r_{N,\ell}.\]
		But now
		\[f:=\sum_{\ell=1}^{n_d}a_\ell f_{k,\ell}x^{d-N}\]
		will have leading term $rx^d,$ matching $p.$ So again, $p-f$ has smaller degree by cancelling the leading term, implying that $p-f\in (S)$ and hence $p\in(S).$
		\qedhere
	\end{itemize}
\end{proof}
\begin{remark}[Nir]
	The end of this proof is essentially doing Euclidean division with many polynomials.
\end{remark}

\subsection{Analytic Examples}
Let's see some more examples.
\begin{ex}
	We have the following list.
	\begin{itemize}
		\item The ring $\CC[x]$ of polynomials is Noetherian.
		\item The ring of holomorphic functions on $\CC$ is {\color{red}not} Noetherian.
		\item The ring of functions which are holomorphic on the closed unit disk is Noetherian.
		\item The ring of functions which are holomorphic on the open unit disk is {\color{red}not} Noetherian.
		\item The ring of functions which are holomorphic in some neighborhood are $0$ is Noetherian.
		\item The ring of functions smooth at $0$ is {\color{red}not} Noetherian.
		\item The ring of formal power series at $0$ is Noetherian.
	\end{itemize}
	All but the last item are contained in the previous, but smooth functions at $0$ are not all represented by formal power series.
\end{ex}
All of the rings in the above are quite similar, but being Noetherian is switching on and off. Let's do some of the explanations.
\begin{itemize}
	\item The ring $\CC[x]$ is Noetherian because it is principal.
	\item Similarly, $\CC[[x]]$ is Euclidean and hence principal and hence Noetherian. The trick is to reverse our definition of degree. Namely, given a nonzero power series
	\[a(x):=\sum_{k=0}^\infty a_kx^k\in\CC[[x]],\]
	we define $|a|$ to be the least $k$ such that $a_k\ne0,$ which exists because $a\ne0.$ Then to divide some power series $a(x)=\sum_{k=0}^\infty a_kx^k$ by a nonzero power series $b(x)=\sum_{k=0}^\infty b_kx^k,$ we note that $|a|\ge|b|$ implies we can write
	\[r:=a-\frac{a_{|a|}}{b_{|b|}}x^{|a|-|b|}\cdot b.\]
	Here, $r$ has the $a_{|a|}x^{|a|}$ term vanish while adding no lower-degree terms, so $r=0$ or $|r|<|a|.$ In this way, we can inductively push the degree downwards until $r=0$ or $|r|<|b|,$ which is what we need for Euclidean division.
\end{itemize}
\begin{remark}
	The ring $\CC[[x]]$ is an example of a ``local'' ring.
\end{remark}
\begin{itemize}
	\item Holomorphic functions on $\CC$ is not Noetherian. For example, define
	\[I_n:=\{f\text{ holomorphic}:f(k)=0\text{ for each positive integer }k\ge n\}\]
	for each $n\in\NN.$ Then we can check that we have an ascending chain
	\[I_0\subseteq I_1\subseteq I_2\subseteq\cdots.\]
	One way to see that this containment is strict is to note that, for each $n\in\NN,$
	\[f_n(z):=\frac{\sin\pi z}{\prod_{k<n}(z-k)}\]
	vanishes at positive integers at least $n$ but returns $1$ for positive integers less than $n.$ Thus, $f_n\in I_n\setminus I_{n-1}.$
	
	More generally, we can replace $\NN$ with any set of complex numbers with no limit point, though we have to do some complex analysis to see this.
	\item Holomorphic functions on the closed unit disk are Noetherian because it is a principal ideal domain. Indeed, the main point is that a holomorphic function on the closed unit disk must only have finitely many roots. Given an ideal $I,$ we can define
	\[S:=\{z\in\CC:f(z)=0\text{ for each }f\in I\},\]
	where zeroes of higher order are counted with multiplicity in $S.$ Then we set
	\[f_S(z):=\prod_{a\in S}(z-a)\]
	again counting with multiplicity. Then $J:=\frac1{f_S}I$ is still an ideal, and it has no points upon which all functions in $J$ vanish; it follows by waving our hands a bit\footnote{I suspect this claim follows from some random complex analytic result, but I do not know what it is.} we can construct a function in $J$ with no roots, so $J=(1),$ so $I=(f_S).$
	\item Holomorphic functions on the open unit disk is not Noetherian for the same reason that holomorphic functions on $\CC$ is not Noetherian. Namely, we have the infinite isolated sequence
	\[a_n:=1-\frac1n\]
	for $n>0$ in the open disk, which can be used to construct the strictly ascending chain
	\[I_n:=\{f\text{ holomorphic}:f(a_k)=0\text{ for each positive integer }k\ge n\}\]
	for each $n>0.$
	\item Holomorphic functions at $0$ can be identified with formal power series
	\[f(z)=\sum_{k=0}^\infty a_kz^k\]
	such that $\limsup_{n\to\infty}\sqrt[n]{|a_n|}<\infty.$ We can show that these functions are closed under addition and multiplication, so they inherit the division algorithm of $\CC[[x]].$
	\item Smooth functions at $0$ is quite odd. For example, we can we can set $I$ equal to the functions vanishing with infinite order at $0.$ Namely, the function $e^{-1/x^2}$ vanishes with infinite order at $0$ along $\RR.$

	There are other ways to see that this ring is not Noetherian. For example, Noetherian rings have that all elements are the product of irreducibles, which we showed for principal ideal domains, whose proof carries over nicely here. But $f:=e^{-1/x^2}$ has
	\[f=\left(\sqrt f\right)^2=\left(\sqrt[4]f\right)^4=\cdots,\]
	so $f$ is not the product of irreducibles.
\end{itemize}
So being Noetherian can be a kind of fuzzy condition to work with.

\subsection{Noetherian Philosophy}
Let's have some informal ways of thinking about the Noetherian condition before we continue.
\begin{itemize}
	\item Rings of finite-dimensional algebraic objects tend to be Noetherian. For example, polynomials over a finite number of variables are more or less actions on a finite-dimensional subspace. However, infinitely many variables would act on infinite-dimensional space.
	\item Rings in analysis tend to be non-Noetherian. This is sad for analysts.
	\item Noetherian rings are more or less associated with zeroes of functions being nice. For example, on the closed unit disk, holomorphic functions have a finite number of zeroes. But this is not the case for all of $\CC$ or for the open disk.
\end{itemize}

\subsection{Hilbert's Finiteness Theorem: Set-Up}
We will spend the rest of lecture discussing an application of Noetherian rings.

Here is the set-up: suppose tha a group $G$ acts on a finite-dimensional $k$-vector space $V.$ One way to study $V$ would be to look at the ring of polynomial functions out of $V.$ Fixing a basis $\{v_1,\ldots,v_n\},$ this ring is
\[k[V]:=k[v_1^*,\ldots,v_n^*],\]
where $v_\bullet^*:V\to k$ is the coordinate function for $v_\bullet.$\footnote{Sure, there are other functions $V\to\CC,$ but from an algebraic perspective, these polynomial ones are more or less the only ones we can guarantee to exist when working in full generality.}

We are interested in studying the $G$-invariants of $V,$ and we can do this by studying $G$-invariants of $k[V].$ Namely,  Now, the $G$-action on $V$ induces an action on $k[V]$ by
\[(\sigma\cdot f)(v):=f(\sigma^{-1}v),\]
where $\sigma\in G$ and $f\in k[V]$ and $v\in V.$ Here, we are inverting in order to make the associative law for the group action actually behave. So we find that the $G$-invariants of $k[V]$ are
\[k[V]^G:=\{f\in k[V]:\sigma\cdot f=f\text{ for each }\sigma\in G\}.\]
So what we can say about $k[V]^G$? It's not too hard to see that our $G$-action preserves addition and multiplication in $k[V],$ so we have that $k[V]^G$ is a subring of $k[V].$ Further, the $G$-action preserves scalar multiplication by $k,$ so the most structure we can give to $k[V]^G$ is in fact as a full $k$-algebra!

Well, what does $k[V]^G$ look like as a $k$-algebra? For example, is it finitely generated? This turns out to be a difficult question; we will show that the answer is yes for $G$ a finite group and $k=\CC,$ though the answer is yes in more general contexts.
\begin{remark}
	Hilbert invented the notion of Noetherian in order to talk about the above result.
\end{remark}
\begin{exercise}
	Fix $G=S_n$ acting on $V=\CC^n$ by permuting the coordinates. Then $\CC[V]^G$ is finitely generated as a $\CC$-algebra.
\end{exercise}
\begin{proof}
	Our coordinate ring is
	\[\CC[V]=\CC[x_1,\ldots,x_n],\]
	where $x_k:V\to\CC$ projects onto the $k$th coordinate. Then we can see that $(\sigma\cdot x_k)(v)=x_k(\sigma^{-1}v)=x_{\sigma k}$ because the $\sigma(k)$th coordinate gets moved to the $k$th coordinate. Because we are working in a polynomial ring, this extends uniquely to a full $G$-action on $\CC[V].$
	
	Namely, $G$ acts on $\CC[V],$ by permuting coordinates, so $\CC[V]^G$ consists of the symmetric polynomials. For example, the polynomials
	\[e_1:=x_1+x_2+\cdots+x_n,\qquad e_2:=\sum_{k<\ell}x_kx_\ell,\ldots\qquad e_m:=\sum_{k_1<k_2<\ldots<k_m}x_{k_1}x_{k_2}\cdots x_{k_m}\]
	are the ``elementary'' symmetric polynomials. It turns out that all symmetric polynomials are a polynomial of the $e_\bullet,$ so
	\[\CC[V]^G=\CC[e_1,\ldots,e_n]\]
	is indeed finitely generated as a $\CC$-algebra. For example, we can write
	\[x_1^2+\cdots+x_n^2=(x_1+\cdots+x_n)^2-2\sum_{k<\ell}x_kx_\ell=e_1^2-2e_2.\]
	Some kind of process like this works for all symmetric polynomials.
\end{proof}
\begin{exercise}
	Fix $G=\langle\sigma\rangle\cong\ZZ/4\ZZ$ acting on $V=\CC^2$ by $\sigma v:=i^{-1}v.$ Then $\CC[V]^G$ is finitely generated as a $\CC$-algebra.
\end{exercise}
\begin{proof}
	Our coordinate ring is $\CC[x,y],$ where $x$ projects onto the first coordinate and $y$ onto the second. Further, we can check that our action is by
	\[(\sigma\cdot x)(v)=x(\sigma^{-1}v)=x(iv)=(ix)(v),\]
	so $\sigma\cdot x=ix.$ Similarly, $\sigma\cdot y=iy,$ and this extends uniquely to a full $G$-action on $\CC[V]$ because $\CC[V]$ is a polynomial ring.
	
	Looking at more general monomials, we see that
	\[\sigma\left(x^ky^\ell\right)=i^{k+\ell}x^ky^\ell,\]
	so the fixed monomials are the ones with $i^{k+\ell}=1,$ which is equivalent to having degree divisible by $4.$ Now, if a polynomial
	\[f(x,y):=\sum_{k,\ell\in\NN}a_{k,\ell}x^ky^\ell\]
	is fixed by the $G$-action, then we see that
	\[(\sigma\cdot f)(x,y)=\sum_{k,\ell\in\NN}i^{k+\ell}a_{k,\ell}x^ky^\ell.\]
	In particular, $G$ preserves the monomials themselves, so we need $i^{k+\ell}=1$ for each $a_{k,\ell}=0.$ Thus, we have that $\CC[V]^G$ consists of the polynomials all of whose monomials have degree divisible by $4.$ In other words,
	\[\CC[V]^G=\CC\left[\left\{x^ky^\ell:k+\ell\equiv0\pmod4\right\}\right].\]
	For example, this is infinite-dimensional as a $\CC$-vector space, spanned by the $x^ky^\ell$ with $k+\ell\equiv0\pmod4.$
	
	However, for each $x^ky^\ell$ with $k+\ell\equiv0\pmod4,$ we can write $k\equiv k'\pmod4$ and $\ell\equiv\ell'\pmod4$ with $0\le k',\ell'<4,$ so $0\le k'+\ell'<8.$ The point is that we can write
	\[x^ky^\ell=\left(x^4\right)^{(k-k')/4}x^{k'}\cdot\left(y^4\right)^{(\ell-\ell')}y^{\ell'}.\]
	But now because $k'+\ell'<8$ while $k'+\ell'\equiv0\pmod4,$ we see that $x^{k'}y^{\ell'}\in\left\{x^0y^0,x^1y^3,x^2y^2,x^3y^1\right\}.$ It follows that we can fit all monomials of $\CC[V]^G$ into
	\[\CC\left[y^4,xy^3,x^2y^2,x^3y,x^4\right],\]
	where we have thrown out $x^0y^0=1$ and added the needed $x^4$ and $y^4.$ It follows that we can write $\CC[V]^G=\CC\left[x^4,x^3y,x^2y^2,xy^3,y^4\right],$ so $\CC[V]^G$ is indeed finitely generated as a $\CC$-algebra.
\end{proof}
In general, rings of invariants are quite complicated, and even if finitely generated, they might require lots of generators.
\begin{ex}
	Let $G=\op{SL}_2(\CC)$ act on the binary quantics, which are polynomials of the form
	\[\sum_{k=0}^na_kx^ky^{n-k}.\]
	Namely, these are all two-variable polynomials which are homogeneous of degree $n,$ and the $G$-action is by multiplication multiplication like
	\[\begin{bmatrix}
		a & b \\
		c & d
	\end{bmatrix}\begin{bmatrix}
		x \\ y
	\end{bmatrix}=\begin{bmatrix}
		ax+by \\
		cx+dy
	\end{bmatrix}.\]
	It turns out that the ring of $G$-invariants are finitely generated, which is due to Gordon.
\end{ex}

\subsection{Hilbert's Finiteness Theorem: Proof}
Proving that these invariants are finitely generated was an incredibly hard problem, but Hilbert presented a disturbingly simple proof of it.
\begin{theorem}[Hilbert's finiteness]
	Fix $G$ a finite group and $V$ a finite-dimensional $\CC$-vector space with a (linear) $G$-action. Then $\CC[V]^G$ is finitely generated as a $\CC$-algebra.
\end{theorem}
\begin{proof}
	The key trick is that, when $G$ is a finite group, we have a ``Reynolds'' operator, which is essentially a ``$G$-average.'' Namely, for some function $f\in\CC[V],$ we define
	\[\rho(f):=\frac1{\#G}\sum_{\sigma\in G}\sigma(f)\in\CC[V].\]
	The division by $\#G$ is legal in $\CC$ but not in all fields because we might end up dividing by the characteristic.
	\begin{remark}
		This is the same Reynolds who did fluid dynamics, who used the Reynolds operator to average fluid flow over time operators.
	\end{remark}
	Now, starting with $\CC[V],$ let $I=\CC[V]^G$ be the ring of invariants, which we grade by degree. Explicitly, we have
	\[I=I_0\oplus I_1\oplus I_2\oplus I_3\oplus\cdots,\]
	where $I_k$ has terms of degree $k.$ (Indeed, any polynomial in $\CC[V]$ can be uniquely decomposed into polynomials of various fixed degrees.) Then we set
	\[J:=(I_1,I_2,\ldots)\subseteq\CC[V]\]
	to be the ideal generated by the homogeneous polynomials in $I$ of positive degree, where we exclude constants to avoid the full ring.

	But $\CC[V]$ is simply a polynomial ring and hence Noetherian! So $J$ is generated by some finite number of elements (as an ideal) in $\CC[V].$ Further, each of these finitely many generating elements can be written as some finite $\CC[V]$-linear combination of nonconstant homogeneous polynomials in $I$ (by construction of $J$), so in fact we may write
	\[J=(j_1,\ldots,j_m),\]
	where the $j_\bullet$ are nonconstant homogeneous $G$-invariant polynomials. We would like to show that these $j_\bullet$ generate $I$ as a $\CC$-algebra; in other words, we claim that
	\[I\stackrel?=\CC[j_1,\ldots,j_m],\]
	which will indeed finitely generate $I$ as a $\CC$-algebra.
	\begin{remark}
		Generating as an ideal and generating as an algebra are again, quite different, and this is where the main difficulty is in the proof. For instance, the ideal $(y)\subseteq\CC[x,y]$ is not finitely generated as a $\CC$-algebra.
		% For instance, our example from earlier had $J$ generated by $(y),$ but the full ideal $I$ was not generated by $J.$
	\end{remark}
	So we need to use some property that $I$ is a ring of invariants, and as promised, we will use the Reynolds operator. Due to the grading, it suffices to show that $I_n\subseteq\CC[j_1,\ldots,j_m]$ for each $n\in\NN.$ We show this by induction; note that $I_0$ consists of constants in $\CC,$ which are in $\CC[j_1,\ldots,j_m]$ automatically.
	
	Otherwise, pick some $b\in I_n$ with $n>0,$ and we need to show $b\in\CC[j_1,\ldots,j_m].$ Because $b\in J,$ and $J=(j_1,\ldots,j_m),$ we may write
	\[b=\sum_{k=1}^mc_kj_k.\]
	Without loss of generality, we may take $\deg c_\bullet=\deg b-\deg j_\bullet$ because any terms of $c_\bullet$ which are not of this degree will have to cancel out somewhere else because $b$ and $j_\bullet$ are homogeneous. We repeat again that the issue here is that the $c_\bullet$ live in $\CC[V],$ not in $\CC[V]^G$ the ring of invariants.

	But the key trick is to apply the Reynolds operator! The Reynolds operator has the following magical properties.
	\begin{itemize}
		\item If $f\in\CC[V]^G$ and $g\in\CC[V],$ then $\rho(fg)=f\rho(g).$ Indeed,
		\[\rho(fg)=\frac1{\#G}\sum_{\sigma\in G}\sigma(fg)=\frac1{\#G}\sum_{\sigma\in G}\sigma(f)\sigma(g)=f\cdot\frac1{\#G}\sum_{\sigma\in G}\sigma(f)=f\rho(g).\]
		\item In particular, if $f\in\CC[V]^G,$ then $\rho(f)=\rho(f\cdot1)=f\rho(1)=f.$
		\item If $f\in\CC[V],$ then $\rho(f)\in\CC[V]^G.$ Indeed, for any $\tau\in G,$ we have that
		\[\tau\cdot\rho(f)=\tau\cdot\frac1{\#G}\sum_{\sigma\in G}\sigma(f)=\frac1{\#G}\sum_{\tau\sigma\in G}(\tau\sigma)(f)=\rho(f).\]
	\end{itemize}
	Thus, we can write
	\[b=\rho(b)=\sum_{k=1}^mj_k\rho(c_k),\]
	which essentially finishes immediately. Indeed, the $\rho(c_\bullet)$ are elements of $I$ of degree smaller than $\deg b,$ so they live in $\CC[j_1,\ldots,j_m],$ so we finish by induction.
\end{proof}
\begin{remark}
	This proof is quite amazing. It is little more than applying the Reynolds operator, wiping out hundreds of pages unreadable invariant theory because explicitly writing out the invariants can be truly terrible.
\end{remark}
We close with some more remarks.
\begin{remark}
	Hilbert's proof is not constructive: we don't have an algorithm to actually find the generators from an ideal in the above proof. He would later provide a more explicit construction, which comes from making the Hilbert basis theorem more constructive.
\end{remark}
\begin{remark}
	We don't need the full force of $G$ finite. For example, $G$ compact lets us integrate for our Reynolds operator using a Haar measure, which is safe. We can also do $G=\op{SL}_2(\CC)$ by the ``unitarian trick,'' where we observe that $\op{SL}_2(\CC)$ (which is not compact) contains the compact group $\op{SU}_2(\CC),$ and then it turns out that the $\op{SL}_2(\CC)$-invariants are the same as the $\op{SU}_2(\CC)$-invariants.
\end{remark}
\begin{remark}
	Nagata found a group $G$ where the invariants are not finitely generated, so this statement is not true for all groups $G.$ (This provided a negative answer to Hilbert's 14th problem.) So we do need some smallness condition on $G$; the correct property for the above proof turns out to be ``linearly reductive.''
\end{remark}
\begin{remark}
	The fact we are working over $\CC$ is also unnecessary as shown by Haboush, though it makes the proof more difficult.
\end{remark}

\end{document}