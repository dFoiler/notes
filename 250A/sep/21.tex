% !TEX root = ../notes.tex














All around me darkness gathers.

\subsection{Rings}
Today we do rings. We have the definition.
\begin{definition}[Ring]
	A \textit{ring} is a set $R$ with two operations $+$ and $\times$ such that $(R,+)$ is a group, $\times$ associates, and we distribute by
	\[a(b+c)=ab+ac\qquad\text{and}(a+b)c=ac+bc.\]
\end{definition}
We have some extra axioms as well.
\begin{definition}[Commutative ring]
	A \textit{commutative ring} is one where multiplication commutes.
\end{definition}
\begin{definition}[Ring with unity]
	A \textit{ring with unity} is one with a multiplicative identity. We might call the multiplicative identity just ``unity'' or ``identity.''
\end{definition}
The above two definitions are generally assumed but not by all authors.
\begin{warn}
	In this course, our rings will generally be commutative with identity.
\end{warn}
Anyways, have some examples.
\begin{example}
	We have that $\ZZ$ is a ring.
\end{example}
\begin{example}
	Any field is a ring.
\end{example}
\begin{example}
	For $R$ a commutative ring, the polynomials $R[x]$ form a commutative ring. If $R$ has a multiplicative identity, then $R[x]$ has the same multiplicative identity.
\end{example}
\begin{example}
	Given a ring $R,$ the $n\times n$ matrices $R^{n\times n}$ form a ring. If $R$ has multiplicative identity, then $R^{n\times n}$ has the identity matrix. However, if $R$ is commutative, it is not necessary for $R^{n\times n}$ to be commutative.
\end{example}
\begin{example}
	The Gaussian integers $\ZZ[i]:\{a+bi:a,b\in\ZZ\}$ make a ring.
\end{example}
Most of these rings are commutative with identity. Let's do some examples not containing $1.$
\begin{example}
	The set $C_0(\RR)$ consisting of all continuous real functions with compact support, where addition and multiplication are pointwise. However, our multiplicative identity in $\{f:\RR\to\RR\}$ is the $x\mapsto1$ function, which does not have compact support.
\end{example}
In general, analysis has lots of natural examples like this.
\begin{example}
	We can also define multiplication on $C_0(\RR)$ by
	\[(f*g)(x):=\int_\RR f(y)g(x-y)\,dy\]
	and makes a perfectly fine commutative ring, but there is no identity; note that this integral is surely well-defined because $f$ and $g$ have compact support. (The identity should be $1_{x=0},$ which is not continuous.)
	
	The checks here are not very interesting; for example, distributivity comes down to noting
	\[(f*(g+h))(x)=\int_\RR f(y)(g+h)(x-y)\,dy=\int_\RR f(y)g(x-y)\,dy+\int_\RR f(y)h(x-y)\,dy\]
	is $(f*g)(x)+(f*h)(x).$
\end{example}

\subsection{Modules}
We can also define modules.
\begin{definition}[Module]
	A (left) \textit{module} $M$ over a ring $R$ has exactly the same axioms as a vector space over a field.
	\begin{itemize}
		\item $(M,+)$ is an abelian group.
		\item $M$ has a left $R$-action $\cdot:(R,M)\to M,$ satisfying $(rs)\cdot m=r\cdot(s\cdot m)$ and the various distributive laws
		\[r\cdot(m+n)=r\cdot m+r\cdot n\qquad\text{and}\qquad(r+s)\cdot m=r\cdot m+s\cdot m\]
		for $r,s\in R$ and $m,n\in M.$ In other words, there is a ring map $R\to\op{End}(M).$
	\end{itemize}
\end{definition}
We remark that sometimes we require $1_Rm=m$ when $R$ has an identity element, which we will also usually require.
\begin{example}
	Vector spaces over a field are modules over that field.
\end{example}
\begin{example}
	Abelian groups are $\ZZ$-modules, where the $\ZZ$-action is exponentiation.
\end{example}

\subsection{Analogies}
There is some correspondence between our algebraic structures, which for now are groups and rings.
\begin{itemize}
	\item Groups act on sets in the same way that rings act on modules. There are even left and right actions in the same way that rings have left and right modules.
	\item There is the symmetric group $S_n,$ which consist of all permutations of $\{1,\ldots,n\}.$ In rings, this is the matrix ring $R^{n\times n},$ which are all linear transformations $R^n\to R^n.$\footnote{We remark that there is some care here: we want $R^{n\times n}$ acts on the left of $R^n,$ but $R$ acts on the left of $R^{n\times n}.$}
	\item At a high level, sets $S$ correspond to free modules $R^S,$ which is the module which consists of $\#S$ copies of $R.$
	\item Groups have permutation representations (which are group actions on a set), which correspond to linear representations of a ring (which are ring actions on a module).
	\item If a group acts on two sets $A$ and $B,$ then we can consider the set-theoretic union $A\cup B$ compute cardinalities as
	\[|A\cup B|=|A|+|B|-|A\cap B|.\]
	(Note there is a canonical way to get a group action on $A\cup B.$\footnote{For example, if $\ZZ/2\ZZ$ swaps $A=\{1,2\}$ and swaps $B=\{2,3\},$ there is no good way for $\ZZ/2\ZZ$ to act on $A\cup B.$}) On the other hand, for vector spaces $V$ and $W$ which are subspaces of a bigger vector space $X,$ we can compute
	\[\dim(V+W)=\dim V+\dim W-\dim(V\cap W),\]
	which looks quite similar.
\end{itemize}
\begin{warn}
	The principle of inclusion-exclusion does not work for three vector spaces. For example, for three sets $A,B,C$ we have
	\[|A\cup B\cup C|=|A|+|B|+|C|-|A\cap B|-|B\cap C|-|C\cap A|+|A\cap B\cap C|.\]
	The analogous formula for vector subspaces $U,V,W\subseteq X$ fails.
\end{warn}
To manifest the warning, the formula fails for $U=\langle1,0\rangle\RR,$ $V=\langle1,1\rangle\RR,$ and $W=\langle0,1\rangle\RR$ living in $\RR^2.$ We can compute
\[\dim(U+V+W)=\dim\RR^2=2,\]
but
\[\dim U+\dim V+\dim W-\dim(U\cap V)-\dim(V\cap W)-\dim(W\cap U)+\dim(U\cap V\cap W)=3.\]
At a high level, the problem here is that bases do not behave enough like sets.
\begin{itemize}
	\item Regardless, (disjoint) unions of sets correspond to (direct) sums of modules.
	\item Given sets $S$ and $T$ with a $G$-action, we see $S\times T$ has a $G$-action by $g\cdot(s,t):=(g\cdot s,g\cdot t),$ which has
	\[\#(S\times T)=\#S\times\#T.\]
	This corresponds to tensor products of modules. As a quick and dirty definition, if $V$ and $W$ are $k$-vector spaces with bases $\{v_k\}_{k=1}^{\dim V}$ and $\{w_\ell\}_{\ell=1}^{\dim W},$ then we force $V\times W$ to have a basis $v_k\otimes v_\ell.$ Then we see
	\[\dim(V\otimes W)=\dim V\times\dim W.\]
\end{itemize}

\subsection{Burnside Ring}
Let's define an exotic ring: the Burnside ring of a group. We fix $G:=S_3$ for concreteness. We want to look at all isomorphism classes of finite sets with a $G$-action and make a ring, which will almost but not quite work.

For example, with sets $S$ and $T$ with a group action, we define
\[S+T:=S\sqcup T\qquad S\times T:=S\times T.\]
In other words, our addition is disjoint union, and our multiplication is product. To be explicit, our $G$-sets are as follows.
\begin{itemize}
	\item The action of $G$ on $S\sqcup T$ is defined by $g\cdot(s,0):=(g\cdot s,0)$ and $g\cdot(t,1):=(g\cdot t,1).$
	\item The action of $G$ on $S\times T$ is as given in the previous section.
\end{itemize}
Formally, we would have to check that that the isomorphism class of $S\sqcup T$ and $S\times T$ do not depend on the specific representative of $[S]$ and $[T],$ but this check is more annoying than difficult.

These operations obeys most of the ring actions, and multiplication even commutes! For example, our additive identity is $\emp$ (yes, groups can act on $\emp$), and the multiplicative identity is $\{*\}$ with the trivial action. However, there are no additive inverses because no operation can make our sets smaller.

To fix our additive inverse problem, we focus more closely on representatives of all transitive permutation representations of $G$; the point is that any $G$-action on a set is a disjoint union of how $G$ acts on each orbit, which is transitive. Well, if $G$ acts transitively on $S,$ the order of our set $S$ must be $\{1,2,3,6\}$ by the Orbit-stabilizer theorem. We can list the actions.
\begin{itemize}
	\item If $G$ acts on one element, then it is trivial.
	\item If $G$ acts on two elements transitively, then one of the order-$2$ elements swaps, and the rest of the action can be determined from this. There is one way to do this, up to isomorphism.
	\item If $G$ acts on $\{a,b,c\},$ transitively, then note that no transposition can be trivial, for then the entire conjugacy class of transpositions will be trivial, vanishing the image.
	
	Further, distinct transpositions must be sent to distinct transpositions in $\{1,2,3\},$ or else our action collapses to a transitive action on a two-element set. Without loss of generality, we send $(12)\mapsto(12)$ and $(23)\mapsto(bc)$ and $(13)\mapsto(ac)$ so that $G$ is acting on $S_3$ on $\{a,b,c\}.$

	\item If $G$ acts on six elements, it acts like $S_3$ on $S_3$ by left multiplication. Essentially, the transpositions need to all act on separate elements, else the action of $G$ on the set will miss one of the six elements and hence not be transitive.
	
	From these transpositions we can determine the entire action, so there is at most one action here, up to isomorphism. Well, we can exhibit $S_3$ acting on $S_3$ by left multiplication as an action, so one certainly exists.
\end{itemize}
Label these isomorphism classes by $[1],[2],[3],[6].$ Now we see that any permutation representation of $S_3$ are isomorphic to some disjoint union of the above orbits; namely our elements take the form
\[a_1[1]+a_2[2]+a_3[3]+a_6[6]\qquad a_1,a_2,a_3,a_6\ge0.\]
To make this a ring, we just let $a_1,a_2,a_3,a_6$ vary over all integers.
\begin{definition}[Burnside ring]
	Fix $G$ a group, and given a $G$-set $S,$ let $[S]$ be the isomorphism class of $S$ as a $G$-set. Now, label $\{[T]\}_{T\in\mathcal T}$ the isomorphism classes of transitive $G$-actions. Then the \textit{Burnside ring} of $G$ is defined as the free abelian group on $\mathcal T$
	\[\bigoplus_{T\in\mathcal T}\ZZ[T]\]
	with multiplication defined as
	\[[S_1]\times[S_2]:=[S_1\times S_2].\]
\end{definition}
As an example, we'll compute $[3]\times[3].$ Well, here $S_3$ is acting on the following lattice.
% https://q.uiver.app/?q=WzAsOSxbMCwwLCIoMSwxKSJdLFswLDEsIigxLDIpIl0sWzAsMiwiKDEsMykiXSxbMiwyLCIoMywzKSJdLFsxLDIsIigyLDMpIl0sWzEsMSwiKDIsMikiXSxbMSwwLCIoMiwxKSJdLFsyLDAsIigzLDEpIl0sWzIsMSwiKDMsMikiXV0=
\[\begin{tikzcd}
	{(1,1)} & {(2,1)} & {(3,1)} \\
	{(1,2)} & {(2,2)} & {(3,2)} \\
	{(1,3)} & {(2,3)} & {(3,3)}
\end{tikzcd}\]
For example, we can compute that $(12)$ acts as red in the following diagram, and $(23)$ acts as blue.
% https://q.uiver.app/?q=WzAsOSxbMCwwLCIoMSwxKSJdLFswLDEsIigyLDEpIl0sWzAsMiwiKDMsMSkiXSxbMSwwLCIoMSwyKSJdLFsyLDAsIigxLDMpIl0sWzEsMSwiKDIsMikiXSxbMiwxLCIoMiwzKSJdLFsxLDIsIigzLDIpIl0sWzIsMiwiKDMsMykiXSxbMCw1LCIiLDAseyJjb2xvdXIiOlswLDYwLDYwXSwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiYXJyb3doZWFkIn19fV0sWzEsMywiIiwwLHsiY29sb3VyIjpbMCw2MCw2MF0sInN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFs0LDYsIiIsMCx7ImNvbG91ciI6WzAsNjAsNjBdLCJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJhcnJvd2hlYWQifX19XSxbMiw3LCIiLDAseyJjb2xvdXIiOlswLDYwLDYwXSwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiYXJyb3doZWFkIn19fV0sWzUsOCwiIiwwLHsiY29sb3VyIjpbMjQwLDYwLDYwXSwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiYXJyb3doZWFkIn19fV0sWzYsNywiIiwxLHsiY29sb3VyIjpbMjQwLDYwLDYwXSwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiYXJyb3doZWFkIn19fV0sWzMsNCwiIiwwLHsiY29sb3VyIjpbMjQwLDYwLDYwXSwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiYXJyb3doZWFkIn19fV0sWzEsMiwiIiwxLHsiY29sb3VyIjpbMjQwLDYwLDYwXSwic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiYXJyb3doZWFkIn19fV1d
\[\begin{tikzcd}
	{(1,1)}\arrow[color={rgb,255:red,92;green,92;blue,214}, loop, distance=2em, in=215, out=145, ] & {(1,2)} & {(1,3)} \\
	{(2,1)} & {(2,2)} & {(2,3)} \\
	{(3,1)} & {(3,2)} & {(3,3)}\arrow[color={rgb,255:red,214;green,92;blue,92}, loop, distance=2em, in=35, out=325]
	\arrow[color={rgb,255:red,214;green,92;blue,92}, tail reversed, from=1-1, to=2-2]
	\arrow[color={rgb,255:red,214;green,92;blue,92}, tail reversed, from=2-1, to=1-2]
	\arrow[color={rgb,255:red,214;green,92;blue,92}, tail reversed, from=1-3, to=2-3]
	\arrow[color={rgb,255:red,214;green,92;blue,92}, tail reversed, from=3-1, to=3-2]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, tail reversed, from=2-2, to=3-3]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, tail reversed, from=2-3, to=3-2]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, tail reversed, from=1-2, to=1-3]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, tail reversed, from=2-1, to=3-1]
\end{tikzcd}\]
From these we see that we have at most two orbits, namely the diagonal and everything off of the diagonal. The diagonal is in fact an orbit because it is closed: for any $(k,k)$ and $\sigma\in S_3,$ then $\sigma(k,k)=(\sigma k,\sigma k)$ remains on the diagonal. It follows that the off-diagonal elements must also be closed and hence forms another orbit.

So we see that $S_3$ is acting transitively on a set of size $3$ (the diagonal) and transitively on a set of size $6$ (off the diagonal) so we find $\pi_3\times\pi_3=\pi_3+\pi_6.$

\subsection{Group Rings}
We remark that, as expected, $\op{Ring}$ is a category of rings, where morphisms are homomorphisms are maps between rings which preserve the ring structure.

Further, modules over a fixed ring $R$ form a category in the same way that vector spaces are; namely, our morphisms are linear transformations between $R$-modules.

We want some functors. Here is the group ring.
\begin{definition}[Group ring]
	The \textit{group ring} $R[G]$ of a group $G$ and ring $R$ is defined as a free module of $G$ with basis given by the elements of $G.$ Then we define multiplication to distribute and then multiply as in the group:
	\[\left(\sum_{g\in G}a_gg\right)\left(\sum_{h\in G}b_hh\right):=\sum_{k\in G}\sum_{gh=k}(a_gb_h)k.\]
\end{definition}
\begin{remark}
	We can check that $G$ acting linearly on a group is the same thing as finding a module over the group ring.
\end{remark}
We note that the construction for a group ring also works for modules instead of groups. For example, we have the following.
\begin{example}
	If we take the monoid $M=\NN,$ then the group ring $\ZZ[M]$ is the polynomial ring $\ZZ[x].$ Namely, $k\in\NN$ gets taken to $k\mapsto x^k.$
\end{example}
So where are our functors? Well, we have the following.
\begin{proposition}
	We claim that the (forgetful) functor $G:\op{Ring}\to\op{Grp}$ by $G:R\mapsto R^\times$ is right adjoint to the group ring functor $F:\op{Grp}\to\op{Ring}$ by $F:A\mapsto\ZZ[A].$
\end{proposition}
Again, we are having that left adjoints appear free and right adjoints appear forgetful. At a high level, these are isomorphic because maps $G\to R^\times$ are in correspondence with maps $\ZZ[G]\to R$ because maps $\ZZ[G]$ must send group elements to elements of $\RR^\times.$
\begin{proof}
	We will actually do the checks for this because I should do this at least once in my life. The main point is the following lemma; roughly speaking this says that the group ring is the ring freely generated by a group.
	\begin{lemma} \label{lem:grprngup}
		Fix $A$ a group and $R$ a ring with identity. Then we have the following.
		\begin{enumerate}[label=(\alph*)]
			\item A morphism $\varphi:A\to R^\times$ can be uniquely lifted to a morphism $\overline\varphi:\ZZ[A]\to R.$
			\item Any morphism $\overline\varphi:\ZZ[A]\to R$ can be restricted to a morphism $\varphi:A\to R^\times.$
		\end{enumerate}
		We remark that lifting and restriction are inverses of each other, well-defined by the uniqueness of the lifting.
	\end{lemma}
	\begin{proof}
		We take these claims one at a time.
		\begin{enumerate}[label=(\alph*)]
			\item Suppose that we have a morphism $\varphi:A\to R^\times.$ Then, for any element
			\[\sum_{a\in A}k_aa\in\ZZ[A],\]
			properties of $\overline\varphi$ force that
			\[\overline\varphi\left(\sum_{a\in A}k_aa\right)=\sum_{a\in A}k_a\varphi(a)\]
			by distributing repeatedly. This shows that $\varphi:\ZZ[A]\to R$ is forced and hence unique. Conversely, the above actually works as a definition for $\varphi,$ for which we have to check
			\[\overline\varphi\left(\sum_{a\in A}k_aa\cdot\sum_{a\in A}\ell_aa\right)=\overline\varphi\left(\sum_{a\in A}k_aa\right)\overline\varphi\left(\sum_{a\in A}\ell_aa\right),\]
			and
			\[\overline\varphi\left(\sum_{a\in A}k_aa+\sum_{a\in A}\ell_aa\right)=\overline\varphi\left(\sum_{a\in A}k_aa\right)+\overline\varphi\left(\sum_{a\in A}\ell_aa\right),\]
			which are true after some distributing. We do also have to check that $\overline\varphi(e)=e=1e,$ which holds because $\varphi:A\to R^\times$ is a group homomorphism.
			\item Conversely, suppose that we have a morphism $\overline\varphi:\ZZ[A]\to R.$ We note that $\overline\varphi$ being a ring homomorphism implies that $\overline\varphi(a_1a_2)=\overline\varphi(a_1)\overline\varphi(a_2),$ so $\overline\varphi$ restricted to $A$ is homomorphic.

			The main check is that restricting $\overline\varphi$ to $A$ actually outputs into $R^\times.$ Well, the multiplicative identity of $\ZZ[A]$ is $1e=e,$ so for any $a\in A,$ we find
			\[\overline\varphi(a)\overline\varphi\left(a^{-1}\right)=\overline\varphi\left(aa^{-1}\right)=\overline\varphi(e)=1_R,\]
			so indeed $\im\varphi\subseteq R^\times.$
			\qedhere
		\end{enumerate}
	\end{proof}
	We now check that our functors are adjoint. There are two diagrams to check.
	\begin{itemize}
		\item Fix $\gamma:A_1\to A_2.$ We show that the following diagram commutes, for any ring $R.$
		% https://q.uiver.app/?q=WzAsNixbMSwwLCJBXzJcXHRvIFJeXFx0aW1lcyJdLFswLDAsIkFfMSJdLFswLDEsIkFfMiJdLFsxLDEsIkFfMVxcdG8gUl5cXHRpbWVzIl0sWzIsMCwiXFxtYXRoYmIgWltBXzJdXFx0byBSIl0sWzIsMSwiXFxtYXRoYmIgWltBXzFdXFx0byBSIl0sWzEsMiwiXFx2YXJwaGkiLDJdLFswLDMsIi1cXGNpcmNcXHZhcnBoaSIsMl0sWzAsNF0sWzMsNV0sWzQsNSwiLVxcY2lyY1xcdmFycGhpIl1d
		\[\begin{tikzcd}
			{A_1} & {A_2\to R^\times} & {\mathbb Z[A_2]\to R} \\
			{A_2} & {A_1\to R^\times} & {\mathbb Z[A_1]\to R}
			\arrow["\gamma"', from=1-1, to=2-1]
			\arrow["{-\circ\gamma}"', from=1-2, to=2-2]
			\arrow[from=1-2, to=1-3]
			\arrow[from=2-2, to=2-3]
			\arrow["{-\circ\gamma}", from=1-3, to=2-3]
		\end{tikzcd}\]
		Here, the horizontal arrows are the ones promised by the bijection in \autoref{lem:grprngup}. We check the commutativity by hand. Fix $\varphi:A_2\to R^\times.$ Following the diagram around, we see that we are showing $\overline\varphi\circ\gamma=\overline{\varphi\circ\gamma}.$ Well, $\overline{\varphi\circ\gamma}$ is the unique morphism making the following diagram commute.
		% https://q.uiver.app/?q=WzAsNCxbMCwwLCJBXzEiXSxbMSwwLCJSXlxcdGltZXMiXSxbMCwxLCJcXG1hdGhiYiBaW0FfMV0iXSxbMSwxLCJSIl0sWzAsMSwiXFx2YXJwaGlcXGNpcmNcXGdhbW1hIl0sWzAsMiwiIiwyLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMSwzLCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsyLDMsIlxcb3ZlcmxpbmV7XFx2YXJwaGlcXGNpcmNcXGdhbW1hfSIsMl1d
		\[\begin{tikzcd}
			{A_1} & {R^\times} \\
			{\mathbb Z[A_1]} & R
			\arrow["\varphi\circ\gamma", from=1-1, to=1-2]
			\arrow[hook, from=1-1, to=2-1]
			\arrow[hook, from=1-2, to=2-2]
			\arrow["{\overline{\varphi\circ\gamma}}"', from=2-1, to=2-2]
		\end{tikzcd}\]
		However, $\overline\varphi\circ\gamma$ makes the following diagram commute.
		% https://q.uiver.app/?q=WzAsNixbMCwwLCJBXzEiXSxbMSwwLCJBXzIiXSxbMiwwLCJSXlxcdGltZXMiXSxbMSwxLCJcXG1hdGhiYiBaW0FfMl0iXSxbMCwxLCJcXG1hdGhiYiBaW0FfMV0iXSxbMiwxLCJSIl0sWzAsMSwiXFxnYW1tYSJdLFsxLDIsIlxcdmFycGhpIl0sWzQsMywiXFxnYW1tYSIsMl0sWzMsNSwiXFxvdmVybGluZVxcdmFycGhpIiwyXSxbMCw0LCIiLDIseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsxLDMsIiIsMSx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzIsNSwiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XV0=
		\[\begin{tikzcd}
			{A_1} & {A_2} & {R^\times} \\
			{\mathbb Z[A_1]} & {\mathbb Z[A_2]} & R
			\arrow["\gamma", from=1-1, to=1-2]
			\arrow["\varphi", from=1-2, to=1-3]
			\arrow["\gamma"', from=2-1, to=2-2]
			\arrow["\overline\varphi"', from=2-2, to=2-3]
			\arrow[hook, from=1-1, to=2-1]
			\arrow[hook, from=1-2, to=2-2]
			\arrow[hook, from=1-3, to=2-3]
		\end{tikzcd}\]
		In particular, we see that $\overline\varphi\circ\gamma$ makes the diagram for $\overline{\varphi\circ\gamma}$ commute, so $\overline\varphi\circ\gamma=\overline{\varphi\circ\gamma}$ by uniqueness.

		\item Fix $\gamma:R_1\to R_2.$ We show that the following diagram commutes, for any group $A.$
		% https://q.uiver.app/?q=WzAsNixbMCwwLCJSXzEiXSxbMCwxLCJSXzIiXSxbMSwwLCJBXFx0byBSXzFeXFx0aW1lcyJdLFsxLDEsIkFcXHRvIFJfMl5cXHRpbWVzIl0sWzIsMCwiXFxtYXRoYmIgWltBXVxcdG8gUl8xIl0sWzIsMSwiXFxtYXRoYmIgWltBXVxcdG8gUl8yIl0sWzAsMSwiXFxnYW1tYSIsMl0sWzIsMywiXFxnYW1tYVxcY2lyYy0iLDJdLFs0LDUsIlxcZ2FtbWFcXGNpcmMtIl0sWzIsNF0sWzMsNV1d
		\[\begin{tikzcd}
			{R_1} & {A\to R_1^\times} & {\mathbb Z[A]\to R_1} \\
			{R_2} & {A\to R_2^\times} & {\mathbb Z[A]\to R_2}
			\arrow["\gamma"', from=1-1, to=2-1]
			\arrow["{\gamma\circ-}"', from=1-2, to=2-2]
			\arrow["{\gamma\circ-}", from=1-3, to=2-3]
			\arrow[from=1-2, to=1-3]
			\arrow[from=2-2, to=2-3]
		\end{tikzcd}\]
		Again, the horizontal arrows are coming from the bijection promised from \autoref{lem:grprngup}. We check the commutativity by hand. Fix $\varphi:A\to R_1^\times.$ Following the diagram around, we see that we are showing $\overline\gamma\circ\varphi=\overline{\gamma\circ\varphi}.$ Well, $\overline{\gamma\circ\varphi}$ is the unique morphism making the following diagram commute.
		% https://q.uiver.app/?q=WzAsNCxbMCwwLCJBIl0sWzEsMCwiUl5cXHRpbWVzXzIiXSxbMCwxLCJcXG1hdGhiYiBaW0FdIl0sWzEsMSwiUl8yIl0sWzAsMSwiXFxnYW1tYVxcY2lyY1xcdmFycGhpIl0sWzAsMiwiIiwyLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMSwzLCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsyLDMsIlxcb3ZlcmxpbmV7XFxnYW1tYVxcY2lyY1xcdmFycGhpfSIsMl1d
		\[\begin{tikzcd}
			A & {R^\times_2} \\
			{\mathbb Z[A]} & {R_2}
			\arrow["\gamma\circ\varphi", from=1-1, to=1-2]
			\arrow[hook, from=1-1, to=2-1]
			\arrow[hook, from=1-2, to=2-2]
			\arrow["{\overline{\gamma\circ\varphi}}"', from=2-1, to=2-2]
		\end{tikzcd}\]
		However, $\gamma\circ\overline\varphi$ makes the following diagram commute.
		% https://q.uiver.app/?q=WzAsNixbMCwwLCJBIl0sWzEsMCwiUl8xXlxcdGltZXMiXSxbMiwwLCJSXlxcdGltZXNfMiJdLFsxLDEsIlJfMSJdLFswLDEsIlxcbWF0aGJiIFpbQV0iXSxbMiwxLCJSXzIiXSxbMCwxLCJcXHZhcnBoaSJdLFsxLDIsIlxcZ2FtbWEiXSxbNCwzLCJcXG92ZXJsaW5lXFx2YXJwaGkiLDJdLFszLDUsIlxcZ2FtbWEiLDJdLFswLDQsIiIsMix7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzEsMywiIiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMiw1LCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dXQ==
		\[\begin{tikzcd}
			A & {R_1^\times} & {R^\times_2} \\
			{\mathbb Z[A]} & {R_1} & {R_2}
			\arrow["\varphi", from=1-1, to=1-2]
			\arrow["\gamma", from=1-2, to=1-3]
			\arrow["\overline\varphi"', from=2-1, to=2-2]
			\arrow["\gamma"', from=2-2, to=2-3]
			\arrow[hook, from=1-1, to=2-1]
			\arrow[hook, from=1-2, to=2-2]
			\arrow[hook, from=1-3, to=2-3]
		\end{tikzcd}\]
		In particular, we see that $\gamma\circ\overline\varphi$ makes the diagram for $\overline{\gamma\circ\varphi}$ commute, so $\gamma\circ\overline\varphi=\overline{\gamma\circ\varphi}$ by uniqueness.
		\qedhere
	\end{itemize}
\end{proof}

\subsubsection{Fun with \texorpdfstring{$\CC[G]$}{}}
As an example, fix $G:=(\ZZ/2\ZZ)^2$ giving the group ring $\ZZ[G].$ But we can also look at, say, $\CC[G],$ which is a vector space with basis enumerated by $G=(\ZZ/2\ZZ)^2.$ We'll label $G=\{1,a,b,c\}$ for brevity.
\begin{remark}
	We are using $G=(\ZZ/2\ZZ)^2$ because Professor Borcherds is getting bored with cyclic groups.
\end{remark}
However, we claim that $\CC[G]$ is actually just four copies of $\CC,$ as a ring. Surely, $\CC[G]$ is a vector space and splits into one-dimensional vector spaces, but that's not what we're interested in.

Roughly speaking, splitting a ring $R$ into a product $S\times T$ corresponds with idempotent elements.
\begin{definition}[Idempotent]
	An element $x\in R$ is \textit{idempotent} if and only if $x^2=x.$
\end{definition}
\begin{example}
	Any ring $R$ has $0\cdot0=0,$ so $0$ is idempotent. If $R$ has identity $1,$ then $1\cdot1=1,$ so $1$ is also idempotent.
\end{example}
\begin{example}
	If $R$ is a commutative ring with identity satisfying $ab=0$ implies $a=0$ or $b=0,$ then $x^2=x$ implies $x(x-1)=0$ implies $x=0$ or $x=1.$ So in fact $0$ and $1$ are only idempotents.
\end{example}
The reason we care about this is that the ring $S\times T$ will have the extra idempotents $(0,0),(1,1),(0,1),(1,0),$ which is a lot more that what we expect as just $0$ and $1.$ It turns out that we can reverse: given nontrivial idempotents, then we can decompose $R$ into a product of smaller rings.
\begin{proposition} \label{prop:idemdecomp}
	Suppose $R$ is a commutative ring with identity $1$ and an idempotent element $x\in R.$ Then we have the direct sum
	\[Rx\oplus R(1-x)\cong R.\]
\end{proposition}
Note that the rings $Rx$ and $R(1-x)$ need not contain the unity element of $R$ and in fact in general may not. But, for example in $Rx,$ any $rx\in Rx$ has $rx\cdot x=rx^2=rx,$ so $x$ serves as an identity here.
\begin{proof}[Proof of \autoref{prop:idemdecomp}]
	Note that we have the map $\varphi:Rx\oplus R(1-x)\to R$ by $\varphi:(ax,b(1-x))\mapsto ax+b(1-x),$ which we will not check is actually homomorphic, but it is. Note that $\varphi$ is surjective because we can write
	\[r=r1=rx+r(1-x)=\varphi(rx,r(1-x)).\]
	Further, $\varphi$ is injective because it has trivial kernel: if $ax+b(1-x)=0,$ then we claim $ax=b(1-x)=0.$ Indeed, the trick is that $x^2=x$ implies that $x(1-x)=0,$ so
	\[ax=ax^2=ax^2+bx(1-x)=x\cdot\big(ax+b(1-x)\big)=0.\]
	Similarly,
	\[b(1-x)=b(1-x)^2=ax(1-x)+b(1-x)^2=(1-x)\big(ax+b(1-x)\big)=0,\]
	which is what we wanted.
\end{proof}
\begin{remark}
	The representation if $r=ax+b(1-x)$ is only unique up to $ax$ and $b(1-x),$ not up to $a$ and $b.$ In other words, it is possible for the map $R\times R\to R$ defined by $(a,b)\mapsto ax+b(1-x)$ to have a kernel, but this is not what \autoref{prop:idemdecomp} is claiming.
\end{remark}
\begin{remark}
	There is an analogous construction for non-commutative rings with identity: if $x\in R$ is idempotent, we can write
	\[R\cong xRx\oplus xR(1-x)\oplus (1-x)Rx\oplus (1-x)R(1-x).\]
	When the ring is commutative, the terms $xR(1-x)$ and $(1-x)Rx$ vanish because $x(1-x)=0.$
\end{remark}
With this in mind, let's find idempotents in $\CC[G].$ We can check that the following are idempotent.
\[\left\{\frac{1+a+b+c}4,\frac{1-a+b-c}4,\frac{1+a-b-c}4,\frac{1-a-b+c}4\right\}.\]
These are not the only idempotents (adding any of them will also give an idempotent), but they are good enough for a basis of $\CC[G].$ Indeed, we claim that
\[\CC[G]\cong\CC\left[\frac{1+a+b+c}4\right]\oplus\CC\left[\frac{1-a+b-c}4\right]\oplus\CC\left[\frac{1+a-b-c}4\right]\oplus\CC\left[\frac{1-a-b+c}4\right].\]
Note that each of the spaces on the right-hand side are still $G$-sets because they are closed under the $G$-action; for example, $\{1,a,b,c\}$ acting on $\frac{1-a+b-c}4$ will get sent to $\pm\frac{1-a+b-c}4\in\CC\left[\frac{1-a+b-c}4\right]$ under multiplication by $G.$ (This is the same check as $\frac{1-a+b-c}4$ is idempotent.)

To show the direct sum, we note that $\CC[G]$ is four-dimensional as a $\CC$-vector space, and the space
\[V:=\CC\left[\frac{1+a+b+c}4\right]\oplus\CC\left[\frac{1-a+b-c}4\right]\oplus\CC\left[\frac{1+a-b-c}4\right]\oplus\CC\left[\frac{1-a-b+c}4\right],\]
is at most dimension $4,$ so it suffices to show that the above spaces will span into all $\CC[G].$ For this it is enough to note the natural map
\[(w,x,y,z)\longmapsto w\frac{1+a+b+c}4+x\frac{1-a+b-c}4+y\frac{1+a-b-c}4+z\frac{1-a-b+c}4.\]
is in fact bijective because this transformation corresponds to the matrix
\[\frac14\begin{bmatrix}
	1 &  1 &  1 &  1 \\
	1 & -1 &  1 & -1 \\
	1 &  1 & -1 & -1 \\
	1 & -1 & -1 &  1 \\
\end{bmatrix},\]
which has nonzero determinant. So indeed, we see that $\CC[G]$ splits as claimed.
\begin{remark}
	It turns out that any abelian group ring over $\CC$ will split into various copies of $\CC$ as a ring as well, which is roughly speaking due to the representation theory of abelian groups.
\end{remark}
\begin{example}[Nir]
	Take $G=\langle g\rangle\cong\ZZ/n\ZZ.$ Then the group ring $\CC[G]$ is decomposed with the idempotents $\frac1n\sum_{k=0}^n(\zeta^\bullet g)^k,$ where $\zeta$ is a primitive $n$th root of unity. Indeed, we can compute that
	\[\left(\sum_{k=0}^n(\zeta^ag)^k\right)\left(\sum_{\ell=0}^n(\zeta^bg)^\ell\right)=\sum_{k,\ell=0}^n\zeta^{ak+b\ell}g^{k+\ell}=\sum_{m=0}^n\left(\sum_{k+\ell=m}\zeta^{ak+b\ell}\right)g^m=\sum_{m=0}^n\left(\sum_{k=0}^n\zeta^{(a-b)k}\right)\zeta^{bm}g^m.\]
	If $a=b,$ then the internal sum evaluates to $n$; if $a\ne b,$ then the internal sum vanishes. This shows that these elements are orthogonal idempotents.
\end{example}

\subsubsection{Dirichlet Series}
Let's do another example of a monoid ring, as formal series.
\begin{example}
	So we have that $\CC[\NN]$ is the polynomials over $\CC,$ where $\NN$ is the naturals under addition.
\end{example}
\begin{example}
	We consider the set of formal Dirichlet series
	\[\sum_{k=1}^\infty\frac{a_k}{k^s}.\]
	Our multiplication is defined formally by
	\[\left(\sum_{k=1}^\infty\frac{a_k}{k^s}\right)\left(\sum_{\ell=1}^\infty\frac{b_\ell}{\ell^s}\right)=\sum_{n=1}^\infty\left(\sum_{k\ell=n}a_kb_\ell\right)\frac1{n^s}.\]
	Note that this is very different from the usual polynomial ring multiplication.
\end{example}
It turns out that the finite Dirichlet series are the ring $\CC[\NN^\times],$ where $\NN^\times$ is the monoid of the nonzero naturals under multiplication. Then in the same way that we can make $\CC[\NN]$ formal by making it infinite, we can make Dirichlet series infinite.

As an example of what we can do, number theorists care a lot about Dirichlet series. For example, we have
\[\zeta(s)=\sum_{k=1}^\infty\frac1{k^s}\qquad\text{and}\qquad\frac1{\zeta(s)}=\sum_{k=1}^\infty\frac{\mu(n)}{n^s},\]
where $\mu$ is the M\"obius function.

\subsection{Coproducts}
We can also talk about categorical coproducts in $R.$ To review, this means that we have rings $R$ and $S$ and want a ring $R*S$ with inclusions $\iota_R:R\to R*S$ and $\iota_S:S\to R*S$ that satisfies the universal property. Explicitly, for any other ring $A$ with maps $\alpha_R:R\to A$ and $\alpha_S:S\to A,$ there is a unique induced map $\alpha:R*S\to A$ making the following diagram commute.
% https://q.uiver.app/?q=WzAsNCxbMCwxLCJTIl0sWzEsMCwiUiJdLFsxLDEsIlIqUyJdLFsyLDIsIkEiXSxbMCwyLCJcXGlvdGFfUyJdLFsxLDIsIlxcaW90YV9SIiwyXSxbMSwzLCJcXGFscGhhX1IiLDAseyJjdXJ2ZSI6LTJ9XSxbMCwzLCJcXGFscGhhX1MiLDIseyJjdXJ2ZSI6Mn1dLFsyLDMsIlxcYWxwaGEiLDEseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	& R \\
	S & {R*S} \\
	&& A
	\arrow["{\iota_S}", from=2-1, to=2-2]
	\arrow["{\iota_R}"', from=1-2, to=2-2]
	\arrow["{\alpha_R}", curve={height=-12pt}, from=1-2, to=3-3]
	\arrow["{\alpha_S}"', curve={height=12pt}, from=2-1, to=3-3]
	\arrow["\alpha"{description}, dashed, from=2-2, to=3-3]
\end{tikzcd}\]

However, it is an important point that what the coproduct is depends on whether we are working with commutative rings or non-commutative rings.
\begin{example}
	Consider $R=S=\ZZ[x].$
	\begin{itemize}
		\item The coproduct $\ZZ[x]*\ZZ[x]$ in the category of commutative rings is the two-variable polynomials $\ZZ[x,y].$ Indeed, any ring map $\ZZ[x]\to X$ corresponds to deciding where $x$ should go in $X,$ so when deciding on a map $\ZZ[x]*\ZZ[x],$ we have two decisions to make for each $\ZZ[x].$ Making two choices is the same as making choices for $\ZZ[x,y].$
		\item The coproduct in the category of all rings is the ``non-commutative polynomial ring,'' which is the ring formed over $\ZZ$ where the generators $x,y$ do not need to commute. Namely, we have our $\ZZ$-module freely generated by
		\[1,x,y,\quad x^2,xy,yx,y^2,\quad x^3,x^2y,yx^2,xy^2,y^2x,y^3,\ldots\]
	\end{itemize}
\end{example}
So this is similar to the story for groups, where things that commute are good, but things that don't commute are difficult to get a handle of. To be more explicit, the generators of the coproduct in non-commutative rings turn look like some kind of free (non-commutative) monoid generated by $x,y.$

\subsection{Ideals}
We work with commutative rings here. We can also define rings based off of their generators and relations. In the group story, we wanted normal subgroups, but here our story is different. Suppose that we have a surjective ring homomorphism $\varphi:R\to S.$ Then $\ker\varphi$ satisfies the following.
\begin{itemize}
	\item $\ker\varphi$ is closed under addition.
	\item $\ker\varphi$ is closed under multiplication by any element of $R.$
\end{itemize}
This defines an ideal.
\begin{definition}[Ideal]
	An ideal $I$ of a ring $R$ satisfies the following, for any $r\in R$ and $a,b\in I.$
	\begin{itemize}
		\item $a+b\in I.$
		\item $ra,ar\in I.$
	\end{itemize}
\end{definition}
\begin{remark}
	If our rings are non-commutative, then we have to deal with left and right ideals, which might be closed under multiplication on one side but not the other.
\end{remark}
We can show that all kernels are ideals.
\begin{lemma}
	Fix $R$ and $S$ commutative rings with identity. Fix a ring homomorphism $\varphi:R\to S.$ Then $\ker\varphi$ is an ideal.
\end{lemma}
\begin{proof}
	We check the conditions one at a time.
	\begin{itemize}
		\item If $k_1,k_2\in\ker\varphi,$ then $\varphi(k_1+k_2)=\varphi(k_1)+\varphi(k_2)=0_S+0_S=0_S,$ so $k_1+k_2\in\ker\varphi.$
		\item If $r\in R$ and $k\in\ker\varphi,$ then
		\[\varphi(rk)=\varphi(r)\varphi(k)=\varphi(r)\cdot0_S=0_S,\]
		so $rk\in\ker\varphi$ as well.
		\qedhere
	\end{itemize}
\end{proof}
The converse is also true, using a similar construction as with quotient groups.
\begin{lemma}
	Fix $R$ a commutative ring and $I$ an ideal. Then we can define the quotient group $R/I$ and make $R/I$ into a ring by
	\[aI\cdot bI=(ab)I\]
	for $a,b\in R.$ If $R$ has unity, then $I$ does as well.
\end{lemma}
\begin{proof}
	The quotient group $R/I$ exists because $(R,+)$ is abelian, so $I$ is a subgroup and hence a normal subgroup.

	The main thing to check is that multiplication is well-defined. Well, suppose that $a_1I=a_2I$ and $b_1I=b_2I$ so that $a_1-a_2=:i_a\in I$ and $b_1-b_2=:i_b\in I.$ Then we want to verify that
	\[(a_1b_1)I\stackrel?=(a_2b_2)I.\]
	Indeed, we see
	\[a_2b_2=(a_1+i_a)(b_1+i_b)=a_1b_1+\underbrace{b_1i_a+a_1i_b+i_1i_2},\]
	where the bracketed part is in $I$ by definition of the ideal.

	We will not check that all of the various ring axioms hold; they are mostly just inherited directly from $R.$
\end{proof}
The point is that the canonical map $R\onto R/I$ by $r\mapsto rI$ goes into the kernel if and only if $r\in I,$ so this map has kernel $I.$ So indeed, any ideal can be constructed as a kernel. In this way ideals are somewhat similar to normal subgroups, in that they are the conditions we want to make quotients.

So now, to define a ring (or group) by generators and relations, we pick up some generators $\{a_k\}_{k=1}^n,$ which generate a free ring (or group). Then we want to quotient by the ideal (or normal subgroup) generated by those relations. We give these constructions more explicitly as follows.
\begin{itemize}
	\item To be formal, let $\op{Free}(S)$ be the free group generated by $S.$
	
	For our construction, doing this for groups means we start with the letters $\{a_\alpha\}_{\alpha\in\lambda}$ generating the free group $\op{Free}(\{a_\alpha\}_{\alpha\in\lambda}).$ Then, given some relations we want to mod out by as words $\{w_\beta\}_{\beta\in\kappa},$ we note that there is a morphism $\varphi:\op{Free}(\kappa)\to F$ lifting
	\[\varphi:\beta\mapsto w_\beta.\]
	Then the group $G$ given by the letters $\{a_\alpha\}$ and relations $\{w_\beta\}$ is
	\[F/\overline{\im\varphi},\]
	which is $F$ modulo the normal closure of $\im\varphi.$ Explicitly,
	\[\overline{\im\varphi}:=\bigcap_{\im\varphi\subseteq N}M,\]
	where $N$ loops over normal subgroups of $F.$

	\item A bit more easily, we can define the ring generated by letters $\{a_\alpha\}_{\alpha\in\lambda}$ and words $\{w_\beta\}_{\beta\in\kappa}$ to be the free ring modulo
	\[\bigoplus_{\beta\in\kappa}Fw_\beta,\]
	which is the ideal generated by the words $\{w_\beta\}_{\beta\in\kappa}.$
\end{itemize}
\begin{example}
	Fix $G$ generated by $a,b$ with relations $a^2=b^2=(ab)^n=e.$ We can check that $G$ is $D_{2n},$ where $a$ and $b$ are some particular reflections.
\end{example}
In general, it is very hard to find the group given generators and relations.
\begin{nex}
	Fix $G$ generated by $a,b,c$ with relations $aba^{-1}=b^2$ and $bcb^{-1}=c^2$ and $cac^{-1}=a^2.$ This problem turns out to be very hard, even to determine if $G$ is trivial or not.
\end{nex}
\begin{remark}
	In fact, there is a theorem that there is no algorithm which can in general turn a system of generators and relations into a group structure, or even if the group is trivial.
\end{remark}
\begin{example}
	Fix generators $x,y$ with the relation $y^2=x^3-x,$ and we look at the free polynomial ring $\CC[x,y].$ Then we are studying
	\[\frac{\CC[x,y]}{\left(y^2-x^3+x\right)}.\]
	Things ring can be interpreted as the polynomial functions from the curve $y^2=x^3-x$ to, say, $\CC.$ Namely, we want to identify two polynomials on $y^2=x^3-x$ if they are equal on all points of $y^2=x^3-x,$ which is the same as modding out by polynomials which identically vanish on $y^2=x^3-x.$
\end{example}
For more related to the above example, see algebraic geometry.