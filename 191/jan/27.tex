% !TEX root = ../notes.tex

\documentclass[../notes.tex]{subfiles}

\begin{document}

\section{January 27}

We began class finishing the proof of \Cref{thm:ps}. I have edited directly into that proof for continuity.

\subsection{An Abstract Functional Equation}
We now use \Cref{thm:ps} in order to show the functional equation for $\zeta$, which provides us with its meromorphic continuation.

There is a usual functional equation, but we will take a moment to point out that there is nothing particularly special about the functional equation we are about to construct. Indeed, we can build a family of functional equations as follows.
\begin{proposition} \label{prop:int-functional-eq}
	Call a Schwarz function $f\colon\RR\to\RR$ ``slow'' if and only if the function
	\[S_f(x)\coloneqq\sum_{n\in\ZZ}f(nx)\]
	is defined on $(0,\infty)$ and decays at a rate of $(\alpha,\beta)$ for all $0<\alpha<\beta$. If $f$ is slow, then $I(f,s)\coloneqq(\mc MS_f)(s)$ converges absolutely to a holomorphic function on $\{s:\op{Re}s>0\}$. In fact, if $\mc Ff$ is also slow, then
	\[I(\mc Ff,1-s)=I(f,s)\]
	for $0<\op{Re}s<1$.
\end{proposition}
\begin{proof}
	The second sentence follows from \Cref{prop:bound-mellin-transform}.

	It remains to show the last sentence. By \Cref{ex:use-ps}, we see
	\[\sum_{n\in\ZZ}f(nx)=\frac1x\sum_{n\in\ZZ}(\mc Ff)(n/x)\]
	for any $x>0$. It follows that
	\begin{align*}
		I(f,s) &= \int_0^\infty\Bigg(\sum_{n\in\ZZ}f(nx)\Bigg)x^s\,\frac{dx}x \\
		&= \int_0^\infty\Bigg(\sum_{n\in\ZZ}(\mc Ff)(n/x)\Bigg)x^{s-1}\,\frac{dx}x \\
		&= \int_0^\infty\Bigg(\sum_{n\in\ZZ}(\mc Ff)(nx)\Bigg)x^{1-s}\,\frac{dx}x \\
		&= I(\mc Ff,1-s),
	\end{align*}
	which is what we wanted.
\end{proof}
\begin{corollary} \label{cor:abstract-func-eq}
	Continue in the context of \Cref{prop:int-functional-eq}, but further assume that the (double) integrals $I(f,s)$ and $I(\mc Ff,s)$ both absolutely converge for $\op{Re}s>0$. Then
	\[\zeta(s)(\mc Mf)(s)=(\mc M\mc Ff)(1-s)\zeta(1-s).\]
\end{corollary}
\begin{proof}
	Because the (double) integral $I(f,s)$ absolutely converges, we may use Fubini's theorem to write
	\begin{align*}
		I(f,s) &= \int_0^\infty\Bigg(\sum_{n\in\ZZ}f(nx)\Bigg)x^s\,\frac{dx}x \\
		&= \sum_{n\in\ZZ}\left(\int_0^\infty f(nx)x^s\,\frac{dx}x\right) \\
		&\stackrel*= 2\sum_{n=1}^\infty\left(\frac1{n^s}\int_0^\infty f(x)x^s\,\frac{dx}x\right) \\
		&= 2\zeta(s)(\mc Mf)(s),
	\end{align*}
	Note at $\stackrel*=$ we have assumed that $f(0)=0$, which holds because $S_f(x)$ converges absolutely. (Indeed, if $f|(0)|>0$, then as $x\to0^+$, we would have $S_f(x)$ diverge: we may say $|f(x)|>|f(0)|/2$ for $|x|<\delta$, but then the absolute sum is bounded below by $n|f(0)|/2$ at $x=\delta/n$.) To finish, we plug into the functional equation of \Cref{prop:int-functional-eq}.
\end{proof}
\begin{remark}
	We could spend time searching for a function $f$ satisfying all of our various hypotheses, but we are about to show a more concrete functional equation, so there is little point.
\end{remark}

\subsection{Facts about \texorpdfstring{$\Gamma$}{ Gamma}}
In this subsection, we will collect a few facts about $\Gamma$ which will be helpful shortly. We will loosely follow \cite[Section 1]{tao-gamma-function}.
\begin{definition}
	For $\op{Re}s>0$, we define
	\[\Gamma(s)\coloneqq\int_0^\infty e^{-t}t^s\,\frac{dt}t.\]
\end{definition}
\begin{remark} \label{rem:gamma-is-gauss-sum}
	In some sense, $\Gamma$ is a continuous version of a Gauss sum: it's an integral of an additive character multiplied by a multiplicative character, over a suitable Haar measure.
\end{remark}
\begin{remark} \label{rem:gamma-is-holo}
	Define $f\colon[0,\infty)\to\RR$ by $f(t)\coloneqq e^{-t}$ so that $\Gamma=\mc Mf$ by definition. Notably, for any $c>0$, the function $t\mapsto t^cf(t)$ is bounded on $[0,\infty)$ because
	\[\lim_{t\to\infty}t^cf(t)=\lim_{t\to\infty}\frac{t^c}{e^t}=0.\]
	(Explicitly, find $N$ such that $\left|t^cf(t)\right|<1$ for any $x>N$; for $x\le N$, note $t\mapsto t^cf(t)$ has a maximum on the compact set $[0,N]$.) Thus, $f$ decays at a rate of $(\alpha,\beta)$ for any $0<\alpha<\beta$, so \Cref{prop:bound-mellin-transform} implies that $\Gamma$ converges absolutely and is a holomorphic function on $\{s:\op{Re}s>0\}$ by taking the union over all such $(\alpha,\beta)$.
\end{remark}
\Cref{rem:gamma-is-holo} assures us that $\Gamma$ is holomorphic on $\op{Re}s>0$, but we quickly note that we can provide $\Gamma$ with a meromorphic continuation to the left, at the cost of some poles.
\begin{lemma} \label{lem:ind-continue-gamma}
	For any $\op{Re}s>0$, we have $\Gamma(s+1)=s\Gamma(s)$.
\end{lemma}
\begin{proof}
	This is integration by parts. Indeed, we compute
	\begin{align*}
		\Gamma(s+1) &= \int_0^\infty e^{-t}t^{s}\,dt \\
		&= -e^{-t}t^s\bigg|_0^\infty+\int_0^\infty e^{-t}st^{s-1}\,dt \\
		&= 0+s\int_0^\infty e^{-t}t^s\,\frac{dt}t \\
		&= s\Gamma(s),
	\end{align*}
	which is what we wanted.
\end{proof}
\begin{example} \label{ex:gamma-on-positive-integers}
	For any positive integer $n$, applying \Cref{lem:ind-continue-gamma} inductively yields
	\[\Gamma(n)=(n-1)\Gamma(n-1)=(n-1)(n-2)\Gamma(n-2)=\cdots=(n-1)!\Gamma(1).\]
	Notably, $\Gamma(1)=\int_0^\infty e^{-t}\,dt=1$, so we see $\Gamma(n)=(n-1)!$ for any positive integer $n$.
\end{example}
\begin{remark} \label{rem:ind-continue-gamma}
	We now describe how to (inductively) continue $\Gamma$ using \Cref{lem:ind-continue-gamma}. Fix some $n\in\NN$ and set $U_n\coloneqq\{s:\op{Re}s>-n,-s\notin\ZZ_{\ge0}\}$. Then we define $\Gamma_n\coloneqq U_n\to\CC$ by
	\[\Gamma_n(s)\coloneqq\frac{\Gamma(s+n)}{s(s+1)(s+2)\cdots(s+n-1)}.\]
	Because $\Gamma$ is holomorphic on $\op{Re}s>0$, we see $\Gamma_n$ is holomorphic on $U_n$. Further, \Cref{lem:ind-continue-gamma} implies that $\Gamma_n(s)=\Gamma(s)$ for $\op{Re}s>0$, so we have indeed defined a continuation of $\Gamma$. Sending $n\to\infty$ provides our meromorphic continuation of $\Gamma$ to all of $\CC$.
\end{remark}
\Cref{rem:ind-continue-gamma} is in some sense analogous to defining a continuation for $\zeta(s)$ to all of $\CC$ using the repeated integration by parts mentioned in \Cref{rem:ind-continue-zeta}. However, just as with $\zeta$, there is a ``functional equation'' for $\Gamma$ which does not require the sort of inductive arguments of \Cref{rem:ind-continue-gamma}. We begin by upgrading \Cref{lem:ind-continue-gamma}.
\begin{lemma} \label{lem:add-gamma}
	For any $s_1,s_2\in\CC$ such that $\op{Re}s_1,\op{Re}s_2>0$, we have
	\[\Gamma(s_1+s_2)\int_0^1u^{s_1-1}(1-u)^{s_2-1}\,du=\Gamma(s_1)\Gamma(s_2).\]
\end{lemma}
\begin{proof}
	\Cref{rem:gamma-is-holo} tells us that the integral defining $\Gamma$ converges absolutely, so Fubini's theorem lets us write
	\[\Gamma(s_1)\Gamma(s_2)=\int_0^\infty\int_0^\infty e^{-t_1-t_2}t_1^{s_1-1}t_2^{s_2-1}\,dt_1dt_2.\]
	We would like to combine the $t_1$ and $t_2$ into a single $t$. Thus, we set $t_1=ut$ and $t_2=(1-u)t$ for $u\in[0,1]$ and $t\in(0,\infty]$. More precisely, for $t_1,t_2>0$, we have $u=t_1/(t_2+t_1)$ and $t=t_1+t_2$, which makes our Jacobian
	\[\det\left(\begin{bmatrix}
		\del t_1/\del u & \del t_1/\del t \\
		\del t_2/\del u & \del t_2/\del t
	\end{bmatrix}\right)=\det\left(\begin{bmatrix}
		t & u \\
		-t & 1-u
	\end{bmatrix}\right)=t.\]
	Thus,
	\[\Gamma(s_1)\Gamma(s_2)=\int_0^1\int_0^\infty e^tt^{s_1+s_2-1}u^{s_1-1}(1-u)^{s_2-1}\,dtdu.\]
	This still absolutely converges (indeed, we can just change coordinates back to $dt_1dt_2$ to see this), so a last application of Fubini's theorem reveals
	\[\Gamma(s_1)\Gamma(s_2)=\left(\int_0^1u^{s_1-1}(1-u)^{s_2-1}\,du\right)\left(\int_0^1e^tt^{s_1+s_2-1}\,dt\right)=\Gamma(s_1+s_2)\int_0^1u^{s_1-1}(1-u)^{s_2-1}\,du,\]
	which is what we wanted.
\end{proof}
\begin{remark}
	Because $\Gamma(1)=1$ and $\int_0^1u^s\,du=\frac1s$ for $\op{Re}s>0$, we see \Cref{lem:add-gamma} implies
	\[\Gamma(s)=\Gamma(s)\Gamma(1)=\Gamma(s+1)\int_0^1u^s\,du=\frac1s\Gamma(s+1),\]
	thus recovering \Cref{lem:ind-continue-gamma}.
\end{remark}
\begin{proposition}[Functional equation for $\Gamma$] \label{prop:gamma-func-eq}
	For any $s$ with $0<\op{Re}s<1$, we have
	\[\Gamma(s)\Gamma(1-s)=\frac\pi{\sin(\pi s)}.\]
\end{proposition}
\begin{proof}
	By \Cref{lem:add-gamma}, we see
	\[\Gamma(s)\Gamma(1-s)=\Gamma(1)\int_0^1u^{s-1}(1-u)^{-s}\,du=\int_0^1(1-u)\left(\frac u{1-u}\right)^{s-1}\,du.\]
	As such, we have reduced to compute some integral. This is done via contour integration. Thus, we set $t\coloneqq\frac u{1-u}=\frac1{1-u}-1$ so that $u=\frac t{t+1}$ and $dt=\frac1{(1-u)^2}\,du=(1+t)^2\,du$, which gives
	\[\Gamma(s)\Gamma(1-s)=\int_0^\infty\frac{t^{s-1}}{1+t}\,dt.\]
	We are now ready to use contour integration. Being careful, the function $t\mapsto t^{s-1}$ is given a meromorphic continuation to $\CC\setminus\RR_{\ge0}$ by $t\mapsto\exp((s-1)\log t)$, where $\log t$ has a branch cut at $\RR_{\ge0}$; explicitly, $\op{Im}(\log t)\in[0,2\pi)$. Now, for fixed $R,\varepsilon$ with $R>1>\varepsilon>0$, draw the following contour $\gamma$, split into four pieces.
	\begin{center}
		\begin{asy}
			unitsize(1.5cm);
			real R=1.7;
			real x=2.0;
			draw((-x,0)--(x,0), arrow=EndArrow);
			draw((0,-x)--(0,x), arrow=EndArrow);
			real theta = 180*asin(1/(R*R))/3.1415;
			draw(arc((0,0),R,theta,180), arrow=EndArrow, p=red);
			draw(arc((0,0),R,180,360-theta), arrow=EndArrow, p=red);
			draw(arc((0,0),1/R,90,270), arrow=BeginArrow, p=red);
			draw((0,1/R)--R*dir(theta), arrow=EndArrow, p=blue);
			draw((0,-1/R)--R*dir(-theta), arrow=BeginArrow, p=blue);
			draw((0,0)--R*dir(135));
			label("$R$", (R/2+0.1)*dir(135), dir(45));
			draw((R/2,0)--(R/2,1/R));
			label("$\varepsilon$", (R/2,0.5/R), E);
			label("$\gamma_1$", (R*cos(3.1415*theta/180)/2,1/R), N, blue);
			label("$\gamma_3$", (R*cos(3.1415*theta/180)/2,-1/R), N, blue);
			label("$\gamma_2$", R*dir(225), dir(225), red);
			label("$\gamma_4$", dir(225)/R, dir(225), red);
		\end{asy}
	\end{center}
	Notably, the function $f(z)\coloneqq z^{s-1}/(1+z)$ is meromorphic on $\CC\setminus\RR_{\ge0}$ with a single simple pole at $z=-1$, with residue $(-1)^{s-1}=e^{\pi i(s-1)}$. Thus, the Residue theorem yields
	\[\frac1{2\pi i}\oint_\gamma f(z)\,dz=e^{\pi i(s-1)}=-e^{\pi is}\]
	because $z=-1$ lies within the interior of $\gamma$. We now compute the integral $\oint_\gamma f(z)\,dz$ on each of the $\gamma_i$ independently.
	\begin{itemize}
		\item For $i\in\{1,3\}$, we compute
		\[\int_{\gamma_i}f(z)\,dz=\int_0^R\frac{\lambda_i(t\pm\varepsilon i)^{s-1}}{1+(t\pm\varepsilon i)}\,(\pm dt),\]
		where $\lambda_i=1$ (and we use $+$) if $i=1$, and $\lambda_i=e^{2\pi i(s-1)}=e^{2\pi is}$ (and we use $-$) if $i=3$. Now, for each $\varepsilon\in(0,1)$, we see
		\[\left|\frac{(t\pm\varepsilon i)^{s-1}}{1+(t+\varepsilon i)}\right|\le\frac{(t+1)^{\op{Re}s-1}}{1+t},\]
		and the right-hand function has finite integral over $[0,R]$ because $\op{Re}s>0$. Thus, we may apply the Dominated convergence theorem to see that sending $\varepsilon\to0^+$ tells us that
		\[\lim_{R\to\infty}\lim_{\varepsilon\to0^+}\int_{\gamma_i}f(z)\,dz=\lim_{R\to\infty}\pm\lambda_i\int_0^R\frac{t^{s-1}}{1+t}\,dt=\pm\lambda_i\int_0^\infty\frac{t^{s-1}}{1+t}\,dt.\]
		\item On $\gamma_2$, we bound
		\[\left|\int_{\gamma_2}f(z)\,dz\right|\le2\pi R\cdot\max_{z\in\im\gamma_2}|f(z)|.\]
		To compute this maximum, we use the fact that $|z|=R>1$ to see
		\[\left|\frac{z^{s-1}}{1+z}\right|\le\frac{R^{\op{Re}s-1}}{R-1},\]
		so
		\[\left|\int_{\gamma_2}f(z)\,dz\right|\le\frac{2\pi R^{\op{Re}s}}{R-1}=\frac{2\pi R^{\op{Re}s-1}}{1-1/R}.\]
		Sending $R\to\infty$ has this integral go to $0/1$ because $\op{Re}s<1$.
		\item On $\gamma_4$, we bound
		\[\left|\int_{\gamma_4}f(z)\,dz\right|\le\pi\varepsilon\cdot\max_{z\in\im\gamma_t}|f(z)|.\]
		To compute this maximum, we use the fact that $|z|=\varepsilon<1$ to see
		\[\left|\frac{z^{s-1}}{1+z}\right|\le\frac{\varepsilon^{\op{Re}s-1}}{1-\varepsilon},\]
		so
		\[\left|\int_{\gamma_4}f(z)\,dz\right|\le\frac{\pi\varepsilon^{\op{Re}s}}{1-\varepsilon}.\]
		Sending $\varepsilon\to0^+$ has this integral go to $0/1$ because $\op{Re}s>0$.
	\end{itemize}
	Combining the above integrals, we see
	\[-2\pi ie^{\pi is}=\oint_\gamma f(z)\,dz=\left(1-e^{2\pi is}\right)\int_0^\infty\frac{t^{s-1}}{1+t}\,dt\]
	upon sending $\varepsilon\to0^+$ and then $R\to\infty$. Rearranging,
	\[\Gamma(s)\Gamma(1-s)=\int_0^\infty\frac{t^{s-1}}{1+t}\,dt=\frac{-2\pi ie^{\pi is}}{1-e^{2\pi is}}=\frac\pi{\left(e^{-\pi is}-e^{\pi is}\right)/(2i)}=\frac\pi{\sin(\pi s)},\]
	which is what we wanted.
\end{proof}
\begin{example} \label{ex:gamma-half}
	Plugging in $s=1/2$ into \Cref{prop:gamma-func-eq}, we see $\Gamma(1/2)^2=\pi$. However, the definition of $\Gamma$ surely has $\Gamma(1/2)>0$, so we must have $\Gamma(1/2)=\sqrt\pi$.
\end{example}
\begin{corollary} \label{cor:continue-gamma}
	The function $\Gamma$ has a meromorphic continuation to all $\CC$, and $\Gamma$ has no zeroes. The only poles are simple poles occurring at all nonpositive integers, and the residue of the pole at $-n$ is $(-1)^n/n!$ for each positive integer $n$.
\end{corollary}
\begin{proof}
	For completeness, we use the functional equation to produce an analytic continuation. Let $Z$ be the zeroes of $\Gamma$ in $\{s:\op{Re}s>0\}$, which we know is an isolated set because $\Gamma$ is a nonconstant holomorphic function. Now, define $U\coloneqq\CC\setminus(\ZZ_{\le0}\cup\{s:1-s\in Z\})$, and define a function $U\to\CC$ by
	\[s\mapsto\begin{cases}
		\Gamma(s) & \text{if }\op{Re}s>0, \\
		\pi/(\Gamma(1-s)\sin(\pi s)) & \text{if }\op{Re}s<1.
	\end{cases}\]
	Note \Cref{prop:gamma-func-eq} tells us that this function is well-defined on the overlapping region $\{s:0<\op{Re}s<1\}$. Thus, gluing these meromorphic functions together, we define a single meromorphic function $\Gamma\colon U\to\CC$.

	It remains to show the other listed properties of $\Gamma$. Note that $\Gamma(s+1)=s\Gamma(s)$ holds on $\{s:\op{Re}s>0\}$ and hence everywhere by analytic continuation. Thus, for the residue computation, we fix some nonnegative integer $n$ and write
	\[\lim_{s\to0}s\Gamma(s-n)=\lim_{s\to0}\frac{s\Gamma(s-n+1)}{(s-n)}=\cdots=\lim_{s\to0}\frac{s\Gamma(s+1)}{(s-n)(s-n+1)\cdots(s-1)(s)}=\frac{\Gamma(1)}{(-1)^nn!}.\]
	Thus, $\Gamma$ has a pole of residue $(-1)^n/n!$ at $-n$ for each nonnegative integer $n$.
	
	Lastly, we show that $\Gamma$ has no zeroes. Note $\Gamma$ has no zeroes on the positive integers by \Cref{ex:gamma-on-positive-integers}, and $\Gamma$ isn't even defined on the nonpositive integers, so $\Gamma$ has no zeroes on $\ZZ$. Additionally, we note that we surely have an analytic continuation of $\Gamma$ by $\CC\setminus\ZZ_{\le0}$ by \Cref{rem:ind-continue-gamma}. Thus, we see each $s\in\CC\setminus\ZZ_{\le0}$ has $1-s\in\CC\setminus\ZZ_{\le0}$, thus giving
	\[\Gamma(s)\Gamma(1-s)=\frac\pi{\sin(\pi s)}\ne0,\]
	which forces $\Gamma(s)\ne0$. (Note this functional equation extends from $\{s:0<\op{Re}s<1\}$ to all $\CC\setminus\ZZ$ by uniqueness of analytic continuation.)
\end{proof}
\begin{remark} \label{rem:recip-gamma-entire}
	\Cref{cor:continue-gamma} tells us that $1/\Gamma(s)$ is an entire function. Indeed, the poles of $\Gamma$ becomes $0$s, and $\Gamma$ has no zeroes to become poles! Notably, \Cref{cor:continue-gamma} tells us that $1/\Gamma(s)$ is entire with only simple zeroes at the nonpositive integers $n$.
\end{remark}
While we're here, we give another application of \Cref{lem:add-gamma}.
\begin{proposition} \label{prop:duplicate-gamma}
	For any $s\in\CC\setminus\ZZ_{\le0}$, we have
	\[\Gamma\left(\frac s2\right)\Gamma\left(\frac{s+1}2\right)=\sqrt\pi2^{1-s}\Gamma(s).\]
\end{proposition}
\begin{proof}
	By the uniqueness of analytic continuation, it suffices to show this for $0<\op{Re}s<1$. Now \Cref{lem:add-gamma} lets us write
	\begin{align*}
		\frac{\Gamma\left(\frac s2\right)\Gamma\left(\frac s2\right)}{\Gamma(s)} &= \int_0^1u^{s-1}(1-u)^{s-1}\,du \\
		&= \int_{-1}^1\left(\frac{1+t}2\right)^{s/2-1}\left(\frac{1-t}2\right)^{s/2-1}\,\frac{dt}2 \\
		&= \frac1{2^{s-1}}\int_{-1}^1\left(1-t^2\right)^{s/2-1}\,dt \\
		&= \frac1{2^s}\int_0^1\left(1-t^2\right)^{s/2-1}\,dt \\
		&= \frac1{2^{s-1}}\int_0^1u^{1/2-1}(1-u)^{s/2-1}\,dt \\
		&= \frac1{2^{s-1}}\cdot\frac{\Gamma\left(\frac12\right)\Gamma\left(\frac s2\right)}{\Gamma\left(\frac{s+1}2\right)}.
	\end{align*}
	By \Cref{cor:continue-gamma}, $\Gamma(s/2)\ne0$ for all $s$, so we may rearrange the above into
	\[\Gamma\left(\frac s2\right)\Gamma\left(\frac{s+1}2\right)=\Gamma\left(\frac12\right)2^{1-s}\Gamma(s).\]
	Plugging in $\Gamma(1/2)=\sqrt\pi$ from \Cref{ex:gamma-half} completes the proof.
\end{proof}

\subsection{Bounds on \texorpdfstring{$\Gamma$}{ Gamma}}
While $\Gamma$ is still fresh in our mind, we will prove a few bounds about it. We continue to roughly follow \cite{tao-gamma-function}. From \Cref{thm:hadamard}, we know that a lower bound on $\Gamma$ will produce an upper bound on $1/\Gamma$ and thus a factorization of $1/\Gamma$. However, it will be convenient to actually provide this factorization first and then use it to produce bounds.
\begin{proposition} \label{prop:hadamard-gamma}
	For any $s\in\CC$, we have
	\[\frac1{\Gamma(s)}=se^{\gamma s}\prod_{n=-1}^{-\infty}E_1(s/n).\]
	Here, $\gamma$ is the Euler--Mascheroni constant, and $E_1(z)=(1-z)e^z$. In fact, this product converges absolutely and uniformly.
\end{proposition}
\begin{proof}
	The infinite product converges absolutely and uniformly to an entire function by \Cref{lem:elem-factor-prod-lower-bound}. Indeed, we see that
	\[\#\{k:-k<r\}=\floor r+1<r+1\ll r^{1+\varepsilon}\]
	for any $\varepsilon>0$. (Formally, note $(r+1)r^{-1-\varepsilon}\to0$ as $r\to\infty$, so this continuous function is bounded.) So indeed, we have all the correct convergence.

	It follows from the uniqueness of analytic continuation that we can just check the identity for $s\in\RR_{>0}$. Quickly, we remove the $\gamma$ term by writing
	\begin{align*}
		se^{\gamma s}\prod_{n=-1}^{-\infty}E_1(s/n) &= \lim_{n\to\infty}se^{\sum_{k=1}^ns/k-s\log n}\prod_{k=1}^n(1+s/k)e^{-s/k} \\
		&= \lim_{n\to\infty}sn^{-s}\prod_{k=1}^n(1+s/k) \\
		&= \lim_{n\to\infty}\frac{s(s+1)\cdots(s+n)}{n^sn!}.
	\end{align*}
	Thus, it suffices to show that
	\[\Gamma(s)\stackrel?=\lim_{n\to\infty}\frac{n^sn!}{s(s+1)\cdots(s+n)}.\]
	Using the functional equation $\Gamma(s+1)=s\Gamma(s)$ from \Cref{lem:ind-continue-gamma} inductively tells us that $\Gamma(n+1)=n!$ and $\Gamma(s+n+1)=(s+n)\cdots(s+1)s\Gamma(s)$, so we see
	\[\lim_{n\to\infty}\frac{n^sn!}{s(s+1)\cdots(s+n)}=\lim_{n\to\infty}\left(n^s\cdot\frac{\Gamma(s)\Gamma(n+1)}{\Gamma(s+n+1)}\right).\]
	Now using \Cref{lem:add-gamma}, this is
	\begin{align*}
		\lim_{n\to\infty}n^s\cdot\frac{\Gamma(s)\Gamma(n+1)}{\Gamma(s+n+1)} &= \lim_{n\to\infty}n^s\int_0^1t^{s-1}(1-t)^n\,dt \\
		&= \lim_{n\to\infty}\int_0^1(nt)^{s-1}(1-t)^n\,ndt \\
		&= \lim_{n\to\infty}\int_0^nt^{s-1}\left(1-\frac tn\right)^n\,dt.
	\end{align*}
	We would like to use the Dominated convergence to compute this limit of integrals as $\Gamma(s)$. As such, we for each $n$, define
	\[f_n(t)\coloneqq t^{s-1}\left(1-\frac tn\right)^n1_{\le n}(t).\]
	We would like to use the Dominated convergence theorem on the $f_n$. Well, for $t\ge n$, we see $f_n(t)=0$, and for $t<n$, we see
	\[\log f_n(t)=(s-1)\log t+n\log\left(1-\frac tn\right)\stackrel*\le(s-1)\log t+n\left(1-\frac tn\right)=(s-1)\log t-t,\]
	where $\stackrel*\le$ holds by using the power series $-\log(1-x)=x+\frac{x^2}2+\frac{x^3}3+\cdots$. Thus, $f_n(t)\le t^{s-1}e^{-t}$, which has a finite integral over $(0,\infty)$ bounded by $\Gamma(s)$. Thus, by the Dominated convergence theorem, we see
	\[\lim_{n\to\infty}\int_0^\infty f_n(t)\,dt=\int_0^\infty\left(\lim_{n\to\infty}f_n(t)\right)\,dt=\int_0^\infty t^{s-1}e^{-t}\,dt=\Gamma(s),\]
	where we have used the fact that $\left(1-\frac tn\right)^n\to e^{-t}$ as $n\to\infty$. (This also can be seen by taking logs and bounding the error term.) This completes the proof.
\end{proof}
\begin{corollary} \label{cor:bound-log-gamma-deriv}
	For $s\in\CC\setminus\ZZ_{\le0}$, we have
	\[\frac{\Gamma'(s)}{\Gamma(s)}=\lim_{n\to\infty}\Bigg(\log n-\sum_{k=0}^n\frac1{s+k}\Bigg).\]
\end{corollary}
\begin{proof}
	Note that the product of \Cref{prop:hadamard-gamma} converges absolutely and uniformly. Thus, \Cref{cor:deriv-inf-prod} applies and tells us that
	\[-\frac{\Gamma'(s)}{\Gamma(s)}=\frac{(1/\Gamma)'(s)}{(1/\Gamma)(s)}=\underbrace{\frac1s}_s+\underbrace{\gamma}_{e^{\gamma s}}+\sum_{k=-1}^{-\infty}\underbrace{\frac1k\cdot\frac{E_1'(s/k)}{E_1(s/k)}}_{E_1(s/k)}\]
	wherever $1/\Gamma(s)\ne0$, which is exactly $s\in\CC\setminus\ZZ_{\le0}$ by \Cref{rem:recip-gamma-entire}. Now, we see
	\[\frac{E_1'(z)}{E_1(z)}=\frac{1}{z-1}+1,\]
	so
	\[\frac{\Gamma'(s)}{\Gamma'(s)}=-\frac1s-\gamma+\sum_{k=-1}^{-\infty}\left(\frac1{-k}-\frac1{s-k}\right)=-\frac1s-\gamma+\sum_{k=1}^{\infty}\left(\frac1{k}-\frac1{s+k}\right),\]
	where we must be very careful about signs. To finish, we use the definition of $\gamma$ to write
	\[\frac{\Gamma'(s)}{\Gamma(s)}=\lim_{n\to\infty}\Bigg(-\frac1s+\log n-\sum_{k=1}^{n}\frac1k+\sum_{k=1}^n\left(\frac1{k}-\frac1{s+k}\right)\Bigg)=\lim_{n\to\infty}\Bigg(\log n-\sum_{k=0}^n\frac1{s+k}\Bigg),\]
	which is what we wanted.
\end{proof}
Thus, to estimate $\Gamma'/\Gamma$, we want to know about the rate of growth of harmonic numbers. It turns out that Abel summation is not quite good enough for our purposes, so we will have to integrate by parts one more time.
\begin{lemma}[Trapezoid rule] \label{lem:trapezoid}
	Fix a continuously twice-differentiable function $f\colon[m,n]\to\CC$, where $m<n$ are integers. Then
	\[\sum_{k=m}^nf(k)=\int_m^nf(t)\,dt+\frac{f(m)+f(n)}2+O\left(\int_m^n|f''(t)|\,dt\right).\]
\end{lemma}
\begin{proof}
	This is integration by parts twice. Indeed, we see
	\begin{align*}
		\int_m^nf(t)\,dt &= \sum_{k=m}^{n-1}\int_k^{k+1}f(t)\,dt \\
		&= \sum_{k=m}^{n-1}\left(\frac12f(k+1)--\frac12f(k)-\int_k^{k+1}\left(t-n-\frac12\right)f'(t)\,dt\right) \\
		&= \sum_{k=m}^{n-1}\left(\frac{f(k+1)+f(k)}2-\int_k^{k+1}\left(t-n-\frac12\right)f'(t)\,dt\right) \\
		&= \sum_{k=m}^{n-1}\Bigg(\frac{f(k+1)+f(k)}2-\left(\frac12\left(n+1-n-\frac12\right)^2-\frac18\right)f'(n+1) \\
		&\qquad+\left(\frac12\left(n-n-\frac12\right)^2-\frac18\right)f'(n)+\int_k^{k+1}\left(\frac12\left(t-n-\frac12\right)^2-\frac18\right)f''(t)\,dt\Bigg) \\
		&= \sum_{k=m}^{n-1}\Bigg(\frac{f(k+1)+f(k)}2+\frac12\int_k^{k+1}\left(\{t\}^2-\{t\}\right)f''(t)\,dt\Bigg) \\
		&= \sum_{k=m}^nf(k)-\frac{f(m)+f(n)}2+\frac12\int_m^n\left(\{t\}^2-\{t\}\right)f''(t)\,dt.
	\end{align*}
	Rearranging the above equality finishes upon noting that the function $\frac{\{t\}^2-\{t\}}2$ has a maximum (for example, it is bounded in magnitude by $\frac{1+1}2=1$).
\end{proof}
And here is our estimate.
\begin{proposition} \label{prop:bound-digamma}
	Fix $\varepsilon\in(0,\pi)$. For $s\in\{z\in\CC:|\arg z|<\pi-\varepsilon\}$, we have
	\[\frac{\Gamma'(s)}{\Gamma(s)}=\log s-\frac1{2s}+O_\varepsilon\left(1/|s|^2\right).\]
\end{proposition}
\begin{proof}
	We use \Cref{cor:bound-log-gamma-deriv}. Using \Cref{lem:trapezoid}, we set $f(t)\coloneqq1/(s+t)$ so that
	\begin{align*}
		\sum_{k=0}^n\frac1{s+k} &= \int_0^n\frac1{s+t}\,dt+\frac{f(0)+f(n)}2+O\left(\int_0^n\frac2{|s+t|^3}\,dt\right) \\
		&= \log(n+s)-\log s+\frac1{2s}+\frac1{2(n+s)}+O\left(\int_0^n\frac2{|s+t|^3}\,dt\right).
	\end{align*}
	We would like for the integral to be $O_\varepsilon\left(1/|s|^2\right)$ as $n\to\infty$. We have two cases.
	\begin{itemize}
		\item If $\op{Re}s\ge0$, then $|s+t|\ge\op{Re}(s+t)\ge t$ and $|s+t|\ge|s|$ for each $t\ge0$, so we can easily upper-bound
		\begin{align*}
			\int_0^n\frac2{|s+t|^3}\,dt &\le \int_0^1\frac2{|s+t|^3}\,dt+\int_1^\infty\frac2{|s+t|^3}\,dt\\
			&\le \int_0^1\frac2{|s|^3}\,dt+\int_1^\infty\frac2{|t|^3}\,dt\\
			&= \frac2{|s|^3}+\left(-\frac1{t^2}\bigg|_{1}^\infty\right) \\
			&= \frac2{|s|^3}-1,
		\end{align*}
		which is in fact $O\left(1/|s|^2\right)$.

		\item If $\op{Re}s<0$, then we note $\op{Im}s>0$ because $\arg z\ne\pi$. Here the bounding is harder; take $n>2|s|$ for convenience. For large values of $t$, we note $t\ge2|s|$ will make $|s+t|\ge t-|s|$ fairly large, so
		\[\int_{2|s|}^n\frac2{|s+t|^3}\,dt\le\int_{2|s|}^\infty\frac2{(t-|s|)^3}\,dt=-\frac1{(t-|s|)^2}\bigg|_{2|s|}^\infty=\frac1{|s|^2},\]
		which is $O\left(1/|s|^2\right)$.
		
		Now, the interval $t\in[0,2|s|]$ is more difficult to handle. Because $t$ is real, we note that $|s+t|=\sqrt{(t+\op{Re}s)^2+(\op{Im}s)^2}\ge|\op{Im}s|$, which is perhaps the best we can do because $s+t$ can have arbitrarily small real part in this interval. However, letting $\theta\coloneqq\arg z$, we note that
		\[\frac{\op{Im}s}{|s|}=|\sin\theta|\ge\sin(\pi-\varepsilon)\]
		by assumption on $\arg s$. Thus,
		\[\int_0^{2|s|}\frac2{|s+t|^3}\,dt\le\int_0^{2|s|}\frac2{|\op{Im}s|^3}\,dt=2|s|\cdot\frac2{|\op{Im}s|^3}\le4|\sin(\pi-\varepsilon)|^3\cdot\frac1{|s|^2},\]
		which is still $O_\varepsilon\left(1/|s|^2\right)$, so we are safe. Totaling our integrals finishes.
	\end{itemize}
	In total, we see that
	\[\sum_{k=0}^n\frac1{s+k}=\log(n+s)-\log s+\frac1{2s}+\frac1{2(n+s)}+O_\varepsilon\left(1/|s|^2\right).\]
	Thus, by \Cref{cor:bound-log-gamma-deriv}, we see
	\begin{align*}
		\frac{\Gamma'(s)}{\Gamma(s)} &= \lim_{n\to\infty}\Bigg(\log n-\sum_{k=0}^n\frac1{s+k}\Bigg) \\
		&= \lim_{n\to\infty}\left(\log n-\log(n+s)+\log s-\frac1{2s}-\frac1{2(n+s)}+O_\varepsilon\left(1/|s|^2\right)\right) \\
		&= \log s-\frac1{2s}+\lim_{n\to\infty}\left(\log\left(1-\frac s{n+s}\right)-\frac1{2(n+s)}\right)+O_\varepsilon\left(1/|s|^2\right) \\
		&= \log s-\frac1{2s}+O_\varepsilon\left(1/|s|^2\right),
	\end{align*}
	which is what we wanted.
\end{proof}
Taking the integral of this allows us to recover a version of Stirling's approximation.
\begin{proposition}[Stirling's approximation] \label{prop:stirling}
	Fix $\varepsilon\in(0,\pi/2)$. For $s\in\{z\in\CC:|\arg z|<\pi-\varepsilon\}$, we have
	\[\log\Gamma(s)=\left(s-\frac12\right)\log s-s+\frac12\log2\pi+O_\varepsilon(1/|s|).\]
\end{proposition}
\begin{proof}
	Set $\Omega_\varepsilon\coloneqq\{z\in\CC:|\arg z|<\pi-\varepsilon\}$; note that $\Omega_\varepsilon$ is convex because (roughly speaking) any complex nonzero complex number on the line segment connecting two nonzero complex numbers $\alpha,\beta$ will have argument between the two arguments of $\alpha$ and $\beta$. Anyway, we proceed in steps.
	\begin{enumerate}
		\item The function $\Gamma$ is holomorphic on $\Omega_\varepsilon$ and does not vanish there by \Cref{rem:recip-gamma-entire}, so \Cref{lem:no-vanish-has-log} grants us a logarithm. In fact, using \Cref{rem:explicit-log} to get our explicit logarithm, we see
		\[\log\Gamma(s)=\underbrace{\log\Gamma(1)}_0+\int_1^s\frac{\Gamma'(z)}{\Gamma(z)}\,dz,\]
		where the integral here is along the straight line from $1$ to $s$ (which does live in $\Omega_\varepsilon$ because $\Omega_\varepsilon$ is convex). Thus, we see we do in fact want to integrate the bound given by \Cref{prop:bound-digamma}.

		\item Being a little careful, we set
		\[E_\varepsilon(s)\coloneqq\frac{\Gamma'(s)}{\Gamma(s)}-\log s+\frac1{2s}.\]
		Notably, $E_\varepsilon$ is holomorphic on $\Omega_\varepsilon$ because the right-hand side here is holomorphic on $\Omega_\varepsilon$ (for suitably chosen $\log$), so $E_\varepsilon$ is in particular integrable. Additionally, we note that $|E_\varepsilon(s)|\le C_\varepsilon/|s|^2$ for some constant $C_\varepsilon$ and $|s|$ large enough. Thus, fixing $s$ and some large $N>|s|$, we compute for $|s|$ large enough that
		\[\int_1^sE_\varepsilon(z)\,dz = \int_1^NE_\varepsilon(z)\,dz-\int_s^NE_\varepsilon(z)\,dz.\]
		The left integral here converges absolutely as $N\to\infty$ because
		\[\int_1^\infty|E_\varepsilon(z)|\,dz\le C_\varepsilon\int_1^\infty\frac1{z^2}\,dz=C_\varepsilon.\]
		We would like to show that the right integral is $O_\varepsilon(1/|s|)$. However, if $s$ is close to the negative real axis, there are potentially large contributions of the integral when $z$ is roughly $0$, so we change our path.
		
		Instead of using the straight line from $s$ to $N$, we follow the arc of a circle with center at $z=0$ and radius $|s|$ until we hit the positive real axis (moving clockwise if $\op{Re}s>0$ and counterclockwise otherwise); then we move along the positive real axis from $|s|$ to $N$. Letting $\gamma$ denote this arc, we see
		\begin{align*}
			\left|\int_s^NE_\varepsilon(z)\,dz\right|&\le\left|\int_\gamma E_\varepsilon(z)\,dz\right|+\left|\int_{|s|}^NE_\varepsilon(z)\,dz\right| \\
			&\le \ell(\gamma)\cdot\max_{z\in\im\gamma}\{|E_\varepsilon(z)|\}+\int_{|s|}^N|E_\varepsilon(z)|\,dz \\
			&\le \pi|s|\cdot\frac{C_\varepsilon}{|s|^2}+C_\varepsilon\int_{|s|}^N\frac1{z^2}\,dz \\
			&= \frac{C_\varepsilon\pi}{|s|}+\frac{C_\varepsilon}{|s|}-\frac{C_\varepsilon}N.
		\end{align*}
		In total, we see
		\[\int_1^sE_\varepsilon(z)\,dz=\int_1^NE_\varepsilon(z)\,dz+O\left(\frac{C_\varepsilon\pi}{|s|}+\frac{C_\varepsilon}{|s|}-\frac{C_\varepsilon}N\right).\]
		Sending $N\to\infty$ shows that this is
		\[\int_1^sE_\varepsilon(z)\,dz=\underbrace{\int_1^\infty E_\varepsilon(z)\,dz}_{C\coloneqq}{}+{}O_\varepsilon(1/|s|),\]
		which is good enough for our purposes.

		\item Integrating over $E_\varepsilon$, we see
		\begin{align*}
			\log\Gamma(s) &= \int_1^s\frac{\Gamma'(z)}{\Gamma(z)}\,dz \\
			&= \int_1^s\left(\log z-\frac1{2z}\right)\,dz+\int_1^sE_\varepsilon(z)\,dz \\
			&= s\log s-s-\frac12\log s+C+O_\varepsilon(1/|s|) \\
			&= \left(s-\frac12\right)\log s-s+C+O_\varepsilon(1/|s|)
		\end{align*}
		for some constant $C$ chosen above.
		
		\item It remains to show $C=\frac12\log2\pi$. For this, we use \Cref{prop:gamma-func-eq}. We restrict our attention to $\Omega'_\varepsilon\coloneqq\{z\in\CC:\varepsilon<|\arg z|<\pi-\varepsilon\}$. For $t>0$, set $s\coloneqq\frac12+it$; notably, $s,1-s\in\Omega_\varepsilon$ for $t>\frac12$ because this gives $\arg s,\arg(1-s)\in(-\pi/2,\pi/2)$. Also, $|s|=|1-s|\ge t$. Thus, on one hand, we can use our bound above to show
		\begin{align*}
			\log\Gamma(s)\Gamma(1-s) &= \log\Gamma(s)+\log\Gamma(1-s) \\
			&= it\log\left(\frac12+it\right)-\left(\frac12+it\right)+C-it\log\left(\frac12-it\right)-\left(\frac12-it\right)+C+O_\varepsilon(1/|t|) \\
			&= 2C+it\log\left(\frac{1/(2t)+i}{1/(2t)-i}\right)-1+O_\varepsilon(1/|t|).
		\end{align*}
		We are going to need to understand the log term here more carefully. Choosing a suitable branch of $\log$ (say, now away from the positive reals), we write $x\coloneqq1/t$ so that we are interested in the behavior of the holomorphic function $f(x)\coloneqq\log\left(\frac{x/2+i}{x/2-i}\right)$ at $x=0$. Notably, $f(0)=\log(-1)=\pi i$ (for some choice of branch of $\log$). Additionally, we see
		\[f'(x)=\frac{1/2}{x/2+i}-\frac{1/2}{x/2-i}\]
		yields $f'(0)=-i$. Thus, our power series for $f$ is given by $f(x)=\pi i-it+\cdots$,
		so
		\[\lim_{t\to\infty}\left(\pi t+it\log\left(\frac{1/(2t)+it}{1/(2t)-i}\right)\right)=\lim_{x\to0}\frac{if(x)+\pi}x=1.\]
		On the other hand, we see
		\begin{align*}
			\log\left(\frac\pi{\sin(\pi s)}\right) &= \log\pi-\log\sin\left(\frac\pi2+\pi it\right) \\
			&= \log\pi-\log\left(\frac{e^{i\pi/2-\pi t}-e^{-i\pi/2+\pi t}}{2i}\right) \\
			&= \log\pi-\log\left(\frac{e^{\pi t}+e^{-\pi t}}{2}\right) \\
			&= -\pi t+\log2\pi-\log\left(1+e^{-2\pi t}\right),
		\end{align*}
		up to multiples of $2\pi i$, so
		\[2C+it\log\left(\frac{1/(2t)+i}{1/(2t)-i}\right)-1+O_\varepsilon(1/|t|)=-\pi t+\log2\pi-\log\left(1+e^{-2\pi t}\right).\]
		Quickly, we rearrange this to
		\[2C+\left(\pi t+it\log\left(\frac{1/(2t)+i}{1/(2t)-i}\right)-1\right)+O_\varepsilon(1/|t|)=\log2\pi-\log\left(1+e^{-2\pi t}\right).\]
		Thus, sending $t\to\infty$ makes almost all terms vanish, leaving us with $C=\frac12\log2\pi$ (up to a multiple of $2\pi i$). This completes the proof.
		\qedhere
	\end{enumerate}
\end{proof}
\begin{corollary}
	Fix real numbers $a<b$. For any $\sigma\in[a,b]$, we have
	\[|\Gamma(\sigma+it)|\sim_{a,b}\sqrt{2\pi}e^{-\pi|t|/2}|t|^{\sigma-1/2}\]
	as $|t|\to\infty$.
\end{corollary}
\begin{proof}
	For psychological reasons, we quickly reduce to the case where $t>0$. By definition of $\Gamma$, we see that $\Gamma(s)\in\RR$ if $s\in\RR_{>0}$, so $\Gamma(s)=\overline{\Gamma(\overline s)}$. However, these are both holomorphic functions, so the uniqueness of analytic continuation enforces
	\[|\Gamma(\sigma+it)|=|\overline{\Gamma(\sigma+it)}|=|\Gamma(\overline{\sigma+it})|=|\Gamma(\sigma-it)|.\]
	Thus, adjusting for the sign appropriately, we may assume $t>0$ in the argument which follows.

	Now, this bound is an application of \Cref{prop:stirling}. Set $\varepsilon\coloneqq\pi/4$ and assume that $t>\max\{|a|,|b|\}$ throughout so that $\arg s\in(\pi/4,3\pi/4)$. Thus, noting $|s|\ge t$, we get the estimate
	\begin{align*}
		\log\Gamma(\sigma+it) &= \left(\sigma+it-\frac12\right)\log(\sigma+it)-(\sigma+it)+\frac12\log2\pi+O(1/t) \\
		&= \left(\sigma-\frac12\right)\log t+it\log\left(\frac\sigma t+i\right)-\sigma+\frac12\log2\pi\\
		&\qquad+\left(\sigma-\frac12\right)\log\left(\frac\sigma t+i\right)+it(\log t-1)+O(1/t).
	\end{align*}
	Because we want $|\Gamma(\sigma+it)|=\exp(\op{Re}\log\Gamma(\sigma+it))$, we are primarily interested in the real part of the above expression. Notably, $\log\left(\frac\sigma t+i\right)\to\log i=\pi i/2$ as $t\to\infty$, so this term contributes no real part. Similarly, $it(\log t-1)$ is purely imaginary and doesn't matter.

	The hardest term left to understand is $it\log\left(\frac\sigma t+i\right)$. Well, set $x\coloneqq1/t$ and $f(x)\coloneqq\log(\sigma x+i)$, and we want to understand the behavior of $f$ around $x=0$. Notably, for suitably chosen $\log$, we are holomorphic at $x=0$ with $f(0)=\log i=i\pi/2$ and $f'(0)=\frac\sigma{\sigma\cdot0+i}=-\sigma i$. Thus,
	\[\lim_{t\to\infty}\left(it\log\left(\frac\sigma t+i\right)-\sigma+\frac\pi2t\right)=\lim_{x\to0}\frac{if(x)+\frac\pi2-\sigma x}{x}=0,\]
	so in total,
	\[\lim_{t\to\infty}\log\left|\frac{\Gamma(\sigma+it)}{\sqrt{2\pi}e^{-\pi t/2}t^{\sigma-1/2}}\right|=\lim_{t\to\infty}\left(\left(\sigma-\frac12\right)\log t-\log t^{\sigma-1/2}+it\log\left(\frac\sigma t+i\right)-\sigma+\frac\pi2t\right)=0.\]
	Taking $\exp$ of both sides completes the proof.
\end{proof}

\subsection{The Functional Equation}
We now return to discussing the functional equation for $\zeta$. Being concrete, we will want to fix a particular Schwarz function $f\colon\RR\to\RR$. Staring at \Cref{cor:abstract-func-eq}, we see that it will be helpful to have control over both $f$ and $\mc Ff$, so we will take $f(x)\coloneqq e^{-\pi x^2}$, even this of course does not satisfy all the hypotheses. The associated function $S_f$ has a name.
\begin{defihelper}[$\Gamma$] \nirindex{Gamma@$\Gamma$}
	Define the function $\Theta\colon(0,\infty)\to\RR$ by
	\[\Theta(t)\coloneqq\sum_{n\in\ZZ}e^{-\pi nt^2}.\]
\end{defihelper}
\begin{remark} \label{rem:theta-converges}
	Note that series defining $\Theta$ converges absolutely and uniformly on any interval $[\varepsilon,0)$ for $\varepsilon>0$ by the Weierstrass $M$-test: indeed, we may upper-bound
	\[\sum_{n\in\ZZ}e^{-\pi n^2t}\le1+2\sum_{n=1}^\infty e^{-\pi\varepsilon n^2}\le1+2\sum_{n=1}^\infty e^{-\pi\varepsilon n}=1+2\cdot\frac{e^{-\pi\varepsilon}}{1-e^{-\pi\varepsilon}}<\infty.\]
	In particular, the uniform convergence confirms that $\Theta$ defines a continuous function $(0,\infty)\to\RR$.
\end{remark}
The functional equation for $\zeta$ will come from the following functional equation for $\Theta$.
\begin{proposition} \label{prop:theta-func-eq}
	For any $t>0$, we have
	\[\Theta(t)=\frac1{\sqrt t}\Theta\left(\frac1t\right).\]
\end{proposition}
\begin{proof}
	For fixed $t>0$, define $f(x)\coloneqq e^{-\pi\left(\sqrt tx\right)^2}$, which is Schwarz by \Cref{lem:fourier-checks} and \Cref{exe:gaussian}; in particular, $(\mc Ff)(s)=\frac1{\sqrt t}f(s)$. Thus, \Cref{thm:ps} implies that $\Theta(t)$ converges absolutely, and
	\[\Theta(t)=\sum_{n\in\ZZ}e^{-\pi nt^2}=\sum_{n\in\ZZ}f(n)=\sum_{n\in\ZZ}(\mc Ff)(n)=\sum_{n\in\ZZ}\frac1{\sqrt t}e^{-\pi n/x^2}=\frac1{\sqrt t}\Theta\left(\frac1t\right),\]
	which is what we wanted.
\end{proof}
\begin{remark}
	For $z\in\HH$, set $q\coloneqq e^{2\pi iz}$ so that $|q|<1$. Then
	\[f(z)\coloneqq\sum_{n\in\ZZ}q^{n^2/2}=\sum_{n\in\ZZ}e^{\pi in^2z}\]
	converges absolutely and satisfies $f(it)=\Theta(t)$. One can check, for example using \Cref{prop:diff-under-sign}, that $f$ is holomorphic on $\HH$. In fact, $f$ is a modular form: note that $f(z+2)=f(z)$. Further, hitting \Cref{prop:theta-func-eq} with the uniqueness of analytic continuation, we see that $f(-1/z)=(z/i)^{1/2}f(z)$ for $z\in\HH$, for suitably defined square root. Thus, (with a growth condition we haven't mentioned) $f$ is a modular form of weight $1/2$ and level
	\[\left\langle\begin{bmatrix}
		1 & 2 \\
		0 & 1
	\end{bmatrix},\begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix}\right\rangle\subseteq\op{SL}_2(\ZZ).\]
\end{remark}
We next describe how $\zeta$ relates $\Theta$. This requires us to ``complete'' $\zeta$, as follows.
\begin{defihelper}[{$\xi$}] \nirindex{Xi@$\xi$}
	For $\op{Re}s>0$, we define
	\[\xi(s)\coloneqq\pi^{-s/2}\Gamma(s/2)\zeta(s).\]
	Similarly, we define $\Xi(s)\coloneqq s(1-s)\xi(s)$.
\end{defihelper}
\begin{remark}
	Note $\xi$ is meromorphic on $\{s:\op{Re}s>0\}$ with only a simple pole at $s=1$ because $s\mapsto\pi^{-s/2}\Gamma(s/2)$ is holomorphic here (see \Cref{rem:gamma-is-holo}), and $\zeta$ is meromorphic with only a simple pole at $s=1$ (see \Cref{prop:continue-zeta}).
\end{remark}
\begin{remark}
	In some sense, we want to write
	\[\xi(s)=\pi^{-s/2}\Gamma(s/2)\prod_{p\text{ prime}}\frac1{1-p^{-s}}.\]
	Here, $\pi^{-s/2}\Gamma(s/2)$ is an ``archimedean local factor'' corresponding to the infinite place $\infty$ of $\QQ$, and each of the $\left(1-p^{-s}\right)^{-1}$ are ``nonarchimedean local factors.'' Roughly speaking, the rigorization of this intuition is Tate's thesis \cite{tate-thesis}.
\end{remark}
Now here is how $\Theta$ enters the picture.
\begin{lemma} \label{lem:xi-as-integral}
	For $\op{Re}s>1$, we have
	\[\xi(s)=\int_0^\infty\left(\frac{\Theta(t)-1}2\right)t^{s/2}\,\frac{dt}t.\]
\end{lemma}
\begin{proof}
	This argument is similar to \Cref{cor:abstract-func-eq}. Note
	\[\frac{\Theta(t)-1}2=\sum_{n=1}^\infty e^{-\pi n^2t}\]
	for any $t>0$, so we are looking at
	\[\int_0^\infty\Bigg(\sum_{n=1}^\infty e^{-\pi n^2t}t^{(s-2)/2}\Bigg)dt.\]
	We would like to switch the sum and integral, so we check for absolute convergence. Well, to check absolute convergence, it's enough to check after we exchange the integral and sum, so we compute
	\begin{align*}
		\sum_{n=1}^\infty\left(\int_0^\infty\left|e^{-\pi n^2t}t^{s/2}\cdot\frac1t\right|\,dt\right) &= \sum_{n=1}^\infty\left(\int_0^\infty e^{-\pi n^2t}t^{\op{Re}s/2}\,\frac{dt}t\right) \\
		&= \sum_{n=1}^\infty\left(\int_0^\infty e^{-t}\left(\frac t{\pi n^2}\right)^{\op{Re}s/2}\,\frac{dt}t\right) \\
		&= \pi^{-\op{Re}s/2}\sum_{n=1}^\infty\left(\frac1{n^{\op{Re}s}}\int_0^\infty e^{-\pi t}t^{\op{Re}s/2}\,\frac{dt}t\right) \\
		&= \pi^{-\op{Re}s/2}\zeta(\op{Re}s)\Gamma(\op{Re}s/2).
	\end{align*}
	Now, $\op{Re}s>1$, so all terms are finite, so we have absolute convergence. Thus, our integral converges absolutely, so we can exchange the integral and sum. Repeating the above equalities but removing the absolute value signs (and hence removing $\op{Re}s$ with just $s$ everywhere) shows
	\[\int_0^\infty\Bigg(\sum_{n=1}^\infty e^{-\pi n^2t}t^{(s-2)/2}\Bigg)dt=\sum_{n=1}^\infty\left(\int_0^\infty e^{-\pi n^2t}t^{s/2}\,\frac{dt}t\right)=\pi^{-s/2}\Gamma(s/2)\zeta(s)=\xi(s)\]
	for $\op{Re}s>1$, which is what we wanted.
\end{proof}
We are now ready to prove our functional equation.
\begin{theorem}[Functional equation for $\xi$] \label{thm:xi-func-eq}
	The function $\xi$ has a meromorphic continuation to all $\CC$, with only simple poles at $s=1$ and $s=0$ of residue $1$ and $-1$, respectively. In fact, $\xi$ satisfies the equation
	\[\xi(s)=\xi(1-s)\]
	for $s\in\CC\setminus\{0,1\}$.
\end{theorem}
\begin{proof}
	We combine \Cref{prop:theta-func-eq} with \Cref{lem:xi-as-integral}. We proceed in steps.
	\begin{enumerate}
		\item The integral in \Cref{lem:xi-as-integral} is poorly behaved for $\op{Re}s<1$ because of the integral over $t\in(0,1)$, so we define
		\[I(s)\coloneqq\int_1^\infty\left(\frac{\Theta(t)-1}2\right)t^{s/2}\,\frac{dt}t.\]
		We claim that $I(s)$ defines an entire function; more precisely, we will show that $I(s)$ defines holomorphic function on $\{s:\op{Re}s>\sigma\}$ for any $\sigma\in\RR$, and taking the union over all $\sigma$ will finish.
		
		We use \Cref{prop:diff-under-sign}. For one, the function $t\mapsto\left(\frac{\Theta(t)-1}2\right)t^{s/2}$ is continuous (recall $\Theta$ is continuous by \Cref{rem:theta-converges}) and hence measurable. Lastly, we must upper-bound
		\begin{align*}
			\int_1^\infty\left|\left(\frac{\Theta(t)-1}2\right)t^{s/2}\right|\frac{dt}t &= \frac12\int_1^\infty\Bigg(\sum_{n=1}^\infty e^{-\pi n^2t}\Bigg)t^{\sigma/2}\,\frac{dt}t \\
			&\le \frac12\int_1^\infty\Bigg(\sum_{n=1}^\infty e^{-\pi nt}\Bigg)t^{\sigma/2}\,\frac{dt}t \\
			&= \frac12\int_1^\infty\frac{e^{-\pi t}t^{\sigma/2}}{1-e^{-\pi t}}\,\frac{dt}t \\
			&\le \frac1{2\left(1-e^{-\pi}\right)}\int_1^\infty e^{-\pi t}t^{\sigma/2}\,\frac{dt}t.
		\end{align*}
		Thus, we take $g\colon(1,\infty)\to\CC$ by $g(t)\coloneqq e^{-\pi t}t^{\sigma/2-1}/\left(2\left(1-e^{-\pi}\right)\right)$. Using \Cref{prop:diff-under-sign}, it remains to show that $\int_1^\infty g(t)\,dt<\infty$. Well, $e^{-\pi t}t^{\sigma/2+1}\to0$ as $t\to\infty$, so this function achieves a maximum on $[1,\infty)$,\footnote{Find $N$ such that $g(t)<g(1)$ for $t<N$. Then the maximum of $g$ is its maximum on $[1,N]$.} which we will call $M$. It follows
		\[\int_1^\infty g(t)\,dt\le\frac1{2\left(1-e^{-\pi}\right)}\int_1^\infty\frac Mt\,\frac{dt}t<\infty.\]
	
		\item Having controlled the $(1,\infty)$ part of the integral in \Cref{lem:xi-as-integral}, we turn to the $(0,1)$ part. The idea here is to use \Cref{prop:theta-func-eq} to transform the $(0,1)$ part back into a well-behaved $(1,\infty)$ part. Indeed, for $\op{Re}s>1$, we may evaluate
		\begin{align*}
			\int_0^1\left(\frac{\Theta(t)-1}2\right)t^{s/2}\,\frac{dt}t &= \int_1^\infty\left(\frac{\Theta(1/t)-1}2\right)t^{-s/2}\,\frac{dt}t \\
			&= \int_1^\infty\left(\frac{\sqrt t\Theta(t)-1}2\right)t^{-s/2}\,\frac{dt}t \\
			&= \int_1^\infty\left(\frac{\sqrt t\Theta(t)-\sqrt t}2\right)t^{-s/2}\,\frac{dt}t-\frac12\int_1^\infty t^{-s/2}\,\frac{dt}t+\frac12\int_1^\infty t^{(1-s)/2}\,\frac{dt}t \\
			&= \int_1^\infty\left(\frac{\Theta(t)-1}2\right)t^{(1-s)/2}\,\frac{dt}t-\int_1^\infty t^{-s}\,\frac{dt}t+\int_1^\infty t^{1-s}\,\frac{dt}t \\
			&= I(1-s)-\frac1s-\frac1{1-s}.
		\end{align*}

		\item Synthesizing the previous steps, \Cref{lem:xi-as-integral} grants
		\[\xi(s)=I(s)+I(1-s)-\frac1s-\frac1{1-s}\]
		on $\op{Re}s>1$. However, $I(s)$ is fully entire, so the right-hand side is a meromorphic function on $\CC$ with simple poles at $s=1$ (of residue $\op{Res}_{s=1}-\frac1{1-s}=\op{Res}_{s=1}\frac1{s-1}=1$) and at $s=0$ (of residue $\op{Res}_{s=1}-\frac1s=-1$). Viewing the right-hand side as our continuation of $\xi$ completes the analysis of $\xi$. Lastly, the above equation tells us that
		\[\xi(s)=\xi(1-s)\]
		for $s\in\CC\setminus\{0,1\}$, which completes the proof.
		\qedhere
	\end{enumerate}
\end{proof}
\begin{remark}
	Directly from \Cref{thm:xi-func-eq}, we see that $\Xi(s)=s(1-s)\xi(s)$ is an entire function and satisfies the functional equation
	\[\Xi(s)=\Xi(1-s).\]
\end{remark}
% \begin{remark}
% 	The previous remark, after some summation by parts, tells us that $\pi(x)-\op{Li}(x)$ has a better error term than $\pi(x)-x/\log x$, where
% 	\[\op{Li}(x)=\int_2^x\frac{dt}{\log t}.\]
% \end{remark}
% Next class we will show the functional equation.

\subsection{Corollaries of the Functional Equation}
We quickly establish the following more asymmetric version of the functional equation.
\begin{corollary}[Functional equation for $\zeta$]
	The function $\zeta$ has a meromorphic continuation to $\CC$ with only a simple pole at $s=1$ of residue $1$. In fact, for $s\in\CC\setminus\ZZ_{\le0}$, we have the functional equation
	\[\zeta(1-s)=2(2\pi)^{-s}\cos\left(\frac{\pi s}2\right)\Gamma(s)\zeta(s).\]
\end{corollary}
\begin{proof}
	We begin by discussing the meromorphic continuation of $\zeta$. Note \Cref{thm:xi-func-eq} lets us continue $\zeta$ by writing
	\[\zeta(s)=\frac{\xi(s)}{\pi^{-s/2}\Gamma(s/2)}\]
	for any $s\in\CC\setminus\{0,1\}$. Notably, the denominator is never nonzero, and even through $\Gamma(s/2)$ has a simple pole at nonpositive even integers $-2n$ by \Cref{cor:continue-gamma} at these points $\xi(s)$ will have at worst simple pole by \Cref{thm:xi-func-eq} as well, so we can just multiply the numerator and denominator by $(s-2n)$ until the denominator is nonzero.

	It remains to deal with $s\in\{0,1\}$. At $s=0$, we write
	\[\zeta(s)=\frac{s\xi(s)}{\pi^{-s/2}\cdot s\Gamma(s/2)}\]
	so that we have written $\zeta(s)$ as the quotient of holomorphic functions nonzero at $s=0$. (Note $s\cdot\Gamma(s/2)$ has no pole and is nonzero at $s=0$ by \Cref{cor:continue-gamma}.) However, at $s=1$, we already know that $\zeta$ has a simple pole of residue $1$ by \Cref{prop:continue-zeta}.

	To finish the proof, we must produce the functional equation. By uniqueness of the functional equation, it suffices to focus on $0<\op{Re}s,1$. Here, \Cref{thm:xi-func-eq} grants
	\begin{equation}
		\pi^{-(1-s)/2}\Gamma\left(\frac{1-s}2\right)\zeta(1-s)=\xi(1-s)=\xi(s)=\pi^{-s/2}\Gamma\left(\frac s2\right)\zeta(s). \label{eq:almost-zeta-func-eq}
	\end{equation}
	Multiplying both sides by $\Gamma\left(\frac{1+s}2\right)$, we see \Cref{prop:gamma-func-eq} implies
	\[\Gamma\left(\frac{1+s}2\right)\Gamma\left(\frac{1-s}2\right)=\frac\pi{\sin\left(\pi\cdot\frac{1+s}2\right)}=\frac\pi{\cos(\pi s/2)}.\]
	On the other hand, \Cref{prop:duplicate-gamma} implies
	\[\Gamma\left(\frac s2\right)\Gamma\left(\frac{s+1}2\right)=\sqrt\pi2^{1-s}\Gamma(s).\]
	In total, we may rearrange \eqref{eq:almost-zeta-func-eq} into
	\[\frac{\pi^{-(1-s)/2+1}\zeta(1-s)}{\cos(\pi s/2)}=\pi^{1/2-s/2}\cdot 2^{1-s}\zeta(s),\]
	which rearranges into the desired equation.
\end{proof}
\begin{example} \label{ex:zeta-zero}
	Note
	\[\zeta(0)=\lim_{s\to1}\zeta(1-s)=\lim_{s\to1}\left(2(2\pi)^{-s}\cdot\frac{\cos(\pi s/2)}{s-1}\cdot\Gamma(s)\cdot(s-1)\zeta(s)\right).\]
	Using L'H\^opital's rule, we see $\cos(\pi s/2)/(s-1)\to-\pi/2$ as $s\to1$. By \Cref{prop:continue-zeta}, we see $(s-1)\zeta(s)\to1$ as $s\to1$. Plugging everything else in, we see $\zeta(0)=2\cdot(2\pi)^{-1}\cdot(\pi/2)\cdot1\cdot1=-1/2$.
\end{example}
This functional equation grants us some basic knowledge about the zeroes of $\zeta$.
\begin{corollary} \label{cor:basic-zeta-zeroes}
	We have the following.
	\begin{listalph}
		\item Conjugate symmetry: if $\zeta(s)=0$, then $\zeta(\overline s)=0$.
		\item Trivial zeroes: the function $\zeta$ has a simple zero at $-2n$ for each positive integer $n$.
		\item Critical strip: if $\zeta(s)=0$ and $-s/2\notin\NN$, then $0\le\op{Re}s\le1$.
		\item Horizontal symmetry: if $\zeta(s)=0$ and $0\le\op{Re}s\le1$, then $\zeta(1-s)=0$.
	\end{listalph}
\end{corollary}
\begin{proof}
	Here we go.
	\begin{listalph}
		\item More generally, we claim that $\overline{\zeta(\overline s)}=\zeta(s)$ for $s\in\CC\setminus\{1\}$, from which the claim will follow.
		
		Because $\zeta$ is holomorphic in this region, we see that $s\mapsto\overline{\zeta(\overline s)}$ is also holomorphic. (Formally, we can just check that $\zeta(x+yi)=u(x+yi)+iv(x+yi)$ satisfying the Cauchy--Riemann equations implies that $u(x-yi)-iv(x-yi)$ does as well.) So by the uniqueness of analytic continuation, it suffices to check the result for $s\in\RR_{>1}$, which is clear because $\zeta$ is real on this line, so
		\[\zeta(s)=\zeta(\overline s)=\overline{\zeta(\overline s)}.\]

		\item For any positive integer $n$, write
		\[\zeta(s)=\frac{(s+2n)\xi(s)}{\pi^{-s/2}\cdot(s+2n)\Gamma(s/2)}.\]
		As $s\to-2n$, the numerator vanishes because $\xi$ is holomorphic at $s=-2n$ by \Cref{thm:xi-func-eq}. However, the denominator is finite and nonzero: $\pi^{-s/2}$ vanishes nowhere, and $\Gamma(s/2)$ has a simple pole at $s=-2n$ by \Cref{cor:continue-gamma} which is cancelled by the factor of $(s+2n)$. In total, we conclude
		\[\zeta(-2n)=\lim_{s\to-2n}\zeta(s)=0.\]
		To compute the order of the zero at $-2n$, the argument above implies that the order of vanishing of $\zeta$ is one more than the order of vanishing of $\xi$. However,
		\[\xi(-2n)=\xi(1+2n)=\pi^{-(1+2n)}\Gamma((1+2n)/2)\zeta(1+2n)\]
		does not vanish. In particular, $\Gamma$ does not vanish by \Cref{rem:recip-gamma-entire}, and $\zeta$ does not vanish by \Cref{cor:dumb-zero-free}.

		\item If $\op{Re}s>1$, then $\zeta(s)\ne0$ by \Cref{cor:dumb-zero-free} already. Thus, it remains to discuss $\op{Re}s<0$. Well, for $\op{Re}s>1$, we see
		\[\zeta(1-s)=2(2\pi)^{-s}\cos\left(\frac{\pi s}2\right)\Gamma(s)\zeta(s),\]
		and for $\op{Re}s>1$ this right-hand side will only vanish when $\cos(\pi s/2)=0$, which is equivalent to $s\in2\ZZ_{\ge0}+1$. (Namely, $\Gamma(s)$ never vanishes by \Cref{cor:continue-gamma}, and $\zeta(s)$ does not vanish in this region as just discussed.) Unwinding, we see that $\zeta(s)=0$ and $\op{Re}s<0$ implies that $1-s\in2\ZZ_{\ge0}+1$, which is equivalent to $s\in-2\ZZ_{\le0}$. This is what we wanted.

		\item Note that $\zeta(1)$ isn't defined, and $\zeta(0)\ne0$ by \Cref{ex:zeta-zero}, so we may safely ignore $s\in\{0,1\}$. Otherwise, we stare at
		\[\zeta(1-s)=2(2\pi)^{-s}\cos\left(\frac{\pi s}2\right)\Gamma(s)\zeta(s),\]
		which is valid on $\{s:0\le\op{Re}s\le1\}\setminus\{0,1\}$. (In particular, $\Gamma$ is holomorphic here by \Cref{cor:continue-gamma}.) Thus, $\zeta(s)=0$ implies $\zeta(1-s)=0$.
		\qedhere
	\end{listalph}
\end{proof}
\begin{remark}
	The negative even integers are called the ``trivial'' zeroes of $\zeta(s)$. The remaining ones, which all lie in the ``critical strip'' $\{s\in\CC:0\le\op{Re}s\le1\}$ by \Cref{cor:basic-zeta-zeroes}, are called the ``nontrivial'' zeroes.
\end{remark}

\end{document}