% !TEX root = ../notes.tex

\documentclass[../notes.tex]{subfiles}

\begin{document}

\section{December 2}
Welcome back. I missed last lecture.

\subsection{The Weyl Character Formula}
Last class we proved that the quotient $L_\lambda$ is finite-dimensional if and only if $\lambda$ is a dominant integral weight. We are in the process of writing down the Weyl character formula for the character $\chi_\lambda$ of $L_\lambda$.
\begin{remark}
	Recall that $\chi_V$ for a representation $V$ of $\mf g$  has the following property: if $G$ is a simply connected Lie group with $\op{Lie}G=\mf g$, then any $h\in\mf h$ has
	\[\tr_V\exp(h)=\sum_\lambda\dim V[\lambda]e^{\lambda(h)},\]
	which motivates the definition
	\[\chi_V\coloneqq\sum_{\lambda}\dim V[\lambda]e^\lambda\]
	as a formal sum.
\end{remark}
Here is our statement.
\begin{theorem}[Weyl character formula]
	Fix a complex semisimple Lie algebra $\mf g$ with root system $\Phi=\Phi_+\sqcup\Phi_-$ and Weyl group $W$. Let $\lambda$ be a dominant integral weight. Then
	\[\chi_\lambda=\frac{\displaystyle\sum_{w\in W}\varepsilon(w)e^{w(\lambda+\rho)-\rho}}{\displaystyle\prod_{\alpha\in\Phi_+}\left(1-e^{-\alpha}\right)}.\]
	Here, $\rho=\frac12\sum_{\alpha\in\Phi_+}\alpha$, and $\varepsilon(w)=(-1)^{\ell(w)}$.
\end{theorem}
\begin{proof}
	To begin our proof, we note that we can rewrite this denominator as
	\[\Delta\coloneqq e^\rho\prod_{\alpha\in\Phi_+}\left(1-e^{-\alpha}\right)=\prod_{\alpha\in\Phi_+}\left(e^{\alpha/2}-e^{-\alpha/2}\right).\]
	For example, it follows that $w\cdot\Delta=\varepsilon(w)\Delta$ for all $w\in W$. We would now like to show that
	\[\Delta\chi_\lambda\stackrel?=\sum_{w\in W}\varepsilon(w)e^{w(\lambda+\rho)}.\]
	Notably, the weights of $L_\lambda$ are invariant under the action of $W$, so $w\cdot\Delta\chi_\lambda=\varepsilon(w)\Delta\chi_\lambda$. In particular, this place will strong constraints on what the coefficients of the expansion
	\[\Delta\chi_\lambda=\sum_{\mu\in P}c_\mu e^\mu.\]
	In particular, it is enough to compute $c_\mu$ for $\mu\in P_+$ by applying the action of $W$ to get the remaining coefficients. The same is true for the right-hand side of our desired sum, so it remains to show that
	\[\{\mu\in P_+:c_\mu\ne0\}\stackrel?=\{\lambda+\rho\}.\]
	Technically, this only checks that $\Delta\chi_\lambda$ and the sum are equal only up to some constant, but one can compute the coefficient of $e^\lambda$ as $1$ in order to achieve the actual equality.
	
	To show the last claim, we build a resolution for $L_\lambda$. It is certainly surjected onto by $M_\lambda$, and the kernel will be generated by some singular vectors in $M_\lambda$, which we will denote by $M_{v_{1i}},\ldots,M_{v_{1k_1}}$. (Explicitly, the $v_{1i}$s can be seen as $v_\lambda$ times some element of $\mf g$.) One can repeat this process to build a resolution
	\[\cdots\to\bigoplus_{i=1}^{k_2}M_{v_{2i}}\to\bigoplus_{i=1}^{k_1}M_{v_{1i}}\to M_\lambda\to M\to L_\lambda\to0.\]
	Let's explain why this process must terminate. The action of $C\in U\mf g$ on $M_\lambda$ is by $(\lambda+2\rho,\lambda)$, so we see that each $v_{ij}$ has $(v_{ij}+2\rho,v_{ij})=(\lambda+2\rho,\lambda)$, but there are only finitely many weights that can achieve this. This tells us that the resolution above must be finite and why each sum is finite: there are only finitely many weights to go around! Taking characters, we see
	\[\chi_\lambda=\chi_{M_\lambda}-\sum_{i=1}^{k_1}\chi_{v_{1i}}+\sum_{i=1}^{k_2}\chi_{v_{2i}}-\cdots.\]
	One can compute that
	\[\chi_{M_\lambda}=\frac{e^{\lambda+\rho}}{\Delta}\]
	via the isomorphism $U\mf n_-\to M_\lambda$ given by $u\mapsto uv_\lambda$. Expanding this out, the key combinatorial input is that the only vector $v\in (\lambda-Q_+)\cap(P_+-\rho)$ such that $(v+2\rho,v)=(\lambda+2\rho,\lambda)$ is $v=\lambda$, which one shows via some geometric argument.
\end{proof}
\begin{remark}
	There exists a cleaner proof by constructing a better resolution for $L_\lambda$. However, then one has to work much harder to write down this resolution.
\end{remark}

\subsection{Representation Theory of \texorpdfstring{$\mf{sl_n}$}{sln}}
We work with $\mf g\coloneqq\mf{sl}_n$. Then $\mf h$ is the diagonal matrices $\op{diag}(x_1,\ldots,x_n)$ whose coordinates sum to $0$, and we see that $P$ equals the $n$-tuples $(y_1,\ldots,y_n)$ such that $y_i-y_j\in\ZZ$ for all $i$ and $j$ and that $\sum_iy_i=0$. This group is abstractly isomorphic to $\ZZ^n/\ZZ(1,\ldots,1)$; let $\omega_1,\ldots,\omega_n$ be the corresponding basis. Notably, we see that $P_+$ becomes decreasing sequences $(k_1,\ldots,k_{n-1},0)$, which is simply a partition with at most $n-1$ elements. As usual, one can write down such a thing as a Young diagram. Let's give a few examples.
\begin{example}
	The standard representation $V=\CC^n$ has highest weight vector $e_1$ and corresponds to $L_{(1,0,\ldots,0)}$.
\end{example}
\begin{example}
	The representation $\land^iV$ has highest weight vector $e_1\land\cdots\land e_i$ and corresponds to $L_{(1,\ldots,1,0,\ldots,0)}$ where there are $i$ ones.
\end{example}
In general, if $\lambda=\sum_in_i\omega_i$, then one can find $L_\lambda$ inside the tensor power
\[L_{\omega_1}^{\otimes n_1}\otimes\cdots\otimes L_{\omega_r}^{n_r},\]
and in particular one uses the vector $v_{\omega_1}^{\otimes n_1}\otimes\cdots\otimes v_{\omega_r}^{\otimes n_r}$. One can show in this manner that the standard representation $V$ of $\mf{sl}_n$ generates the full tensor category $\op{Rep}_\CC\mf{sl}_n$ because one can find any representation in any large enough tensor power.

\end{document}