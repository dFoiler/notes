% !TEX root = ../notes.tex

\documentclass[../notes.tex]{subfiles}

\begin{document}

\section{November 6}
Today we start talking about abstract root systems.

\subsection{Classical Root Systems}
Let's begin by reviewing some root systems we already know about.
\begin{example}[type $A_{n-1}$]
	Take $\mf g=\mf{sl}_n(F)$ with Cartan subalgebra $\mf h$ given by the diagonal matrices. Then $\mf h^\lor$ is spanned by projections $e_i\colon\mf h\to F$ onto the $i$th diagonal coordinate, with the relation $e_1+\cdots+e_n=0$. The adjoint action of $\mf h$ on $\mf g$ is diagonalized by having kernel $\mf h$ and eigenvectors $E_{ij}$ for $i\ne j$ with nonzero eigenvalues $e_i-e_j$. Thus, our root system is
	\[\{e_i-e_j:i\ne j\}.\]
\end{example}
\begin{example}[type $D_n$]
	Take $\mf g=\mf{so}_{2n}$ to preserve $J\coloneqq\begin{bsmallmatrix}
		& 1 \\ 1
	\end{bsmallmatrix}$. Then
	\[\mf g=\left\{\begin{bmatrix}
		A & B \\ C & -A^\intercal
	\end{bmatrix}:B^\intercal=-B,C^\intercal=-C\right\}.\]
	For example, one can check that $\mf h$ (given by diagonal matrices) is once again a Cartan subalgebra. From here, one can diagonalize the adjoint action by having kernel $\mf h$ and eigenvectors from elementary matrices in $A$ (with eigenvalues $e_i-e_j$) and elementary matrices in $B$ (with eigenvalues $e_i+e_j$) and elementary matrices in $C$ (with eigenvalues $-e_i-e_j$). Thus, our root system is
	\[\{e_i-e_j:i\ne j\}\sqcup\{e_i+e_j:i<j\}\sqcup\{-e_i-e_j:i<j\}.\]
\end{example}
\begin{example}[type $B_n$]
	Take $\mf g=\mf{so}_{2n+1}$ to preserve $J\coloneqq\op{diag}\left(1,\begin{bsmallmatrix}
		& 1_n \\ 1_n
	\end{bsmallmatrix}\right)$. Then
	\[\mf g=\left\{\begin{bmatrix}
		& u & -u \\
		w & A & B \\
		-w & C & -A^\intercal
	\end{bmatrix}:B^\intercal=-B,C^\intercal=-C\right\}.\]
	For example, one can check that $\mf h$ (given by diagonal matrices) is once again a Cartan subalgebra. From here, one can diagonalize the adjoint action by having kernel $\mf h$ and eigenvectors from elementary matrices in $A$ (with eigenvalues $e_i-e_j$) and elementary matrices in $B$ (with eigenvalues $e_i+e_j$) and elementary matrices in $C$ (with eigenvalues $-e_i-e_j$) and elementary matrices in $u$ and $w$ (with eigenvalues $e_i$ and $-e_i$). Thus, our root system is
	\[\{e_i-e_j:i\ne j\}\sqcup\{e_i+e_j:i<j\}\sqcup\{-e_i-e_j:i<j\}\sqcup\{\pm e_i\}.\]
\end{example}
\begin{example}[type $C_n$]
	Take $\mf g=\mf{sp}_{2n}$ to preserve $J\coloneqq\begin{bsmallmatrix}
		& 1 \\ -1
	\end{bsmallmatrix}$. Then
	\[\mf g=\left\{\begin{bmatrix}
		A & B \\ C & -A^\intercal
	\end{bmatrix}:B=B^\intercal,C=C^\intercal\right\}.\]
	Once again, $\mf h$ given by diagonal matrices is a Cartan subalgebra and then diagonalize the adjoint action of $\mf h$ on $\mf g$. The same sort of elementary matrices show that our root system is
	\[\{e_i-e_j:i\ne j\}\sqcup\{e_i+e_j:i<j\}\sqcup\{-e_i-e_j:i<j\}\sqcup\{\pm2e_i\}.\]
\end{example}
\begin{remark}
	In all the above computations, one can choose a non-degenerate bilinear form on $\mf g$ to be some multiple of $\langle X,Y\rangle\coloneqq\tr XY$ (possibly off by a factor of $2$), scaled so that $\langle e_i,e_j\rangle=1_{i=j}$.
\end{remark}

\subsection{Abstract Root Systems}
We would like to codify combinatorial properties of our known root systems in order to begin doing some classification.
\begin{definition}[root system]
	Let $E$ be a finite-dimensional $\QQ$-vecotr space equipped with an inner product. A finite subset $\Phi\subseteq E\setminus\{0\}$ is a \textit{root system} if and only if it satisfies the following axioms.
	\begin{itemize}
		\item Spans: $\Phi$ spans $E$.
		\item For each $\alpha,\beta\in\Phi$, the number $n_{\alpha\beta}\coloneqq2\frac{(\alpha,\beta)}{(\alpha,\alpha)}$ is an integer.
		\item Reflections: for all $\alpha,\beta\in\Phi$, the reflection
		\[s_\alpha(\beta)\coloneqq\beta-n_{\alpha\beta}\alpha\]
		is in $\Phi$.
	\end{itemize}
\end{definition}
\begin{example}
	By combining \Cref{lem:almost-reflect,lem:reflect-root-system}, one sees that the root system attached to a semisimple Lie algebra is in fact a root system in the above sense.
\end{example}
\begin{example}
	Let $\Phi\subseteq E$ be a root system. If $E'\subseteq E$ is any sublattice spanned by $\Phi\cap E'$, then $\Phi\cap E'\subseteq E'$ is a root system. For example, one can start with any sublattice $E''$ and then define $E'\coloneqq\op{span}(\Phi\cap E'')$.
\end{example}
\begin{example}
	For root systems $\Phi_1\subseteq E_1$ and $\Phi_2\subseteq E_2$, then $\Phi_1\sqcup\Phi_2$ is a root system of $E_1\times E_2$. Here, $E_1\times E_2$ has been given the inner product structure where $E_1$ and $E_2$ are orthogonal subspaces. For example, if $\Phi_1\subseteq E_1$ and $\Phi_2\subseteq E_2$ are root systems attached to semisimple Lie algebras $\mf g_1$ and $\mf g_2$, then we showed earlier that $\Phi_1\sqcup\Phi_2$ is the root system attached to $\mf g_1\times\mf g_2$.
\end{example}
\begin{remark}
	Let $\Phi\subseteq E$ be a root system. Note that $s_\alpha(\alpha)=-\alpha$, so one sees that $-\Phi=\Phi$.
\end{remark}
In fact, we want to look at a finer subset of root systems.
\begin{definition}[reduced]
	A root system $\Phi\subseteq E$ is \textit{reduced} if and only if having $\alpha$ and $c\alpha\in\Phi$ for some $c\in\QQ$ requires $c\in\{\pm1\}$.
\end{definition}
\begin{example}
	One can check that root systems attached to semisimple Lie algebras are reduced.
\end{example}
We are interested in classification results, so we define some related notions and invariants.
\begin{definition}[isomorphism]
	An \textit{isomorphism} of two root systems $\Phi_1\subseteq E_1$ and $\Phi_2\subseteq E_2$ is an isomorphism of vector spaces $\varphi\colon E_1\to E_2$ such that $\varphi(\Phi_1)=\varphi(\Phi_2)$ and satisfying
	\[n_{\alpha\beta}=n_{\varphi(\alpha)\varphi(\beta)}\]
	for each $\alpha,\beta\in\Phi_1$.
\end{definition}
\begin{remark}
	Importantly, we do not care if $\varphi$ preserves the full inner products on $E_1$ and $E_2$ because one expects to be able to adjust the inner product up to scalar on simple factors, which should not affect whether we think that the actual root systems are the same.
\end{remark}
While we're here, we pick up a few more definitions.
\begin{definition}[coroot]
	Fix a root system $\Phi\subseteq E$. Then the \textit{coroot} $\alpha^\lor$ is the functional $\alpha^\lor\colon E\to\QQ$ given by
	\[\alpha^\lor(\lambda)\coloneqq2\frac{(\alpha,\lambda}{(\lambda,\lambda)}\]
\end{definition}
% \subsection{The Weyl Group}
Let's provide some invariants of root systems for our classifications later.
\begin{definition}[rank]
	Fix a root system $\Phi\subseteq E$. Then the \textit{rank} is $\op{rank}\Phi\coloneqq\dim E$.
\end{definition}
\begin{definition}[Weyl group]
	Fix a root system $\Phi\subseteq E$. The \textit{Weyl group} $W(\Phi)$ is the subgroup of $\op{GL}(E)$ generated by the reflections $\{s_\alpha\}_{\alpha\in\Phi}$.
\end{definition}
\begin{example}
	On the homework, we can check that $W(\Phi)=S_n$ when $\Phi$ has type $A_{n-1}$.
\end{example}
\begin{remark}
	One can check that $W(\Phi)$ is always a finite subgroup of $\op O(E)$. Certainly it is a subgroup of $\op O(E)$ because the reflections can be checked to preserve the inner product, and this subgroup is finite because an element of $W$ is uniquely determined by its action on $\Phi$ (because $\Phi$ spans $E$, and the reflections preserve $\Phi$), and $\op{Aut}(\Phi)$ is finite. Of course, in general we expect $W(\Phi)\subsetneq\op{Aut}(\Phi)\cap\op O(E)$; for example, in type $A_{n-1}$, there is an automorphism sending $x\mapsto-x$, but this is not realized in $W(\Phi)$ for $n\ge3$.
\end{remark}

\subsection{Root systems of Rank 2}
Let's work towards a classification of reduced root systems of rank $2$. One can hope to build a general classification result from here by passing to the rank $2$ case: for a general root system $\Phi$ of rank larger than $2$, one can pick up linearly independent roots $\alpha,\beta\in\Phi$ and then study the root system $\Phi\cap\op{span}\{\alpha,\beta\}$.

Well, our root system $\Phi$ of rank $2$ is spanned by two roots $\alpha$ and $\beta$. Say that the angle between them is $\varphi$, and we will suppose that $\left|\alpha\right|\ge\left|\beta\right|$ without loss of generality; we also suppose that $\varphi$ is as small as possible for our root system. For example, we see that
\[n_{\alpha\beta}=2\frac{(\alpha,\beta)}{(\alpha,\alpha)}=2\frac{\left|\beta\right|}{\left|\alpha\right|}\cos\varphi\]
by using the fact that $(\alpha,\beta)=\left|\alpha\right|\cdot\left|\beta\right|\cdot\cos\varphi$. Similarly, one finds that
\[n_{\beta\alpha}=2\frac{\left|\alpha\right|}{\left|\beta\right|}\cos\varphi.\]
Thus, $n_{\alpha\beta}n_{\beta\alpha}=4\cos^2\varphi$ needs to be a nonnegative integer, so one has the following cases.
\begin{enumerate}
	\item Suppose $4\cos^2\varphi=0$ so that $\varphi=\frac\pi2$. In this case, one finds that we must have $\left|\alpha\right|=\left|\beta\right|$ up to scaling. This is $A_1\sqcup A_1$, and it looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(1cm);
			draw((0,0)--2*dir(0), EndArrow);
			draw((0,0)--2*dir(180), EndArrow);
			draw((0,0)--2*dir(90), EndArrow);
			draw((0,0)--2*dir(270), EndArrow);
		\end{asy}
	\end{center}
	Note that we cannot add more roots because the smallest angle would no longer be $\pi/4$. Also note that we have assumed our root systems are reduced, so we cannot (say) add $2\alpha$.
	\item Suppose $4\cos^2\varphi=1$. Then $\varphi=\frac\pi3$ or $\varphi=\frac{2\pi}3$. In all cases, one finds that $\left|\alpha\right|=\left|\beta\right|$ by solving back for $n_{\alpha\beta}$, which one can check produces the same root system. This is $A_2=D_2$, and it looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(1cm);
			for(int i=0; i <= 6; ++i)
			{
				//draw((0,0)--2*dir(180/6+60*i), EndArrow);
				draw((0,0)--2*dir(60*i), EndArrow);
			}
		\end{asy}
	\end{center}
	Again, we cannot add any more vectors because the smallest angle would become smaller than $\pi/3$.
	\item Suppose $4\cos^2\varphi=2$. Then $\varphi=\frac\pi4$ or $\varphi=\frac{3\pi}4$. In this case, one finds that $\left|\alpha\right|^2=2\left|\beta\right|^2$, which one can check produces the same root system. This is $B_2=C_2$, and it looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(1cm);
			for(int i = 0; i <= 4; ++i)
			{
				draw((0,0)--1*dir(90*i), EndArrow);
				draw((0,0)--1.41*dir(45+90*i), EndArrow);
			}
		\end{asy}
	\end{center}
	As usual, we cannot add more roots because it would decrease the size of the smallest angle.
	\item Suppose $4\cos^2\varphi=3$. Then $\varphi=\frac{\pi}6$ or $\varphi=\frac{5\pi}6$. In this case, one finds that $\left|\alpha\right|^2=3\left|\beta\right|^2$, which one can check produces the same root system. This is type $G_2$. It looks like the following.
	\begin{center}
		\begin{asy}
			unitsize(1cm);
			//draw((-3,0)--(3,0), dashed+EndArrow);
			//draw((0,-3)--(0,3), dashed+EndArrow);
			for(int i=0; i <= 6; ++i)
			{
				draw((0,0)--2*dir(180/6+60*i), EndArrow);
				draw((0,0)--1.15*dir(60*i), EndArrow);
			}
		\end{asy}
	\end{center}
	As usual, we cannot add any more roots due to the angle.
\end{enumerate}
Note that our classification produces the following result.
\begin{corollary}
	Let $\Phi\subseteq E$ be a reduced root system. If $\alpha,\beta\in\Phi$ have $(\alpha,\beta)<0$, then $\alpha+\beta\in\Phi$.
\end{corollary}
\begin{proof}
	Note that $\alpha$ and $\beta$ span a reduced root system of rank $2$. Then one can appeal to the classification given above and check each case by hand.
\end{proof}

\end{document}