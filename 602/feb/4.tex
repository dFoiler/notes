% !TEX root = ../notes.tex

\documentclass[../notes.tex]{subfiles}

\begin{document}

\section{January 30}

There is a topics list for presentations. They are not required, but they may help improve one's grade. There is a Gradescope for submission with code NG337Y. The homework is 37--38 on page 327, 44 on page 329, and 1, 2, 5--9 on pages 545--546. It is due next week.

\subsection{More on Kummer Theory}
Today we return to Kummer theory. As last time, we assume that $k$ is a field, and $m$ is a positive integer such that $\mu_m\subseteq k$ and that $\op{char}k\nmid m$. (We will touch on $m=p=\op{char}k>0$ later.)

We begin by classifying cyclic extensions. We begin with a ``cohomological'' input.
\begin{proposition}[Hilbert's theorem 90] \label{prop:hilbert-90}
	Fix a cyclic extension $K/k$ of degree $m$, and choose a generator $\sigma\in\op{Gal}(K/k)$. The following are equivalent for some $\beta\in K^\times$.
	\begin{listalph}
		\item $\op N_{K/k}(\beta)=1$.
		\item There is $\alpha\in K^\times$ such that $\beta=\sigma(\alpha)/\alpha$.
	\end{listalph}
\end{proposition}
\begin{proof}
	To see that (b) implies (a), we compute
	\begin{align*}
		\op N_{K/k}(\beta) &= \prod_{i=0}^{m-1}\sigma^i(\beta) \\
		&= \prod_{i=0}^{m-1}\sigma^{i+1}(\alpha)\cdot\prod_{i=0}^{m-1}\sigma^i(\alpha) \\
		&= 1,
	\end{align*}
	where the last equality follows by re-indexing the left product.

	The main content will be in showing (a) implies (b). The key difficulty lies in the construction of $\alpha$, which will not be done explicitly. There are a few ways to motivate the following discussion. We will simply say that the above ``telescoping'' suggests that we would like to choose $\alpha$ of the form
	\[\alpha=\theta+\beta\theta^\sigma+\beta^{1+\sigma}\theta^{\sigma^2}+\cdots+\beta^{1+\sigma+\cdots+\sigma^{m-2}}\theta^{\sigma^{m-1}}\]
	for some $\theta\in K$, where we are using exponential notation for our Galois action. Indeed, we see that $\sigma(\alpha)\beta=\alpha$, so we will be done as soon as we can find any $\theta\in K$ making the above expression for $\alpha$ nonzero.

	More generally, there is a linear independence result for characters: we claim that any distinct characters $\chi_1,\ldots,\chi_n$ of a finite group $G$ are linearly independent as functions $G\to\CC$. Indeed, supposing for the sake of contradiction that there is a set of linearly dependent distinct characters, we may assume that our list is minimal. But then a nonzero linear relation $a_1\chi_1+\cdots+a_n\chi_n=0$ induces a smaller relation
	\[a_1(\sigma_1(y)-\sigma_n(y))\sigma_1+\cdots+a_n(\sigma_n(y)-\sigma_n(y))\sigma_n=0\]
	for any choice of $y\in G$. (Namely, this relation is smaller because the last coefficient is now zero.) For example, if we choose $y$ so that $\sigma_1(y)\ne\sigma_n(y)$, then the first coefficient is nonzero, so this is indeed a strictly smaller nonzero linear relation, providing the needed contradiction.
\end{proof}
\begin{corollary} \label{cor:classify-cyclic-kummer}
	Fix a cyclic extension $K/k$ of degree $m$. Suppose that $\op{char}k\nmid m$ and $\mu_m\subseteq k$. Then there is $\alpha\in K$ such that $K=k(\alpha)$ and $\alpha^m\in k$.
\end{corollary}
\begin{proof}
	Choose a generator $\sigma$ of $\op{Gal}(K/k)$. We use \Cref{prop:hilbert-90} to construct the needed $\alpha$. In particular, choose a generator $\zeta$ of $\mu_m$, and then $\zeta\in k$ implies that $\op N_{K/k}(\zeta)=\zeta^m=1$. Thus, there is $\alpha\in K$ such that $\zeta=\sigma(\alpha)/\alpha$, so $\sigma(\alpha)=\zeta\alpha$, and a quick induction shows that $\sigma^i(\alpha)=\zeta^i\alpha$ for all $i$. Thus, $\alpha$ has $m$ distinct Galois conjugates, so $k(\alpha)$ is a degree $m$ extension of $k$, so $k(\alpha)=K$ follows for degree reasons. Lastly, we should check that $\alpha^m\in k$, which follows because
	\[\sigma^i\left(\alpha^m\right)=\zeta^{mi}\alpha^m=\alpha^m\]
	for all $\sigma$.
\end{proof}
Here is the main theorem, which extends the example from last class.
\begin{theorem}[Kummer]
	Fix a field $k$ and a positive integer $m$. Suppose that $\op{char}k\nmid m$ and $\mu_m\subseteq k$.
	\begin{listalph}
		\item There is a map sending subgroups $B$ between $k^{\times m}$ and $k^\times$ to abelian extensions $K/k$ of exponent $m$. This map sends $B$ to the extension $K_B\coloneqq k(B^{1/m})$ of $k$ generated by the $m$th roots of $B$.
		\item Given some such $B$, the extension $K_B/k$ is finite if and only if the index $\left[B:k^{\times m}\right]$ is finite. In fact, there is an isomorphism
		\[\op{Gal}(K_B/k)^\lor\to B/k^{\times m}.\]
		\item The map in (a) is an inclusion-preserving bijection.
	\end{listalph}
\end{theorem}
% \begin{remark}
% 	In the event of (c), it turns out that there is a canonical isomorphism
% 	\[\op{Gal}(K_B/k)^\lor\to B/k^{\times m}.\]
% \end{remark}
\begin{proof}
	The main input is to define a ``Kummer pairing.'' Motivated by the above discussion, one can describe the pairing $\op{Gal}(K_B/k)\times B\to\mu_m$ by sending a pair $(\sigma,a)$ to the root of unity $\langle\sigma,a\rangle\in\mu_m$ such that
	\[\sigma(\alpha)=\langle\sigma,a\rangle\sigma(\alpha),\]
	where $\alpha$ is any root of the polynomial $X^m-a$. Namely, $\alpha$ and $\sigma(\alpha)$ are both roots of the equation $X^m-a$, so there is a unique root of unity $\langle\sigma,a\rangle\in\mu_m$ relating the two. Additionally, one can check that $\langle\sigma,a\rangle$ does not depend on the precise choice of $\alpha$: any other root of $X^m-a$ takes the form $\zeta\alpha$ for some $\zeta\in\mu_m$, so the fact that $\mu_m\subseteq k$ implies that
	\[\frac{\sigma(\zeta\alpha)}{\zeta\alpha}=\frac{\sigma(\alpha)}{\alpha}.\]
	We now show our parts in sequence. Everything is rather formal except for the surjectivity check in (c), for which we must use \Cref{cor:classify-cyclic-kummer}.
	\begin{listalph}
		\item We must check that $K_B/k$ is an abelian Galois extension of exponent $m$.
		\begin{itemize}
			\item To see that it is Galois, it is enough to check that it is generated by Galois elements, so it is enough to check that all Galois conjugates of $\alpha\in B^{1/m}$ live in $K_B$. Well, $a\coloneqq\alpha^m$ is an element of $k$ by construction, so $\alpha$ is the root of the polynomial $X^m-a$. Because $\mu_m\subseteq k$, we see that the set
			\[\{\zeta\alpha:\zeta\in\mu_m\}\]
			of roots of $X^m-a$ is therefore contained in $K_B$. 
			\item To see that it is abelian, choose two automorphisms $\sigma,\tau\in\op{Gal}(K_B/k)$. We would like to check that $\sigma\tau=\tau\sigma$. It is enough to check this equality on generating elements of $K_B/k$, so we once again choose some $\alpha\in B^{1/m}$ and set $a\coloneqq\alpha^m$. Then we see that
			\[\sigma\tau(\alpha)=\langle\sigma,a\rangle\langle\tau,a\rangle=\tau\sigma(\alpha).\]
		\end{itemize}
		\item We will show that $\langle\cdot,\cdot\rangle$ descends to a perfect pairing
		\[\op{Gal}(K_B/k)\times B/k^{\times m}\to\mu_m.\]
		Here are our checks.
		\begin{itemize}
			\item Well-defined: if $a\in B$ and $b\in k$, we must check that $\langle\sigma,a\rangle=\langle\sigma,ab^m\rangle$. Well, this amounts to noting
			\[\frac{\sigma\left(\alpha\right)}{\alpha}=\frac{\sigma(\alpha b)}{\alpha b}\]
			for a chosen root $\alpha$ of $X^m-a$.
			\item Injective on $\op{Gal}(K_B/k)$: suppose that $\sigma\in\op{Gal}(K_B/k)$ makes $\langle\sigma,\cdot\rangle$ the trivial function, and we must show that $\sigma$ is trivial. Well, it is enough to show that $\sigma$ is trivial on $B^{1/m}$, so we choose some $\alpha\in B^{1/m}$ and set $a\coloneqq\alpha^m$. Then
			\[\frac{\sigma(\alpha)}{\alpha}=\langle\sigma,a\rangle=1,\]
			so $\sigma$ is the identity on $\alpha$.
			\item Injective on $B/k^{\times m}$: suppose that $a\in B$ makes $\langle\cdot,a\rangle$ is trivial, and we would like to show that $a\in k^{\times m}$. Well, choose a root $\alpha\in K_B$ of $X^m-a$, and we would like to show that $\alpha\in k$. For this, we note that $\langle\sigma,\alpha\rangle=1$ implies that $\sigma(\alpha)=\alpha$ for all $\sigma\in\op{Gal}(K_B/k)$, so the result follows.
		\end{itemize}
		\item This will require some effort. Here are our checks.
		\begin{itemize}
			\item Inclusion-preserving: if $B_1\subseteq B_2$, then we see $B_1^{1/m}\subseteq B_2^{1/m}$, so $K_{B_1}\subseteq K_{B_2}$.

			\item Injective: in light of the previous check, it's enough to see that $K_{B_1}\subseteq K_{B_2}$ implies that $B_1\subseteq B_2$. For this, we reduce to the finite case. Choose $b\in B_1$, and it is enough to check that $b\in B_2$ given that $K_{\langle b\rangle}\subseteq K_{B_2}$. However, $b\in K_{B_2}$ implies that $b$ can be written as a finite polynomial in terms of finitely many elements in $B_2^{1/m}$, so we may as well replace $B_2$ by this finite subset to check that $b\in K_{B_2}$. In total, we are reduced to the case where $B_1$ is generated by $b$ and $B_2$ is finite.

			Now, define $B_3\subseteq k^\times$ as being generated by $B_2$ and $b$. Because $b\in K_{B_2}$ already, we know $K_{B_2}=K_{B_3}$, so the duality of (b) implies
			\[[B_2:k^{\times m}]=[B_3:k^{\times m}].\]
			Because $B_2/k^{\times m}\subseteq B_3/k^{\times m}$ already, we see that equality must follow, so $b\in B_2$ is forced.

			\item Surjective: Choose an extension $K/k$ which is abelian of exponent $m$. It is enough to check that $K$ can be generated by the $m$th roots of some subset $S\subseteq k^{\times m}$, from which we find $K=K_B$ where $B$ is the multiplicative subgroup generated by $S$. By writing $K$ as a composite of finite extensions of $k$, we note that each of these finite extensions must be abelian, so it is enough to generate such a finite abelian extension by $m$th roots. Well, a finite abelian group can be written as a product of cyclic groups, so we may write a finite abelian extension as a composite of cyclic ones, so it is enough to generate such finite cyclic extensions by $m$th roots. This is possible by \Cref{cor:classify-cyclic-kummer}.
			\qedhere
		\end{itemize}
	\end{listalph}
\end{proof}

\subsection{Artin--Schreier Theory}
Fix a field $k$ of positive characteristic $p>0$. Instead of using the $p$th power map (which is injective in characteristic $p>0$ and therefore not very useful), we define a map $\pi\colon k\to k$ by $\pi(x)\coloneqq x^p-x$.
\begin{theorem}[Artin--Schreier]
	Fix a field $k$ of positive characteristic $p>0$. Define the map $\pi\colon k\to k$ by $\pi(x)\coloneqq x^p-x$.
	\begin{listalph}
		\item There is a map between subgroups $B$ of $k$ and abelian extensions $K/k$ of exponent $p$. This map sends $B$ to the extension $K_B\coloneqq k\left(\pi^{-1}B\right)$.
		\item Given some such $B$, the extension $K_B/k$ is finite if and only if $[B:\pi(k)]<\infty$.
		\item The map in (a) is an inclusion-reversing bijection.
	\end{listalph}
\end{theorem}
The proofs are similar, but I will omit them (as they were omitted in lecture) due to laziness. Here, the pairing $(\sigma,a)$ is defined by choosing a root $\alpha$ of $X^p-X-a$ and then setting
\[\langle\sigma,a\rangle\coloneqq\sigma(\alpha)-\alpha.\]

\subsection{Matrices and Linear Algebra}
We now turn to a subject closer to linear algebra. We remark that we will discuss multilinear algebra later in this class.
\begin{notation}
	Fix a commutative ring $R$, and choose nonnegative integers $m,m\ge0$. Then we let $R^{m\times n}$ denote the $R$-module of $m\times n$ matrices with entries in $R$. We may write $M_n(R)\coloneqq R^{n\times n}$, which we note is a ring under matrix multiplication.
\end{notation}
\begin{remark}
	If $m=0$ or $n=0$, then these matrices are generally vacuous. For inductive reasons, it is occasionally helpful to assume that there is exactly one such square $0\times0$ matrix with determinant $1$ and trace $0$.
\end{remark}
Given a matrix $A\in R^{m\times n}$, we may write out its coefficients as $\{A_{ij}\}$, where the indices implicitly range among $i\in\{1,\ldots,m\}$ and $j\in\{1,\ldots,n\}$.
\begin{remark}
	As usual, we note that there is an explicitly defined matrix multiplication
	\[R^{m\times n}\times R^{\ell\times m}\to R^{\ell\times n}.\]
	Explicitly, one has
	\[(AB)_{ik}\coloneqq\sum_{j=1}^mA_{ij}B_{jk}.\]
\end{remark}
\begin{remark}
	One can consider infinite-dimensional matrices, but we will generally avoid doing so.
\end{remark}
Here are the typical operations one can do on matrices.
\begin{definition}[transpose]
	Fix a commutative ring $R$, and choose nonnegative integers $m,n\ge0$. Given $A\in R^{m\times n}$, we define the \textit{transpose} $A^\intercal\in R^{n\times m}$ as having the coefficients
	\[\left(A^\intercal\right)_{ij}\coloneqq A_{ji}\]
	for any $i\in\{1,\ldots,m\}$ and $j\in\{1,\ldots,n\}$.
\end{definition}
\begin{remark}
	Here are some basic properties of the transpose which can be checked on the level of the coefficients.
	\begin{itemize}
		\item For $A,B\in R^{m\times n}$, we have $(A+B)^\intercal=A^\intercal+B^\intercal$.
		\item For $A\in R^{m\times n}$ and $B\in R^{\ell\times m}$, we have $(AB)^\intercal=B^\intercal A^\intercal$.
	\end{itemize}
	These two points imply that $(\cdot)^\intercal$ induces a homomorphism $M_n(R)\to M_n(R)^\mathrm{op}$ of rings.
\end{remark}
\begin{remark}
	Fix a matrix $A\in R^{m\times n}$, and let $\varphi_A\colon R^n\times R^m$ denote the corresponding linear map. Taking duals (i.e., taking $\op{Hom}_R(-,R)$) and fixing the usual dual basis, one finds that the dual morphism $\varphi_A^\lor\colon R^m\to R^n$ has matrix given by $A^\intercal$.
\end{remark}
It will be helpful to change rings in the sequel.
\begin{notation}[base change]
	Fix a ring homomorphism $\varphi\colon R\to R'$. Given some matrix $A\in R^{m\times n}$, then we define the matrix $\varphi(A)\in(R')^{m\times n}$ on coefficients by
	\[\varphi(A)_{ij}\coloneqq\varphi(A_{ij}).\]
\end{notation}
\begin{example}
	In linear algebra, the sort of base-changes one typically does is embedding a field $k$ into a larger field such as an algebraic closure. (For example, the embedding $\RR\into\CC$ is used frequently.) However, we remark that we are also permitting some more exotic morphisms such as the surjection $\ZZ\onto\FF_p$.
\end{example}
Let's go ahead and define some functions on matrices.
\begin{definition}[trace]
	Fix a commutative ring $R$, and choose nonnegative integers $m,n\ge0$. Given $A\in R^{m\times n}$, we define the \textit{trace} as
	\[\tr A\coloneqq\sum_{i=1}^{\min\{m,n\}}A_{ii}.\]
\end{definition}
\begin{remark}
	Here are some basic properties that can be checked on coefficients.
	\begin{itemize}
		\item For $A\in R^{m\times n}$ and $B\in R^{n\times m}$, one has $\tr(AB)=\tr(BA)$.
		\item Specifically, if $A,B\in M_n(R)$ with $B$ invertible, then $\tr\left(B^{-1}AB\right)=\tr A$. We remark that one can show this in a ``basis-free'' manner by providing a basis-free definition of the trace and then remarking that $A\mapsto B^{-1}AB$ amounts to a change of basis.
	\end{itemize}
\end{remark}
\begin{definition}[rank]
	Fix a field $k$, and choose nonnegative integers $m,n\ge0$. Given $A\in R^{m\times n}$, we define the \textit{rank} as the dimension of the image of the associated linear map $A\colon R^n\to R^m$.
\end{definition}
\begin{remark}
	By duality arguments, one finds that $\op{rank}A=\op{rank}A^\intercal$. Roughly speaking, one takes $\op{Hom}_k(-,k)$ everywhere. This is an abstracted version of the 
\end{remark}
\begin{remark}
	There is a short exact sequence
	\[0\to\ker A\subseteq k^n\stackrel A\onto\im A\to0.\]
	Taking dimensions, one finds $n=\dim\ker A+\dim\im A$.
\end{remark}
\begin{remark}
	We quickly remark that there is a method of Gaussian elimination which can be used to compute ranks. In fact, one can show that the ``column'' and ``row'' ranks are preserved by the row and column operations (because row and column operations amount to multiplying by the left or on the right by some specified invertible matrices), from which it follows that the column and row ranks are equal after reducing to some row Echelon form.
\end{remark}
\begin{remark}
	There is a variant of Gaussian elimination when we are not working over a field. The resulting ``reduced'' matrix is called the Smith normal form.
\end{remark}
We would now like a way to work with $R$-modules of the form $R^n$ without admitting that the module is $R^n$.
\begin{definition}[free]
	Fix a commutative ring $R$. Then an $R$-module $M$ is \textit{free of finite rank} if and only if there is a finite subset $B\subseteq M$ such that any $m\in M$ admits a unique tuple $\{a_b\}_{b\in B}$ of elements in $R$ such that
	\[m=\sum_{b\in B}a_bb.\]
	In this event, we call the subset $B$ a \textit{basis}, and we say that the \textit{rank} of $M$ is $\#B$.
\end{definition}
\begin{remark}
	There is a generalization removing the finite rank condition, but then we must require that the tuple of coefficients $\{a_b\}$ have $a_b=0$ for all but finitely many $b\in B$.
\end{remark}
\begin{notation}
	Fix a commutative ring $R$, and let $E$ and $F$ be free modules of finite rank with bases $B=\{b_1,\ldots,b_m\}$ and $C=\{c_1,\ldots,c_n\}$, respectively. Given any $(n\times m)$-matrix $A$, we define the associated $R$-module map $A^B_C\colon E\to F$ by
	\[A^B_C(b_j)\coloneqq\sum_{i=1}^nA_{ij}c_i.\]
	For example, if $E=F$, then one can see that the endomorphism ring $\op{End}_R(E)$ is isomorphic to $M_n(R)$, where $n$ is the rank of $E$.
\end{notation}
\begin{remark}
	One can check that this construction $A\mapsto A^B_C$ provides a bijection between matrices and linear maps. Instead of writing out the checks, we will remark that the inverse map sends a map $f\colon E\to F$ to the matrix $A$ defined by
	\[f(b_j)=\sum_{i=1}^n(M^B_Cf)_{ij}c_i,\]
	where the coefficients are uniquely defined by having a basis.
\end{remark}
\begin{remark}
	As usual, on coefficients, one can check that $(A+A')^B_C=A^B_C+(A')^B_C$. If there is an additional free $R$-module $G$ of finite rank and basis $D$, then one can check on coefficients that
	\[(A'A)^B_D=(A')^C_D\circ A^B_C.\]
	For example, this gives a clean proof that matrix multiplication should associate because function composition is associative.
\end{remark}

\end{document}