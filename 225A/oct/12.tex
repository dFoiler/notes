% !TEX root = ../notes.tex

\documentclass[../notes.tex]{subfiles}

\begin{document}

\section{October 12}

The exam is in a week. I'm probably going to fail.

\subsection{More on \texorpdfstring{$o$}{ o}-Minimality}
Let's check something.
\begin{theorem}
	The theory $\mathrm{RCF}$ is $o$-minimal.
\end{theorem}
\begin{proof}
	We already know that any model restricted to the language of ordered sets is a dense linear order. So we need to check that the definable subsets of a model $\mathcal R\models\mathrm{RCF}$ given by a one-variable $\mathcal L_R$-formula $\varphi(x)$ has the partition as needed. By quantifier elimination, we may as well assume that $\varphi(x)$ is quantifier-free, so upon taking boolean combinations, we may as well assume that $\varphi(x)$ is atomic. Well, we note that an atomic formula is equivalent to one of the form $f(x)>0$ or of the form $g(x)=0$ where $f$ and $g$ are polynomials; the point is that a general atomic formula is ``a term equals or is bigger than some other term.''
	\begin{itemize}
		\item In the case $g(x)=0$, we are looking at either a discrete set of points or all of $R$, both of which are of the needed form.
		\item In the case $f(x)>0$ (where $f$ is nonzero), we note that the intermediate value property has that $f(x)>0$ is the union of some intervals whose endpoints are roots of $f(x)$. Explicitly, enumerate the roots as $a_1<a_2<\cdots<a_n$, and we note that $f(x)>0$ for some $x$ between $a_i$ and $a_{i+1}$ implies that the entire interval will have $f(x)>0$, and sign changes for $f$ can only take this form.
	\end{itemize}
	The above checks complete the proof.
\end{proof}
We should probably prove the fundamental theorem of $o$-minimality, which is cell decomposition. This requires the notion of a cell.
\begin{definition}[cell]
	Fix a model $\mathcal R$ of an $o$-minimal theory $T$. Then a \textit{cell} is defined as follows.
	\begin{itemize}
		\item A $0$-cell is a point.
		\item A $1$-cell in $\mathcal R$ is a set of the form $(a,b)$ where $-\infty\le a<b\le\infty$.
		\item From $n$, an $(n+1)$-cell in $\mathcal R^{n+1}$ is a set of one of the following forms.
		\begin{itemize}
			\item We can have
			\[\{(x_1,\ldots,x_n,y):(x_1,\ldots,x_n)\in X\text{ and }y=f(x_1,\ldots,x_n)\}\]
			where $X\subseteq\mathcal R^n$ is an $n$-cell and $f\colon X\to\mathcal R$ is continuous and definable.
			\item We can have $(-\infty,f)_X$ or $(f,g)_X$ or $(g,\infty)_X$ where
			\[(f,g)_X\coloneqq\{(x_1,\ldots,x_n,y):f(\overline x)<y<f(\overline y)\}\]
			where $X$ is an $n$-cell and $f,g\colon X\to\mathcal R$ is continuous and definable with $f(\overline x)<g(\overline x)$ always (where $(-\infty,f)_X$ and $(g,\infty)_X$ are defined analogously).
			\item Lastly, we can have all of $\mathcal R^n$.
		\end{itemize}
	\end{itemize}
\end{definition}
\begin{remark}
	An induction shows that $n$-cells are homeomorphic to open $n$-balls when $\mathcal R$ is $\RR\models\mathrm{RCF}$.
\end{remark}
We can now define a cell decomposition.
\begin{definition}[cell decomposition]
	Fix a model $\mathcal R$ of an $o$-minimal theory $T$. Then a \textit{cell decomposition} $\mathcal C$ of $\mathcal R^n$ is a finite set of cells in $\mathcal R^n$ such that
	\[\mathcal R^n=\bigcup_{c\in\mathcal C}c.\]
\end{definition}
Anyway, here is our theorem.
\begin{theorem} \label{thm:cell-decomp}
	Fix a model $\mathcal R$ of an $o$-minimal theory $T$.
	\begin{listalph}
		\item Given a finite collection $X_1,\ldots,X_m\subseteq\mathcal R^n$ of definable subsets, then there is a cell decomposition $\mathcal C$ of $\mathcal R^n$ such that each $X_\bullet$ is a union of some of these cells.
		\item Any definable function $f\colon\mathcal R^n\to\mathcal R$ is piecewise continuous. In other words, there is a cell decomposition $\mathcal C$ of $\mathcal R^n$ such that $f$ is continuous upon restriction to each cell.
	\end{listalph}
\end{theorem}
\begin{remark}
	The above theory is true even if we only assume that $\mathcal R$ is $o$-minimal, which lets us prove that $T$ is then $o$-minimal! We will not prove this stronger notion because it would take more time than we want to spend.
\end{remark}
We will prove (a) and (b) essentially simultaneously by some kind of awkward induction.

To get us started, we need the following lemma.
\begin{lemma}
	Fix a model $\mathcal R$ of an $o$-minimal theory $T$. Given some $\mathcal L_R$-formula $\varphi(x,y_1,\ldots,y_n)$, there is a bound $B$ (depending only on $\varphi$) such that
	\[\#\del\{a\in\mathcal R:\mathcal R\models\varphi(a,\overline b)\}\le B\]
	for any $\overline b\in R^n$.
\end{lemma}
\begin{proof}
	Note that $T$ is $o$-minimal implies any definable subset $X'$ of a model $\mathcal R'\models T$ has $\del X$ equal to a finite set of points; namely, choose the formula $\varphi(x)$ defining $X'$, and then use the hypothesis so that $X'$ becomes a set of points plus some intervals, whose boundary is just a finite set of points.

	Now, to continue our proof, fix some $\overline b$, and define $X_{\overline b}\subseteq\mathcal R$ to be the set defined by $\varphi(x,\overline b)$. We note that $\del X_{\overline b}$ is definable as saying that $y\in\del X_{\overline b}$ if and only if $y\in\overline X_{\overline b}$ and $y\in\overline{\mathcal R\setminus X_{\overline b}}$. However, we can describe the closure of a definable set $X$ (defined by $\psi(x)$) by saying that any interval around $y\in\mathcal R$ hits $X$, which can be said as
	\[\forall y_-\forall y_+((y_-<y<y_+)\to\exists x((y_-<x<y_+)\to\psi(x))).\]
	Intersecting, we can define our boundary.

	Now, if the lemma were false, then the theory of
	\[\op{elDiag}\mathcal R\cup\{\#\del X_{\overline b}\ge N\},\]
	where $\overline b$ have been taken to be some new constants, is finitely satisfiable and hence satisfiable. So compactness provides an elementary extension $\mathcal R'$ where $\#\del X_{\overline b}$ is infinite, which contradicts our initial hypothesis. Notably, $\mathcal R'$ will still satisfy $T$ because $\mathcal R\le\mathcal R'$.
\end{proof}
\begin{remark}
	If we only took $\mathcal R$ to be $o$-minimal instead of the full theory, then the above lemma is actually the hardest part of the proof. Notably, we used that the theory is $o$-minimal at the end of the proof.
\end{remark}
\begin{remark}
	This is essentially the typical use of compactness: we know that some value is always finite, so it cannot be arbitrarily large lest compactness enforce infinity.
\end{remark}
Alright, let's start proving \Cref{thm:cell-decomp}.
\begin{proof}[Proof of \Cref{thm:cell-decomp} at $n=1$]
	We show (a) and (b) separately. For (a), this is essentially the statement of $o$-minimality. Each of the $X_\bullet$ is a finite union of points or intervals whose endpoints live in $\del X_\bullet$, so we take
	\[F\coloneqq\bigcup_{i=1}^m\del X_\bullet.\]
	Write $F=\{a_1,\ldots,a_{n-1}\}$ with $a_1<a_1<\cdots<a_{n-1}$, and add in $a_0\coloneqq-\infty$ and $a_n\coloneqq\infty$. Then our cell decomposition is $F$ plus the intervals $(a_i,a_{i+1})$ for each $i$. Then we can write $X_\bullet$ as required as points or unions of intervals from points in $\del X_\bullet$, so we are done.

	Now, (b) is harder. Let $f\colon\mathcal R\to\mathcal R$ is definable. We will actually show that $f$ is actually piecewise continuous and either constant or strictly monotone; i.e., there is a cell decomposition $\mathcal C$ such that $f|_c$ is continuous and either constant or strictly monotone. The point is that continuity (and monotonicity) can be expressed as a first-order sentence, so this should approximately happen only finitely many times. Anyway, we proceed in steps.
	\begin{enumerate}
		\item We begin by noting that continuity is actually implied by other assumptions. Suppose $f\colon\mathcal R\to\mathcal R$ is definable is piecewise strictly monotone or constant; then we claim that $f$ is piecewise continuous. If $f$ is constant on a cell, then $f$ is of course continuous there, so we just need to worry about being strictly monotone. Also, if the cell is a point, there is nothing to do.
		
		So without loss of generality, let $I\coloneqq(a,b)$ be an interval on which $f$ is strictly increasing, and we need to show that we can finitely subdivide the interval to make $f$ continuous. Now, the main point is that $f(I)$ is definable, defined by the sentence $\varphi(y)=\exists x\,f(x)=y$, so $o$-minimality tells us that it is a finite union of points and intervals. Further, $f$ is strictly increasing and hence injective, so $f(I)$ is infinite, so $f$ has some open intervals in this image.

		Now, it is enough to check that $f$ is discontinuous at only finitely many points. Well, if $f$ were discontinuous at infinitely many points, we note that the points of discontinuity is definable and hence a finite union of points and intervals, so $f$ will actually be discontinuous everywhere in an interval inside $I$. Re-applying the above logic to this new smaller interval, so $f$ is discontinuous everywhere on $I$ even though $f(I)$ has some intervals in its image.

		Now, let $J'\subseteq f(I')$ is an interval, and we want to show that $f$ is continuous. Well, suppose $f(x)\in J'$. Then for any $\varepsilon_1<f(x)<\varepsilon_2$ where $(\varepsilon_1,\varepsilon_2)\subseteq J'$, we choose $\delta_i=f^{-1}(\varepsilon_i)$ for each $i$, and monotonicity implies that $\delta_1<x'<\delta_2$ implies $\varepsilon_1<f(x')<\varepsilon_2$, as needed.
	\end{enumerate}
	We will complete the proof next class.
\end{proof}

\end{document}