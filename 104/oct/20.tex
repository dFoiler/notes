\documentclass[../notes.tex]{subfiles}

\begin{document}

% !TEX root = ../notes.tex















Here we go again.

\subsection{More on Monotonic Functions}
Last time we showed that if a strictly increasing function has image an interval on an interval, then the function is continuous on the domain interval. Of course, the use here is somewhat restricted because because strictly increasing or decreasing is quite restricted.

By doing some trick, however, sometimes we can get out of a lot of work. For example, if a function is \textit{locally monotone}, we might be able to piece together continuity for the full function.
\begin{example}
	We show that $f(x)=1/x$ is continuous on $[1,2].$ Well, the function is strictly decreasing, and it is not too hard to show that the range is $[1/2,1],$ so the function is continuous.
\end{example}

Continuing our discussion, we have the following definition.
\begin{definition}[One-to-one]
	A function $f$ is \textit{one-to-one} if and only if $f(a)=f(b)$ implies $a=b.$
\end{definition}
\begin{nex}
	The function $f(x)=x^2$ is not one-to-one on $\RR.$ For example, $f(2)=f(-2).$
\end{nex}
It feels like functions which are one-to-one and continuous should be strictly increasing or decreasing. Let's show this.
\begin{proposition}
	Suppose $f:I\to\RR$ is continuous and injective, where $I$ is some interval. Then $f$ is strictly increasing or strictly decreasing.
\end{proposition}
\begin{proof}
	Show that if $f$ is continuous and neither strictly increasing nor strictly decreasing, then $f$ is not injective. Indeed, to not be strictly increasing nor decreasing, there must be $a<b$ and $c<d$ with $f(a)<f(b)$ and $f(c)<f(d).$
	
	By picking up a suitable subset of our three elements, we can say that either $f(a)\ge f(b)\le f(c)$ or $f(a)\ge f(b)\le f(c)$ for $a<b<c.$ If any of these are equalities, we are done already. So without loss of generality take $f(a)<f(b)>f(c),$ but then $f$ must hit each value in $(\max\{f(a),f(c)\},f(b))$ twice, once in $(a,b)$ and once more in $(b,c).$ So this violates injectivity.
\end{proof}
Let's do some exercises.
\begin{exercise}
	We show that $xe^x=2$ for some $x\in(0,1).$
\end{exercise}
\begin{proof}
	This is by the Intermediate value theorem. Note that $xe^x$ is continuous on $(0,1)$ because it is the product of two continuous functions. Then it suffices to note that
	\[0=0e^0<2<1e^1=e.\]
	So the Intermediate value theorem finishes.
\end{proof}
\begin{exercise}
	Show that any polynomial of odd degree will have a root.
\end{exercise}
\begin{proof}
	This is somewhat technical. The main idea is that $x\to\infty$ makes $f(x)\to\pm\infty$ and $x\to-\infty$ makes $f(x)\to\mp\infty.$ So there is some $a$ with $f(a)>0$ and some $b$ with $f(b)<0,$ and so there is some $x$ between them with $f(x)=0$ by the Intermediate value theorem.

	The technicalities are somewhat annoying, so we will not give them. Roughly speaking, we would have to fix
	\[f(x)=\sum_{k=0}^\infty a_kx^k\]
	where all but finitely many of the $a_\bullet$ are zero. Then we can find some positive and some negative outputs by hand.
\end{proof}
The exercises in this section should not be too challenging.

\subsection{Uniform Continuity}
This is one of our first, new analysis concepts. Here is the motivating example.
\begin{exercise}
	We show that $f(x)=x^2$ is continuous at $x=2.$
\end{exercise}
\begin{proof}
	For each $\varepsilon>0,$ we showed last time that $\delta:=\frac15\varepsilon$ was good enough.
\end{proof}
Something funny about this proof is that the constant $\frac15$ was generated off of $x=2.$ For example, with $\varepsilon=1,$ we can choose $\delta=\frac15$ so that
\[|x-2|<\frac15\implies\left|x^2-4\right|<1.\]
But now if we chose $100$ as our point of interest, then $\delta=\frac15$ will no longer work here: $\left(100+\frac1{10}\right)^2>100+20>100+1,$ so we are out of luck.

The issue we are running into here is that $\delta$ is highly dependent on our choice of point we are studying. It does not feel like we can make $\delta$ independent of this, no matter how small it goes.
\begin{proposition}
	Fix $f(x)=x^2$ and $\varepsilon=1.$ Then there does not exist $\delta$ such that, for each $a\in\RR$ and $x\in\RR,$
	\[|x-a|<\delta\implies\left|x^2-a^2\right|<\varepsilon.\]
\end{proposition}
\begin{proof}
	Suppose for the sake of contradiction that there is such a $\delta.$ Then, for any $x,y\in\RR,$ we have that
	\[|x-y|<\delta\implies\left|x^2-y^2\right|<\delta.\]
	But now take $x=2/\delta$ and $y=2/\delta+\delta/2.$ Then these have distance $\delta/2<\delta,$ but
	\[y^2-x^2=\left(\frac2\delta+\frac\delta2\right)^2-\frac{\delta^2}4=1+\frac4{\delta^2}>1=\varepsilon,\]
	so we have hit our contradiction by the hypothesis on $\delta.$
\end{proof}
So we have the following definition.
\begin{definition}
	Fix $f:S\to\RR$ a function. Then we say that $f$ is \textit{uniformly continuous} on $S$ if and only if, for each $\varepsilon>0,$ we have that there exists a single $\delta>0$ such that
	\[|x-y|<\delta\implies|f(x)-f(y)|<\varepsilon.\]
\end{definition}
\begin{example}
	Constant functions are uniformly continuous. For each $\varepsilon>0,$ take $\delta=1$ so that
	\[|x-y|<\delta\implies|f(x)-f(y)|=0<\varepsilon.\]
\end{example}
\begin{example}
	The identity function is uniformly continuous. For each $\varepsilon>0,$ take $\delta=\varepsilon$ so that
	\[|x-y|<\delta\implies|f(x)-f(y)|=|x-y|<\varepsilon.\]
\end{example}
\begin{nex}
	The function $f(x)=x^2$ is not uniformly continuous, as we showed above.
\end{nex}
\begin{example}
	The function $f(x)=e^x$ seems to have the same problems due to it moving at increasing speeds.
\end{example}
\begin{nex}
	The function $\sin\left(x^2\right)$ is bounded and continuous, but it is not uniformly continuous.
\end{nex}
We note that this is a stronger condition than continuity.
\begin{prop}
	If $f:S\to\RR$ is uniformly continuous, then $f$ is continuous on all of $S.$
\end{prop}
\begin{proof}
	Fix any $a\in S.$ Then for any $\varepsilon>0,$ we know there is a $\delta$ such that
	\[|x-y|<\delta\implies|f(x)-f(y)|<\varepsilon.\]
	Plugging in $y=a$ shows that
	\[|x-a|<\delta\implies|f(x)-f(a)|<\varepsilon,\]
	so it follows that $f$ is continuous at $a.$
\end{proof}
But of course, we showed that the reverse implication is untrue with $f(x)=x^2.$

\subsection{Properties of Uniform Continuity}
We would like to have a more concrete way to test for uniform continuity because the given definition has quite a few quantifiers to digest. We have the following example.
\begin{exercise}
	We show that $f(x)=x^2$ is uniformly continuous on $[-4,10].$
\end{exercise}
\begin{proof}
	Here we are safe because our ``speed'' is now bounded, and in fact the condition seems to be the worst at $10.$ Fix any $\varepsilon>0.$ Then we need to find $\delta$ so that
	\[|x-y|<\delta\stackrel?\implies\left|x^2-y^2\right|<\varepsilon.\]
	Now, we note that
	\[\left|x^2-y^2\right|=|x-y|\cdot|x+y|\le|x-y|\cdot(|x|+|y|)\le|x-y|\cdot20,\]
	so we may choose $\delta:=\varepsilon/20$ which gives
	\[|x-y|<\delta\implies\left|x^2-y^2\right|\le|x-y|\cdot20<20\delta=\varepsilon.\]
	This is what we wanted.
\end{proof}
Here is the more general result.
\begin{theorem}
	Suppose that $f(x)$ is continuous on a closed interval $I.$ Then $f$ is uniformly continuous.
\end{theorem}
\begin{proof}
	We go by contradiction, I guess. Then there is a $\varepsilon>0$ such that each $\delta>0$ has a pair $(x,y)$ with $|x-y|<\delta$ even though $|f(x)-f(y)|\ge\varepsilon.$

	We now attack the continuity. For each $k\in\NN,$ we may find $a_k$ and $b_k$ with $|a_k-b_k|<\frac1n$ even though $|f(a_k)-f(b_k)|\ge\varepsilon.$ Now find a convergent subsequence (!) $a_{\sigma k},$ which converges to some $\ell$ in the closed interval. But now
	\[|b_{\sigma k}-\ell|\le|b_{\sigma k}-a_{\sigma k}|+|a_{\sigma k}-\ell|\]
	will go to $0$ as $k\to\infty,$ so it follows that $b_{\sigma k}\to\ell.$

	So we have by continuity that
	\[\lim_{k\to\infty}\big(f(a_{\sigma k})-f(b_{\sigma k})\big)=f(\ell)-f(\ell)=0,\]
	but this contradicts the assertion that $|f(a_{\sigma k})-f(b_{\sigma k})|\ge\varepsilon$ always, so we are done here.
\end{proof}
\begin{remark}
	The above proof does not work for open intervals because our convergent subsequence does not need to converge in the interval. As a concrete example, $f(x)=\frac1x$ on $(0,1)$ is not uniformly continuous because of the speediness at $0.$
\end{remark}

Here is another nice property.
\begin{proposition} \label{prop:uniformcontcauchy}
	Fix $f:S\to\RR$ a uniformly continuous. Then if $\{a_k\}_{k\in\NN}$ is Cauchy, then $\{fa_k\}_{k\in\NN}$ is Cauchy.
\end{proposition}
This is not true for general functions.
\begin{example}
	The continuous function $f(x)=\frac1x$ on $(0,1)$ has the Cauchy sequence $\{1/n\}_{n\in\NN},$ which is not outputted to a Cauchy sequence.
\end{example}
\begin{proof}[Proof of \autoref{prop:uniformcontcauchy}]
	We do this by hand. Fix some $\varepsilon$ so that we want $N$ for which
	\[n,m>N\stackrel?\implies|fa_n-fa_m|<\varepsilon.\]
	But now there exists a $\delta$ for which $|x-y|<\delta$ implies $|f(x)-f(y)|<\varepsilon,$ so we choose $N$ by the Cauchy condition such that
	\[n,m>N\implies|a_n-a_m|<\delta\implies|f(x)-f(y)|<\varepsilon,\]
	which finishes.
\end{proof}
\begin{remark}
	We are using Cauchy sequences in the above rather than convergent sequences because we don't have to worry about the limit being inside of the domain or not. Our example from earlier exemplified this.
\end{remark}

We have the following quick thought.
\begin{proposition}
	If $f:S\to\RR$ is uniformly continuous and $T\subseteq S,$ then $f|_T:T\to\RR$ is uniformly continuous. 
\end{proposition}
\begin{proof}
	Fix $\varepsilon>0.$ Then on $S$ there is some $\delta$ for which $|x-y|<\delta$ implies $|f(x)-f(y)|<\varepsilon,$ but this same $\delta$ also works on $T.$
\end{proof}
\begin{example}
	We have that $x^2$ is uniformly continuous on $(0,1)$ because it is uniformly continuous on $[0,1].$
\end{example}
\begin{nex}
	We cannot ``fix'' $f(x)=1/x$ on $(0,1)$ to be uniformly continuous by replacing this with $[0,1]$ because there is no way to add a point at $0$ to get a continuous function.
\end{nex}
Synthesizing the above two examples gives the following result.
\begin{theorem}
	Fix $(a,b)$ an open interval and $f:(a,b)\to\RR.$ Then $f$ is uniformly continuous on $(a,b)$ if and only if $f$ can be extended to be continuous on $[a,b].$
\end{theorem}
\begin{proof}
	One direction is not so bad: if we can extend $f$ to be continuous on $[a,b],$ then it is uniformly continuous, so it is uniformly continuous on $(a,b).$

	The other direction is a bit trickier, so we won't prove it explicitly; take $f$ uniformly continuous. Then the point is that $f$ takes Cauchy sequences to Cauchy sequences! So find some Cauchy sequence in $(a,b)$ which converges to $\inf(a,b)=a,$ and then we know that the outputs by $f$ will be another Cauchy sequence. This converges in $\RR,$ so say it converges to $f(a).$ Doing similar for $f(b)$ gets us our necessary extension.

	There is some trick that we need to do to make sure all sequences converging to $a$ will converge to the required $f(a).$ Well, if we have another $a'_n$ such that $a'_n\to a$ as $n\to\infty,$ we need to show $f(a'_n)\to f(a)$ still. Well, if it converges to some value $b,$ then the sequence
	\[a_1,a'_1,a_2 a'_2,\ldots\]
	will have output converging to both $f(a)$ and $b,$ so $b=f(a)$ as needed. Regardless, something like this should finish the proof.
\end{proof}
Here is another result.
\begin{proposition}
	Fix $f$ a function defined on an interval $I.$ If $f$ is differentiable with bounded derivative on the interior of $I,$ then $f$ is uniformly continuous on $I.$
\end{proposition}
\begin{nex}
	The function $f(x)=\frac1x$ on $(0,1)$ has derivative approaching $-\infty$ as $x\to0,$ and so it fails the above, as it should.
\end{nex}
\begin{proof}
	Essentially, the bounded derivative shows that the secant lines have bounded slopes by the Mean value theorem. We will not say more here.
\end{proof}

\subsection{Exercises}
And let's close off with some exercises.
\begin{exercise}[Ross 19.1(f)]
	The function $f(x)=\sin\left(\frac1{x^2}\right)$ is not uniformly continuous on $\left(0,1\right].$
\end{exercise}
\begin{proof}
	The point here is that we cannot extend $f$ to a continuous function on $[0,1].$ Namely, we can find sequences $\{a_k\}_{k\in\NN}$ and $\{b_k\}_{k\to\infty}$ with $a_k\to0$ and $b_k\to0$ with $f(a_k)\equiv0$ and $f(b_k)\equiv1$ (say), so there is no way to assign some $f(0)$ continuously.
\end{proof}
\begin{exercise}[Ross 19.1(g)]
	The function $g(x)=x^2\sin\left(\frac1x\right)$ on $\left(0,1\right].$
\end{exercise}
\begin{proof}
	We can extend $g$ to a continuous function on $[0,1]$ by setting
	\[g(0)=\lim_{x\to0}g(x)=\lim_{x\to0}x^2\sin\left(\frac1x\right),\]
	which is $0$ by the Squeeze theorem.
\end{proof}
\begin{exercise}[Ross 19.3(a)]
	We show that $f(x)=\frac x{x+2}$ on $[0,2]$ by hand.
\end{exercise}
\begin{proof}
	For each $\varepsilon>0,$ we need to find $\delta>0$ such that
	\[|x-y|<\delta\implies\left|\frac x{x+2}-\frac y{y+2}\right|<\varepsilon.\]
	Well, we can massage a bit by writing
	\[\left|\frac x{x+2}-\frac y{y+2}\right|=\left|\frac{2(x-y)}{(x+2)(y+2)}\right|\le\frac2{(0+2)(0+2)}|x-y|=\frac12|x-y|.\]
	So we see $\delta=2\varepsilon$ so that
	\[|x-y|<\delta\implies\left|\frac x{x+2}-\frac y{y+2}\right|<\frac12|x-y|<\frac12\delta=\varepsilon,\]
	which is what we wanted.
\end{proof}
\begin{exercise}
	Suppose that $f$ is continuous on $\left[0,\infty\right)$ an uniformly continuous on some $\left[k,\infty\right)$ for some $k>0.$ Then $f$ is uniformly continuous on $\left[0,\infty\right).$
\end{exercise}
\begin{proof}
	Fix $\varepsilon>0.$ We can find $\delta_2$ so that, for $x,y\in\left[k,\infty\right),$ we have
	\[|x-y|<\delta_2\implies|f(x)-f(y)|<\varepsilon.\]
	Similarly, we can find $\delta_1$ so that, for $x,y\in[0,k+\delta],$ we have
	\[|x-y|<\delta_1\implies|f(x)-f(y)|<\varepsilon\]
	because $f$ is continuous and hence uniformly continuous on $[0,k+\delta].$ So taking $\delta:=\min\{\delta_1,\delta_2\}$ has
	\[|x-y|<\delta\implies|f(x)-f(y)|<\varepsilon\]
	in all cases, after some care. Indeed, if $|x-y|<\delta,$ then either $x,y\in[0,k+\delta]$ or $x,y\in\left[k,\infty\right).$
\end{proof}

\end{document}