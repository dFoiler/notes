\documentclass[../notes.tex]{subfiles}

\begin{document}

% !TEX root = ../notes.tex

















We continue with our discussion on continuity.

\subsection{Talking Continuity}
People usually start with a graphical definition of continuity, but we will want something more general. For example, graphical intuition does not really help define functions which are continuous on $\RR\setminus\QQ$ but not in $\QQ.$

We have given a precise definition of continuity, so we can start talking about some continuity laws. For example, is the sum of two continuous functions itself continuous?
\begin{proposition}
	Fix functions $f,g:S\to\RR$ are continuous at some $a\in S.$ Then $f+g$ is continuous at $a.$
\end{proposition}
\begin{proof}
	Fix any $\varepsilon>0.$ Then $\varepsilon/2>0,$ so we have some $\delta_f>0$ such that
	\[|x-a|<\delta_f\implies|f(x)-f(a)|<\frac12\varepsilon.\]
	Similarly, we have some $\delta_g>0$ such that
	\[|x-a|<\delta_g\implies|g(x)-g(a)|<\frac12\varepsilon.\]
	But now set $\delta:=\min\{\delta_f,\delta_g\}>0$ so that $\delta>0$ has $|x-a|<\delta$ implies both of the above, so we bound
	\[|(f+g)(x)-(f+g)(a)|\le|f(x)-f(a)|+|g(x)-g(a)|<\frac12\varepsilon+\frac12\varepsilon=\varepsilon,\]
	which is what we need.
\end{proof}
Note that we could have just proven the corresponding limit law here using the sequence definition instead and used the fact that we know limits of sequences decompose.

And we can also do $f\cdot g.$
\begin{proposition}
	Fix functions $f,g:S\to\RR$ are continuous at some $a\in S.$ Then $fg$ is continuous at $a.$
\end{proposition}
\begin{proof}
	The key point is that
	\[|f(x)g(x)-f(a)g(a)|\le|f(x)g(x)-f(x)g(a)|+|f(x)g(a)-f(a)g(a)|=|f(x)|\cdot|g(x)-g(a)|+|g(a)|\cdot|f(x)-f(a)|.\]
	Now we can bound this quantity; fix any $\varepsilon>0.$ Something annoying here is that we need to bound the $|f(x)|$ on the outside. So start by fixing some $\varepsilon_0$ to get $\delta_0$ so that
	\[|x-a|<\delta_0\implies|f(x)-f(a)|<\varepsilon_0.\]
	In particular, $|f(x)|<|f(a)|+\varepsilon_0$ always, so we see that $|x-a|<\delta_0$ implies
	\[|f(x)g(x)-f(a)g(a)|\le||f(a)|+\varepsilon_0|\cdot|g(x)-g(a)|+|g(a)|\cdot|f(x)-f(a)|.\]
	Now bounding $|f(x)-f(a)|$ and $|g(x)-g(a)|$ we can bound without tricks. Now we can find $\delta_f>0$ such that
	\[|x-a|<\delta_f\implies|f(x)-f(a)|<\frac{\varepsilon/2}{|g(a)|+1},\]
	and we can find some $\delta_g>0$ such that
	\[|x-a|<\delta_g\implies|g(x)-g(a)|<\frac{\varepsilon/2}{||f(a)|+\varepsilon_0|+1}.\]
	In particular, $\delta:=\min\{\delta_0,\delta_f,\delta_g\}>0$ will have $|x-a|<\delta$ imply all of the above so that
	\[|f(x)g(x)-f(a)g(a)|\le||f(a)|+\varepsilon_0|\cdot|g(x)-g(a)|+|g(a)|\cdot|f(x)-f(a)|<\frac12\varepsilon+\frac12\varepsilon<\varepsilon,\]
	which is what we wanted.
\end{proof}

Let's do some exercises.
\begin{exercise}[Ross 17.5]
	Fix some $m$ a positive integer. We show that $f(x)=x^m$ is continuous for each real number $x.$
\end{exercise}
\begin{proof}
	Because $m$ is a positive integer, we can do this by induction. Our base case is $m=1,$ where we say that each $a\in\RR$ with $\varepsilon>0$ has $\delta=\varepsilon$ giving
	\[|x-a|<\varepsilon\implies|f(x)-f(a)|=|x-a|<\delta=\varepsilon,\]
	establishing our continuity. Now, we know that products of continuous functions are continuous, so
	\[\underbrace{x\cdot\ldots\cdot x}_{m}\]
	is also continuous.
\end{proof}
Here is a harder example.
\begin{exercise}[Ross 17.9(a)]
	We show that $f(x)=x^2$ is continuous at $a=2.$
\end{exercise}
\begin{proof}
	We use the $\varepsilon$-$\delta$ definition of continuity. Namely, for each $\varepsilon>0,$ we need to find $\delta>0$ so that
	\[|x-2|<\delta\stackrel?\implies\left|x^2-4\right|<\varepsilon.\]
	But now we see that
	\[\left|x^2-4\right|=|x-2|\cdot|x+2|.\]
	Provided $\delta\le1,$ then we see that $|x-2|<\delta$ implies $|x+2|\le|x-2|+4\le1+4=5.$ So we set $\delta:=\min\{1,\varepsilon/5\}>0$ so that $|x-2|<\delta$ implies
	\[\left|x^2-4\right|=|x-2|\cdot|x+2|<\delta\cdot5\le\varepsilon,\]
	which is what we wanted.
\end{proof}
Notably, we don't care for the exact value of $\delta$ that will give the sharpest inequality. We need something to work; constant factors are inconsequential.
\begin{exercise}[Ross 17.9(b)]
	We show that $f(x)=\sqrt x$ is continuous at $a=0.$
\end{exercise}
\begin{proof}
	For each $\varepsilon>0,$ we need to find $\delta$ such that
	\[|x-0|<\delta\stackrel?\implies\left|\sqrt{x}\right|<\varepsilon.\]
	Well, we can just set $\delta=\varepsilon^2$ so that $|x|<\delta$ implies $|\sqrt x|<\varepsilon,$ which we can show by contraposition: $|\sqrt x|\ge\varepsilon$ would imply that $|x|\ge\varepsilon^2$ by multiplication.
\end{proof}

\subsection{Extreme Value Theorem}
So we're actually starting to do some analysis in this class. We recall the following statement.
\begin{theorem}[Extreme value]
	Fix $f$ a continuous function on a closed interval. Then $f$ is bounded and achieves a maximum and minimum.
\end{theorem}
\begin{warn}
	We have that $\RR=(-\infty,\infty)$ is closed and an interval, but it is not a closed interval because it does not contain its endpoints.
\end{warn}
\begin{proof}
	We start by showing that $f$ is bounded. We will show that $f$ is bounded above, and bounded below is a similar argument; suppose for the sake of contradiction that $f$ is not bounded above, so that we can find a sequence $\{f(x_k)\}_{k\in\NN}$ so that $f(x_k)\ge k$ for each $k\in\NN.$ However, the sequence $\{x_k\}_{k\in\NN}$ is a sequence in a bounded set, so it must have a convergent subsequence $\{x_{\sigma k}\}_{k\in\NN}$ given by $\sigma:\NN\to\NN.$

	So now say that $x_{\sigma k}\to x,$ and we know that $x$ is in the domain of $f$ because the domain of $f$ is closed (!). But now $f(x_{\sigma k})\to f(x),$ so there is some $N$ for which $n>N$ implies $|f(x_{\sigma n})-f(x)|<1$ so that
	\[f(x)\ge f(x_{\sigma n})-1\ge\sigma k-1\ge k-1\]
	for each $f(x).$ But now we can set $x=\floor{f(x)}+10$ to get a contradiction, finishing this.

	Now we show that $f$ achieves its maximum, and the minimum is a similar argument. Fix
	\[s:=\sup\{f(x)\}.\]
	Now, the supremum is in the set of subsequential limits, which means we can find $\{x_k\}_{k\in\NN}$ such that $f(x_k)\to s.$ But now the $\{x_k\}_{k\in\NN}$ has a convergent subsequence called $\{x_{\sigma k}\}_{k\in\NN}$ for some strictly increasing $\sigma:\NN\to\NN.$

	To finish, we again see that $x_{\sigma k}\to x$ for some $x$ in the domain of $f$ because the domain of $f$ is closed. But now $f(x_{\sigma k})\to f(x),$ and because $f(x_{\sigma k})\to s$ because the limit of the subsequence is the limit of the sequence when the limit of the sequence is defined. Thus, we have $f(x)=s$ because the limit is unique.
\end{proof}
This is an important idea for calculus when we're trying to find the maximums and minimums of various functions. Namely, it is not immediately obvious---as the above theorem shows---that these actually exist at all. Here we see that we get this for all closed intervals (in fact, compact domains in general), but, say, open intervals are harder.
\begin{remark}
	The above proof also works for any closed and bounded set. So, for example, we have an extreme value theorem on $[0,1]\cup[2,3].$
\end{remark}
We also note that we have some of the tools and thought processes for more general settings. For example, what if instead of $\RR$ as our ambient space, we use $\QQ$? Well, the function
\[f(x)=\frac1{x-\sqrt2}\]
on the closed interval $[0,5]$ is not bounded above or below even though it is perfectly well-formed.

As an aside, we note that closed sets in metric spaces and topologies in general have important implications. Namely, being closed was paramount to the above discussion: everything breaks down on open intervals because we lost closure. In fact, compactness is an important condition here.
\begin{example}
	All functions on $\{1/n\}_{n\in\NN}$ are continuous. Roughly speaking, this is due to ``discreteness.''
\end{example}
In spite of the above example, it really feels like there should be a constraint on $0,$ but functions on $\{1/n\}_{n\in\NN}$ cannot ``see'' $0.$
\begin{example}
	Not all functions on $\{1/n\}_{n\in\NN}\cup\{0\}$ are continuous. Namely, we also have to check that the subsequence $1/n\to0$ is carried to $f(1/n)\to f(0).$
\end{example}

\subsection{Intermediate Value Theorem}
Here is another important result. For example, we used this quite frequently in calculus when doing root-finding.
\begin{theorem}[Intermediate value]
	Fix $f$ a continuous function on the closed interval $[a,b].$ Then if $f$ achieves all values between $f(a)$ and $f(b).$
\end{theorem}
\begin{proof}
	We proceed by contradiction. Without loss of generality, we take $f(a)<f(b).$ Suppose that $d$ between $f(a)$ and $f(b)$ goes is not achieved. However, the idea now is that we can decompose $[a,b]$ into two disjoint open sets, which is a problem because $[a,b]$ is connected. Indeed, we look at
	\[S:=\{x\in[a,b]:f(x)<d\}.\]
	Now, there must be a sequence $\{x_k\}_{k\in\NN}$ such that $x_k\to\sup S,$ and so it follows $\sup S\in[a,b]$ by closure. But now each $f(x_k)$ is at most $d,$ so $f(\sup S)\le d.$

	We very quickly note that $\sup S\notin\{a,b\}.$ Indeed, $f(a)<d<f(b),$ so certainly $f(\sup S)\le d<f(b)$ implies $\sup S\ne b.$ On the other hand, $\sup S=a$ would force $S=\{a\},$ but then $x>a$ would have $f(x)\ge d>f(a),$ so $|f(x)-f(a)|\ge d,$ which breaks continuity of $f$ at $a$ by checking $\varepsilon=d-f(a).$

	To finish, we note that the complement
	\[S^c=\{x\in[a,b]:f(x)>d\}\]
	will have a sequence converging down to $\sup S$ because all points bigger than $\sup S$ are in $S^c,$ and such points exist because $\sup S\notin\{a,b\}.$ Thus, this downward moving subsequence shows that $f(\sup S)\ge d,$ so $f(\sup S)=d,$ which is our contradiction as we have a point which goes to $d.$
\end{proof}
We note that the Intermediate value theorem implies that the output of our continuous function $f$ on the closed interval must itself be a closed interval.
\begin{cor}
	Suppose that $f$ is a continuous function on the closed interval $[a,b].$ Then the image of $f$ is a closed interval.
\end{cor}
\begin{proof}
	We know that $f$ must achieve its maximum $M$ and minimum $m$ from the Extreme value theorem, say from $x_M$ and $x_m$ respectively. But now the Intermediate value theorem implies that
	\[f([a,b])\supseteq f\left([x_M,x_m]\cup[x_m,x_M]\right)\supseteq[m,M],\]
	but$ f\left([a,b]\right)\subseteq[m,M]$ by definition of the maximum and minimum, so we conclude $f([a,b])=[m,M],$ which finishes.
\end{proof}
To continue our story, we pick up the following definition.
\begin{definition}[Strictly increasing]
	We say that $f(x)$ is \textit{strictly increasing} if and only if $a<b$ implies $f(a)<f(b).$
\end{definition}
This is the same idea we had as in sequences.

We have the following result, acting as a partial converse to the Intermediate value theorem.
\begin{proposition}
	Fix $f$ a strictly increasing function on some interval. Then if the image of $f$ is also an interval, then $f$ is continuous.
\end{proposition}
\begin{proof}
	Fix $f:I_1\to I_2$ our function, where $f$ surjects. If $I_2$ is a point, then $f$ is constant and hence continuous. Else points in $I$ have nontrivial open neighborhoods.
	
	Now, fix $a\in I_1$ that we want $f$ to be continuous at. We proceed by force. Choose some $\varepsilon>0,$ and then we observe that
	\[(f(a)-\varepsilon,f(a)+\varepsilon)\cap I_2\]
	is some interval because it is the intersection of two intervals, and this interval is nonempty because it contains $f(a).$ So let this interval have $[y_1,y_2]$ as a closed sub-interval, and then we can pull $y_1$ and $y_2$ back to $x_1$ and $x_2$ by $f.$ Now finding some open neighborhood around $a$ inside of $(x_1,x_2)$ gives us our $\delta$ so that
	\[|x-a|<\delta\implies x\in(x_1,x_2)\implies f(x)\in(f(a)-\varepsilon,f(a)+\varepsilon).\]
	This finishes the proof.
\end{proof}
This helps us test for function continuity, for example by partitioning a big function into small intervals where it is strictly increasing or decreasing because we know that the function ought be continuous on each of those intervals by simply checking what their output through $f$ is.

\end{document}