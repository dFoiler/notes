\documentclass[../notes.tex]{subfiles}

\begin{document}




























We are mostly preluding for the time being, but let's go ahead and jump in with it.

\subsection{Prelude: Motivating Rigor}
Also recall from last time that we can have a sequence of rational numbers which approaches something rational. However, we seem more dubious to having a sequence of real numbers approach something which is not a real number. Part of the problem with putting this doubt to rest is that we don't have a good definition of ``convergence'' yet.

As a related idea, suppose we have a sequence $\{a_k\}_{k\in\NN}$ of only positive real numbers, then the sum
\[\sum_{k=1}^\infty a_k\]
is either convergent or diverges to $+\infty.$ However, if we permit some of these to be negative, then the sum might just not be well-defined. Viewing the infinite series as a sequence of partial sums, we see that we are hoping that a sequence of real numbers (the partial sums) to only converge to real numbers when they converge at all. So if we care about infinite series convergence types, then we must be careful here.

So we hope quite strongly that convergent real sequences only converge to real numbers. This is tied to \textit{completeness}, which we will do later.

Recall the following function.
\[f(x)=\begin{cases}
	0 & x\in\QQ, \\
	1 & 1\notin\QQ.
\end{cases}\]
This function is not continuous at any single point, though it might not be completely apparent because limit laws do not help us here. Namely, all of our limits are bad. For example, let's try to think about
\[\lim_{x\to\infty}f(x).\]
Does this even make sense? How would we go about evalauting this? Our Calculus I and II tricks do not really apply here. To make our lives more concrete, let's imagine something like
\[a_n:=\begin{cases}
	1 & n\text{ is even}, \\
	0 & n\text{ is odd}.
\end{cases}\]
Now how would we evaluate $\lim_{n\to\infty}a_n$? Does this even make sense?

The correct way to approach this is via a $\delta$-$\varepsilon$ proof, which is a bit hard. As an example, how do we prove something like
\[\lim_{x\to2}x^2=4?\]
Well, we could ``just look at it'' so that it's not very interesting. But this rigor is reasonable because of garbage like $\lim_{n\to\infty}f(x).$ We need comfort with $\delta$-$\varepsilon$ proofs because we need to be able to use them when we don't have other options.

There are some other questions we might be interested in.
\begin{itemize}
	\item Can you make a functoin continuous at only one point?
	\item Can you make a function continuous at only the rational numbers?
	\item Can you make a function continuous at onle the irrational numbers?
\end{itemize}
Note that we really need $\delta$-$\varepsilon$ for these proofs because what other tools do we have against the pathologies we need to create?

As another example, recall the Intermediate value theorem.
\begin{thm}[Intermediate value]
	Fix $f:[a,b]\to\RR$ a continuous function. Then, for each $y$ between $f(a)$ and $f(b),$ there exists an $x$ such that $f(x)=y.$
\end{thm}
Now, can we prove this? Intuitively, this is clear, but that is not a proof. Similarly, how could we prove the various convergence tests? For example, how could we prove the ratio test? the root test? What would happen if the limits don't exist?

The real point of this class is to add rigor to our various intuitions. There are things that we know, such as the fact that
\[\sum_{k=1}^\infty\frac1n\]
diverges, which are somewhat difficult to prove. But if we wanted to do this rigorously, it is not clear how we could talk about the partial sums of this series. Or, we know that
\[\sum_{k=0}^\infty\frac1{2k+1}-\frac1{2k+2}\]
will converge by (say) the alternating series test, but what about
\[\sum_{k=0}^\infty\frac1{2k+1}+\frac1{2k+2}-\frac1{2k+3}-\frac1{2k+4}?\]
This requires some trickery; the trickery here turns out to be that we shold group the terms as given and then test convergence.

Here is another series.
\[f(x)=x-\frac{x^2}2+\frac{x^3}3-\frac{x^4}4+\cdots.\]
This series converges at $x=1.$ However, when we take its derivative, we get
\[f'(x)=1-x+x^2-x^3+\cdots,\]
which diverges at $x=1.$ Things are stranger at the ends of its interval of convergence, which is roughly because we cannot exchange an infinite sum with an integral whenever we want: the original series is merely conditionally convergent at $x=1.$

Have yet another question. If we have two everywhere differentiable functions $f,g:\RR\to\RR$ have identically equal derivateives, must they differ by a constant? Well, sure: $\delta:=(f-g)$ has derivative which vanishes everywhere, which implies that the function is constant by the Mean value theorem. We could probably do this by hand with limits if we tried hard enough, but so it goes.

Continuing with our theme, note
\[\int_0^1x^2\,dx=\frac13\qquad\text{and}\qquad\int_0^1\frac1x\,dx=\text{diverges}.\]
However, the integral of the product is $\frac12$ and notably well-defined. Or even worse, what is the integral of
\[\int_0^11_{\QQ}(x)\,dx?\]
I think this will turn out to not be well-defined under Riemann integration (though Lebesgue would like to know your location). In general, it is not clear how we should integrate poorly-behaved functions: the Fundamental theorem of calculus only tells us what to for continuous functions. In this class, we would like to build a general criterion for integrable. For example, can we have an integrable function which is nowhere continuous?

And here is a last example. Imagine the plane $\RR^2$ equipped with its usual (Euclidean) distance. Pick up two points $(x_1,y_1)$ and $(x_2,y_2)$ so that the distance between them is
\[d((x_1,y_1),(x_2,y_2)):=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}.\]
However, why can't we define distance more pathologically, by
\[d_{\text{taxicab}}((x_1,y_1),(x_2,y_2)):+|x_2-x_1|+|y_2-y_1|?\]
This distance function seems fairly nice. But how nice is it? Or what about the lonely, distance, defined by
\[d_{\text{discrete}}((x_1,y_1),(x_2,y_2)):=\begin{cases}
	1 & (x_1,y_1)\ne(x_2,y_2), \\
	0 & (x_1,y_1)=(x_2,y_2).
\end{cases}\]
There are lots of these things that we could play around with. Now, how do these things change convergence? We would like convergence to mean that ``the distance between is going to $0$,'' but in the discrete metric, it doesn't like it's converging. Sadness ensues. In fact, the only convergent sequences in the lonely metric are eventually constant ones.

\subsection{Bring Natural}
Let's get started with the book now. Our story begins with the natural numbers $\NN,$ which consist of the positive integers in this class.

One property of $\NN$ we care about is that $n\in\NN$ implies $n+1\in\NN.$ This appears trivial but is in fact quite fundamental. For example, there is certainly no largest number. Similarly, this gives us rise to induction: if $S\subseteq\NN$ with $1\in S$ and $n\in S\implies n+1\in S,$ then we are able to conclude that $S=\NN.$ Somehow, we've gotten all natural numbers! More precisely, we have the following.
\begin{ax}
	Suppose that $P(n)$ is a proposition in $n\in\NN.$ If $P(1)$ is true, and $P(k)$ implies $P(k+1)$ for any $k\in\NN,$ then $P(n)$ is true for all $n\in\NN.$
\end{ax}
Let's do an example of induction.
\begin{prop}[Ross 1.7]
	We prove that $7^n-6n-1$ is divisible by $36$ for all $n\in\NN.$
\end{prop}
\begin{proof}
	We proceed by induction. Our base case is $n=1,$ for which the statement reads $7^1-6\cdot1-1=7-6-1=0=0\cdot36,$ so we are safe.
	
	Now suppose that $36\mid7^k-6k-1$ so that we want to prove $36\mid7^{k+1}-6(k+1)-1.$ The trick is to write
	\begin{align*}
		7^{k+1}-6(k+1)-1 &= 7\cdot7^k-6k-7, \\
		&= 7\cdot\left(7^k-6k-1\right)+7\cdot6k+7-6k-7 \\
		&= 7\cdot\left(7^k-6k-1\right)+36k,
	\end{align*}
	which is now divisible by $36$ by the inductive hypothesis.
\end{proof}

Here is another example.
\begin{prop}
    We prove that $4^n>3^n+2^n$ for each $n\ge2.$
\end{prop}
\begin{proof}
    Our base case is $n=2,$ for which this reads $16>9+4=13,$ so we are safe. Now suppose that the statement is true for $n,$ and we want to show it is true for $n+1.$ Well, note that
    \[4^{n+1}=4\cdot4^n>4\left(3^n+2^n\right)=4\cdot3^n+4\cdot2^n.\]
    Now the right-hand side is termwise greater than $3^{n+1}+2^{n+1},$ so we finish the inductive step.
\end{proof}
In contrast, how could we go about showing the following?
\begin{prop}
    It is true that $4^x>3^x+2^x$ for real numbers $x\ge2.$
\end{prop}
A direct induction won't work here, though an inductive spirit might: for example, if we show that it is true in $[2,3]$ to start, then we could do an $x\mapsto x+1$ move to get all real numbers. The more direct way to do this is to say that $4^x$ is increasing faster than $2^x+3^x,$ though this is somewhat difficult to rigorize.

\end{document}